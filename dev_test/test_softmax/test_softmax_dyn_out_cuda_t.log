[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:916: LOWER START

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass RemoveUnusedFunctions
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToBasicBlockNormalForm
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass sequential
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass EtaExpand
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x)
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass SimplifyInference
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass SimplifyExpr
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Inline
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass DeadCodeElimination
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlinePrimitives
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldScaleAxis
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToANormalForm
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2 = %x1(%x);
  %x2
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2: Tensor[(?, ?, ?, ?), float32] = %x1(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x2
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass LambdaLift
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2: Tensor[(?, ?, ?, ?), float32] = %x1(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x2
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Inline
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = %0;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %0(%x);
  %x2
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass DeadCodeElimination
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlinePrimitives
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlineGlobals
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass RemoveUnusedFunctions
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[10:53:55] /workspace/home/codes/tvm/src/driver/driver_api.cc:139: LOWER INFERBOUND BEFORE
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, ): range(min=0, ext=4)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=4)): range(min=0, ext=4)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/driver/driver_api.cc:149: Func before opt
[10:53:55] /workspace/home/codes/tvm/src/driver/driver_api.cc:150: primfn(placeholder_1: handle, compute_1: handle) -> ()
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = add(32 /* ty=int64 */, 7 /* ty=int64 */) /* ty=int64 */;
  %4 = prod(%shape_func_out_0) /* ty=int64 */;
  %5 = divide(%3, 8 /* ty=int64 */) /* ty=int64 */;
  %6 = multiply(%4, %5) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%6, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %7 = (%x,);
  %8 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %7, %8) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main() -> int64 {
  %0 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  %0(32 /* ty=int64 */, 7 /* ty=int64 */) /* ty=int64 */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToANormalForm
type Storage {
  
}

def @main() -> int64 {
  let %x = 32 /* ty=int64 */;
  let %x1 = 7 /* ty=int64 */;
  let %x2 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3 = %x2(%x, %x1);
  %x3
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass EtaExpand
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1)
  };
  let %x3: int64 = %x2(%x, %x1);
  %x3
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [T_add] "realize_scope" = "";
  realize(T_add, [], True {
    T_add[] = (placeholder[] + placeholder_1[])
  })
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerReduction
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.PlanAndUpdateBufferAllocationLocation
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ConvertBlocksToOpaque
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CompactBufferAllocation
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.FlattenBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VerifyMemory
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Apply
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InferFragment
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerThreadAllreduce
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerWarpMemory

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Apply
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main() -> int64 {
  %0 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  %0(39 /* ty=int64 */, 8 /* ty=int64 */) /* ty=int64 */
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToANormalForm
type Storage {
  
}

def @main() -> int64 {
  let %x = 39 /* ty=int64 */;
  let %x1 = 8 /* ty=int64 */;
  let %x2 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3 = %x2(%x, %x1);
  %x3
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass EtaExpand
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1)
  };
  let %x3: int64 = %x2(%x, %x1);
  %x3
}

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  attr [T_divide] "realize_scope" = "";
  realize(T_divide, [], True {
    T_divide[] = (placeholder[] / placeholder_1[])
  })
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerReduction
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.PlanAndUpdateBufferAllocationLocation
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ConvertBlocksToOpaque
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CompactBufferAllocation
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.FlattenBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VerifyMemory
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Apply
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InferFragment
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerThreadAllreduce
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerWarpMemory

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Apply
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = prod(%shape_func_out_0) /* ty=int64 */;
  %4 = multiply(%3, 4 /* ty=int64 */) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%4, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %5 = (%x,);
  %6 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %5, %6) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = fn (%p02: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p02) /* ty=int64 */
  };
  %4 = %3(%shape_func_out_0) /* ty=int64 */;
  %5 = fn (%p01: int64, Primitive=1) -> int64 {
    multiply(%p01, 4 /* ty=int64 */) /* ty=int64 */
  };
  %6 = %5(%4) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%6, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %7 = (%x,);
  %8 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %7, %8) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass sequential
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass LabelOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32], hash="145913305f625cf1") -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1, hash="e2782cdc77404249") -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1, hash="75ec56f3169a1497") -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1, hash="e2e2680f0ff08f46") -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:53:55] /workspace/home/codes/tvm/src/driver/driver_api.cc:139: LOWER INFERBOUND BEFORE
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, ): range(min=0, ext=4)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=4)): range(min=0, ext=4)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/driver/driver_api.cc:149: Func before opt
[10:53:55] /workspace/home/codes/tvm/src/driver/driver_api.cc:150: primfn(placeholder_1: handle, compute_1: handle) -> ()
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(4), int64], Primitive=1, hash="75ec56f3169a1497") -> int64 {
  prod(%p0) /* ty=int64 */
}
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k0, ): range(min=0, ext=4)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k0, range(min=0, ext=4)): range(min=0, ext=4)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(singleton, range(min=0, ext=1)): range(min=0, ext=1)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  attr [placeholder_red] "realize_scope" = "";
  realize(placeholder_red, [], True {
    placeholder_red[] = 1i64
    for (k0: int32, 0, 4) {
      placeholder_red[] = (placeholder_red[]*placeholder[k0])
    }
  })
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: int64, Primitive=1, hash="e2e2680f0ff08f46") -> int64 {
  multiply(%p0, 4 /* ty=int64 */) /* ty=int64 */
}
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  attr [T_multiply] "realize_scope" = "";
  realize(T_multiply, [], True {
    T_multiply[] = (placeholder[]*4i64)
  })
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1, hash="e2782cdc77404249") -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
}
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (floormod((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), 512) == 0)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (floormod(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), 512) == 0)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (floormod((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), 512) == 0)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (floormod(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), 512) == 0)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(blockIdx.x, , blockIdx.x): range(min=0, ext=floordiv(((any_dim*any_dim)*any_dim), 512))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(threadIdx.x, , threadIdx.x): range(min=0, ext=512)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k, ): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused, ): range(min=0, ext=((any_dim*any_dim)*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused, ): range(min=0, ext=(any_dim*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(blockIdx.x, , blockIdx.x): range(min=0, ext=floordiv((((any_dim*any_dim)*any_dim)*any_dim), 512))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(threadIdx.x, , threadIdx.x): range(min=0, ext=512)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.i3.fused.inner, ): range(min=0, ext=512)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused, ): range(min=0, ext=((any_dim*any_dim)*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused, ): range(min=0, ext=(any_dim*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.inner, ): range(min=0, ext=512)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused, ): range(min=0, ext=(any_dim*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.i3.fused.outer, ): range(min=0, ext=floordiv((((any_dim*any_dim)*any_dim)*any_dim), 512))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(blockIdx.x, , blockIdx.x): range(min=0, ext=floordiv(((any_dim*any_dim)*any_dim), 512))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused, ): range(min=0, ext=((any_dim*any_dim)*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i3, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.outer, ): range(min=0, ext=floordiv(((any_dim*any_dim)*any_dim), 512))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k, ): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i3, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.inner, ): range(min=0, ext=512)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(blockIdx.x, , blockIdx.x): range(min=0, ext=floordiv((((any_dim*any_dim)*any_dim)*any_dim), 512))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(threadIdx.x, , threadIdx.x): range(min=0, ext=512)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.i3.fused.inner, ): range(min=0, ext=512)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(threadIdx.x, , threadIdx.x): range(min=0, ext=512)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.i3.fused, ): range(min=0, ext=(((any_dim*any_dim)*any_dim)*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.i3.fused, ): range(min=0, ext=(((any_dim*any_dim)*any_dim)*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused, ): range(min=0, ext=(any_dim*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused, ): range(min=0, ext=((any_dim*any_dim)*any_dim))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.i3.fused.outer, ): range(min=0, ext=floordiv((((any_dim*any_dim)*any_dim)*any_dim), 512))
[10:53:55] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused.outer, ): range(min=0, ext=floordiv(((any_dim*any_dim)*any_dim), 512))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) == (512*floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512)))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) == (512*floordiv(((any_dim*any_dim_1)*any_dim_2), 512)))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) == (512*floordiv(((any_dim*any_dim_1)*any_dim_2), 512)))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) == (512*floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512)))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) == (512*floordiv(((any_dim*any_dim_1)*any_dim_2), 512)))
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) == (512*floordiv(((any_dim*any_dim_1)*any_dim_2), 512)))
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Buffer(T_softmax_maxelem_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2], [])] "realize_scope" = "";
  realize(T_softmax_maxelem, [0:any_dim, 0:any_dim_1, 0:any_dim_2], True {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod((threadIdx.x + (blockIdx.x*512)), any_dim_2)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod((threadIdx.x + (blockIdx.x*512)), any_dim_2)] = max(T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod((threadIdx.x + (blockIdx.x*512)), any_dim_2)], placeholder[floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod((threadIdx.x + (blockIdx.x*512)), any_dim_2), k])
      }
    }
    attr [T_softmax_exp: Buffer(T_softmax_exp_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [])] "realize_scope" = "";
    realize(T_softmax_exp, [0:any_dim, 0:any_dim_1, 0:any_dim_2, 0:any_dim_3], True {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), floormod((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3)] = @tir.exp((placeholder[floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), floormod((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3)] - T_softmax_maxelem[floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2)]), dtype=float32)
      attr [T_softmax_expsum: Buffer(T_softmax_expsum_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2], [])] "realize_scope" = "";
      realize(T_softmax_expsum, [0:any_dim, 0:any_dim_1, 0:any_dim_2], True {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2)] = (T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2)] + T_softmax_exp[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), k_1])
          }
        }
        attr [T_softmax_norm] "realize_scope" = "";
        realize(T_softmax_norm, [0:any_dim, 0:any_dim_1, 0:any_dim_2, 0:any_dim_3], True {
          attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
          attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
          T_softmax_norm[floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), floormod((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3)] = (T_softmax_exp[floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), floormod((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3)] / T_softmax_expsum[floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2)])
        })
      })
    })
  })
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (floormod(max((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*32), (((any_dim*any_dim_1)*any_dim_2)*32)), 32) == 0)
[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, any_dim_3) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:982: LOWER END

[10:53:55] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1157: CODEGEN START

[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VerifyMemory
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InferFragment
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerThreadAllreduce
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
    @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
      attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
        for (k: int32, 0, any_dim_3) {
          T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_3) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_1)) + (k*stride))])
        }
      }
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_3) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_2)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_1)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim*any_dim_1)*any_dim_2), 512);
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        for (k_1: int32, 0, any_dim_3) {
          T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
        }
      }
      attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512);
      attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_6)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_5)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_4))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.SplitHostDevice
primfn(T_softmax_maxelem: Pointer(float32), T_softmax_exp: Pointer(float32), any_dim: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = 0f32
    for (k: int32, 0, any_dim) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = ((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] + (float32*)T_softmax_exp[((((blockIdx.x*512) + threadIdx.x)*any_dim) + k)])
    }
  }
}

primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim_4: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_5: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_6: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_7: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_7 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_6 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_7, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_5 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_7*any_dim_6), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim_4 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_7*any_dim_6)*any_dim_5), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_7 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_6 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_7, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_5 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_7*any_dim_6), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim_4 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_7*any_dim_6)*any_dim_5), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim_4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_5 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_6 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_7 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
    @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem_1: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem_1, float32, [((any_dim_4*any_dim_5)*any_dim_6)]);
    attr [T_softmax_exp_1: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp_1, float32, [(((any_dim_4*any_dim_5)*any_dim_6)*any_dim_7)]) {
      @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem_1, placeholder, any_dim_7, any_dim_6, any_dim_5, stride_3, stride_2, stride_1, stride, floordiv(((any_dim_4*any_dim_5)*any_dim_6), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp_1, placeholder, T_softmax_maxelem_1, any_dim_7, any_dim_6, any_dim_5, stride_3, stride_2, stride_1, stride, floordiv((((any_dim_4*any_dim_5)*any_dim_6)*any_dim_7), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem_1, T_softmax_exp_1, any_dim_7, floordiv(((any_dim_4*any_dim_5)*any_dim_6), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm, T_softmax_exp_1, T_softmax_maxelem_1, any_dim_7, any_dim_6, any_dim_5, stride_7, stride_6, stride_5, stride_4, floordiv((((any_dim_4*any_dim_5)*any_dim_6)*any_dim_7), 512), 512, dtype=int32)
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_11: int32*any_dim_10)*any_dim_9), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem_2[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k_1: int32, 0, any_dim_8) {
      T_softmax_maxelem_2[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_9), any_dim_10)*stride_8) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_9), any_dim_10)*stride_9)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_9)*stride_10)) + (k_1*stride_11))])
    }
  }
}

primfn(T_softmax_exp_2: Pointer(float32), placeholder_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, stride_12: int32, stride_13: int32, stride_14: int32, stride_15: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_15: int32*any_dim_14)*any_dim_13)*any_dim_12), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_exp_2[((blockIdx.x_2*512) + threadIdx.x_2)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_12), any_dim_13), any_dim_14)*stride_12) + (floormod(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_12), any_dim_13), any_dim_14)*stride_13)) + (floormod(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_12), any_dim_13)*stride_14)) + (floormod(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_12)*stride_15))] - (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_12)]), dtype=float32)
}

primfn(T_softmax_norm_1: Pointer(float32), T_softmax_exp_3: Pointer(float32), T_softmax_maxelem_4: Pointer(float32), any_dim_16: int32, any_dim_17: int32, any_dim_18: int32, stride_16: int32, stride_17: int32, stride_18: int32, stride_19: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_19: int32*any_dim_18)*any_dim_17)*any_dim_16), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_norm_1[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_16), any_dim_17), any_dim_18)*stride_16) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_16), any_dim_17), any_dim_18)*stride_17)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_16), any_dim_17)*stride_18)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_16)*stride_19))] = ((float32*)T_softmax_exp_3[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_4[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_16)])
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
    @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem, placeholder, any_dim_3, any_dim_2, any_dim_1, stride_3, stride_2, stride_1, stride, floordiv(((any_dim*any_dim_1)*any_dim_2), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp, placeholder, T_softmax_maxelem, any_dim_3, any_dim_2, any_dim_1, stride_3, stride_2, stride_1, stride, floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem, T_softmax_exp, any_dim_3, floordiv(((any_dim*any_dim_1)*any_dim_2), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm, T_softmax_exp, T_softmax_maxelem, any_dim_3, any_dim_2, any_dim_1, stride_7, stride_6, stride_5, stride_4, floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512), 512, dtype=int32)
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
    @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem, placeholder, any_dim_3, any_dim_2, any_dim_1, stride_3, stride_2, stride_1, stride, floordiv(((any_dim*any_dim_1)*any_dim_2), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp, placeholder, T_softmax_maxelem, any_dim_3, any_dim_2, any_dim_1, stride_3, stride_2, stride_1, stride, floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem, T_softmax_exp, any_dim_3, floordiv(((any_dim*any_dim_1)*any_dim_2), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm, T_softmax_exp, T_softmax_maxelem, any_dim_3, any_dim_2, any_dim_1, stride_7, stride_6, stride_5, stride_4, floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512), 512, dtype=int32)
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 13, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 13, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, floordiv(((any_dim*any_dim_1)*any_dim_2), 512)), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, 512), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 11, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, floordiv(((any_dim*any_dim_1)*any_dim_2), 512)), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 512), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 5, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 13, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 13, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, floordiv(((any_dim*any_dim_1)*any_dim_2), 512)), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, 512), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 11, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, floordiv(((any_dim*any_dim_1)*any_dim_2), 512)), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 512), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 5, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, floordiv((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 512)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 13, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 13, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, @tir.shift_right(((any_dim*any_dim_1)*any_dim_2), 9, dtype=int32)), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, 512), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 11, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, @tir.shift_right(((any_dim*any_dim_1)*any_dim_2), 9, dtype=int32)), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 512), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 5, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 13, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 13, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, @tir.shift_right(((any_dim*any_dim_1)*any_dim_2), 9, dtype=int32)), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, 512), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 11, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, @tir.shift_right(((any_dim*any_dim_1)*any_dim_2), 9, dtype=int32)), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 512), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 5, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 13, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 13, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, @tir.shift_right(((any_dim*any_dim_1)*any_dim_2), 9, dtype=int32)), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, 512), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 11, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, @tir.shift_right(((any_dim*any_dim_1)*any_dim_2), 9, dtype=int32)), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 512), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 5, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[10:53:55] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(T_softmax_maxelem: Pointer(float32), T_softmax_exp: Pointer(float32), any_dim: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = 0f32
    for (k: int32, 0, any_dim) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = ((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] + (float32*)T_softmax_exp[((((blockIdx.x*512) + threadIdx.x)*any_dim) + k)])
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_7: int32*any_dim_6)*any_dim_5), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k_1: int32, 0, any_dim_4) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride_1)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5)*stride_2)) + (k_1*stride_3))])
    }
  }
}

primfn(T_softmax_exp_1: Pointer(float32), placeholder_1: Pointer(float32), T_softmax_maxelem_2: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_11: int32*any_dim_10)*any_dim_9)*any_dim_8), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_exp_1[((blockIdx.x_2*512) + threadIdx.x_2)] = @tir.exp(((float32*)placeholder_1[((((floordiv(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_5)) + (floormod(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9)*stride_6)) + (floormod(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)*stride_7))] - (float32*)T_softmax_maxelem_2[floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)]), dtype=float32)
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_15: int32*any_dim_14)*any_dim_13)*any_dim_12), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)])
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(T_softmax_maxelem: Pointer(float32), T_softmax_exp: Pointer(float32), any_dim: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = 0f32
    for (k: int32, 0, any_dim) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = ((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] + (float32*)T_softmax_exp[((((blockIdx.x*512) + threadIdx.x)*any_dim) + k)])
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_7: int32*any_dim_6)*any_dim_5), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k_1: int32, 0, any_dim_4) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride_1)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5)*stride_2)) + (k_1*stride_3))])
    }
  }
}

primfn(T_softmax_exp_1: Pointer(float32), placeholder_1: Pointer(float32), T_softmax_maxelem_2: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_11: int32*any_dim_10)*any_dim_9)*any_dim_8), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_exp_1[((blockIdx.x_2*512) + threadIdx.x_2)] = @tir.exp(((float32*)placeholder_1[((((floordiv(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_5)) + (floormod(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9)*stride_6)) + (floormod(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)*stride_7))] - (float32*)T_softmax_maxelem_2[floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)]), dtype=float32)
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_15: int32*any_dim_14)*any_dim_13)*any_dim_12), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)])
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerWarpMemory
primfn(T_softmax_maxelem: Pointer(float32), T_softmax_exp: Pointer(float32), any_dim: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = 0f32
    for (k: int32, 0, any_dim) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = ((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] + (float32*)T_softmax_exp[((((blockIdx.x*512) + threadIdx.x)*any_dim) + k)])
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_7: int32*any_dim_6)*any_dim_5), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k_1: int32, 0, any_dim_4) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride_1)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5)*stride_2)) + (k_1*stride_3))])
    }
  }
}

primfn(T_softmax_exp_1: Pointer(float32), placeholder_1: Pointer(float32), T_softmax_maxelem_2: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_11: int32*any_dim_10)*any_dim_9)*any_dim_8), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_exp_1[((blockIdx.x_2*512) + threadIdx.x_2)] = @tir.exp(((float32*)placeholder_1[((((floordiv(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_5)) + (floormod(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9)*stride_6)) + (floormod(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)*stride_7))] - (float32*)T_softmax_maxelem_2[floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)]), dtype=float32)
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_15: int32*any_dim_14)*any_dim_13)*any_dim_12), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)])
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(T_softmax_maxelem: Pointer(float32), T_softmax_exp: Pointer(float32), any_dim: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = 0f32
    for (k: int32, 0, any_dim) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = ((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] + (float32*)T_softmax_exp[((((blockIdx.x*512) + threadIdx.x)*any_dim) + k)])
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_7: int32*any_dim_6)*any_dim_5), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k_1: int32, 0, any_dim_4) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride_1)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5)*stride_2)) + (k_1*stride_3))])
    }
  }
}

primfn(T_softmax_exp_1: Pointer(float32), placeholder_1: Pointer(float32), T_softmax_maxelem_2: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_11: int32*any_dim_10)*any_dim_9)*any_dim_8), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_exp_1[((blockIdx.x_2*512) + threadIdx.x_2)] = @tir.exp(((float32*)placeholder_1[((((floordiv(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_5)) + (floormod(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9)*stride_6)) + (floormod(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)*stride_7))] - (float32*)T_softmax_maxelem_2[floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)]), dtype=float32)
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_15: int32*any_dim_14)*any_dim_13)*any_dim_12), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)])
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(T_softmax_maxelem: Pointer(float32), T_softmax_exp: Pointer(float32), any_dim: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = 0f32
    for (k: int32, 0, any_dim) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = ((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] + (float32*)T_softmax_exp[((((blockIdx.x*512) + threadIdx.x)*any_dim) + k)])
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((any_dim_7: int32*any_dim_6)*any_dim_5), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k_1: int32, 0, any_dim_4) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5), any_dim_6)*stride_1)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_5)*stride_2)) + (k_1*stride_3))])
    }
  }
}

primfn(T_softmax_exp_1: Pointer(float32), placeholder_1: Pointer(float32), T_softmax_maxelem_2: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_11: int32*any_dim_10)*any_dim_9)*any_dim_8), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_exp_1[((blockIdx.x_2*512) + threadIdx.x_2)] = @tir.exp(((float32*)placeholder_1[((((floordiv(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9), any_dim_10)*stride_5)) + (floormod(floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8), any_dim_9)*stride_6)) + (floormod(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)*stride_7))] - (float32*)T_softmax_maxelem_2[floordiv(((blockIdx.x_2*512) + threadIdx.x_2), any_dim_8)]), dtype=float32)
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_15: int32*any_dim_14)*any_dim_13)*any_dim_12), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13), any_dim_14)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12), any_dim_13)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_12)])
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(T_softmax_maxelem: Pointer(float32), T_softmax_exp: Pointer(float32), any_dim: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right(((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32), 9, dtype=int32);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = 0f32
    for (k: int32, 0, any_dim) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = ((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] + (float32*)T_softmax_exp[((((blockIdx.x*512) + threadIdx.x)*any_dim) + k)])
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right(((any_dim_7: int32*any_dim_6)*any_dim_5), 9, dtype=int32);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k_1: int32, 0, any_dim_4) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder[((((let rmod: int32 = (let rmod_1: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_5) in let rdiv: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_5) in select((((any_dim_5 >= 0) && (rmod_1 >= 0)) || ((any_dim_5 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) % any_dim_6) in let rdiv_1: int32 = (let rmod_1 = (((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_5) in let rdiv = (((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_5) in select((((any_dim_5 >= 0) && (rmod_1 >= 0)) || ((any_dim_5 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) / any_dim_6) in select((((any_dim_6 >= 0) && (rmod >= 0)) || ((any_dim_6 < 0) && (rmod <= 0))), rdiv_1, (rdiv_1 - 1))*stride) + (let rmod_2: int32 = (let rmod_3: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_5) in let rdiv_2: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_5) in select((((any_dim_5 >= 0) && (rmod_3 >= 0)) || ((any_dim_5 < 0) && (rmod_3 <= 0))), rdiv_2, (rdiv_2 - 1)) % any_dim_6) in select((((any_dim_6 >= 0) && (rmod_2 >= 0)) || ((any_dim_6 < 0) && (rmod_2 <= 0))), rmod_2, (rmod_2 + any_dim_6))*stride_1)) + (let rmod_4: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_5) in select((((any_dim_5 >= 0) && (rmod_4 >= 0)) || ((any_dim_5 < 0) && (rmod_4 <= 0))), rmod_4, (rmod_4 + any_dim_5))*stride_2)) + (k_1*stride_3))])
    }
  }
}

primfn(T_softmax_exp_1: Pointer(float32), placeholder_1: Pointer(float32), T_softmax_maxelem_2: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right((((any_dim_11: int32*any_dim_10)*any_dim_9)*any_dim_8), 9, dtype=int32);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_exp_1[((blockIdx.x_2*512) + threadIdx.x_2)] = @tir.call_pure_extern("__expf", ((float32*)placeholder_1[((((let rmod_5: int32 = (let rmod_6: int32 = (let rmod_7: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_3: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_7 >= 0)) || ((any_dim_8 < 0) && (rmod_7 <= 0))), rdiv_3, (rdiv_3 - 1)) % any_dim_9) in let rdiv_4: int32 = (let rmod_7 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_3 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_7 >= 0)) || ((any_dim_8 < 0) && (rmod_7 <= 0))), rdiv_3, (rdiv_3 - 1)) / any_dim_9) in select((((any_dim_9 >= 0) && (rmod_6 >= 0)) || ((any_dim_9 < 0) && (rmod_6 <= 0))), rdiv_4, (rdiv_4 - 1)) % any_dim_10) in let rdiv_5: int32 = (let rmod_6 = (let rmod_7 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_3 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_7 >= 0)) || ((any_dim_8 < 0) && (rmod_7 <= 0))), rdiv_3, (rdiv_3 - 1)) % any_dim_9) in let rdiv_4 = (let rmod_7 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_3 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_7 >= 0)) || ((any_dim_8 < 0) && (rmod_7 <= 0))), rdiv_3, (rdiv_3 - 1)) / any_dim_9) in select((((any_dim_9 >= 0) && (rmod_6 >= 0)) || ((any_dim_9 < 0) && (rmod_6 <= 0))), rdiv_4, (rdiv_4 - 1)) / any_dim_10) in select((((any_dim_10 >= 0) && (rmod_5 >= 0)) || ((any_dim_10 < 0) && (rmod_5 <= 0))), rdiv_5, (rdiv_5 - 1))*stride_4) + (let rmod_8: int32 = (let rmod_9: int32 = (let rmod_10: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_6: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_10 >= 0)) || ((any_dim_8 < 0) && (rmod_10 <= 0))), rdiv_6, (rdiv_6 - 1)) % any_dim_9) in let rdiv_7: int32 = (let rmod_10 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_6 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_10 >= 0)) || ((any_dim_8 < 0) && (rmod_10 <= 0))), rdiv_6, (rdiv_6 - 1)) / any_dim_9) in select((((any_dim_9 >= 0) && (rmod_9 >= 0)) || ((any_dim_9 < 0) && (rmod_9 <= 0))), rdiv_7, (rdiv_7 - 1)) % any_dim_10) in select((((any_dim_10 >= 0) && (rmod_8 >= 0)) || ((any_dim_10 < 0) && (rmod_8 <= 0))), rmod_8, (rmod_8 + any_dim_10))*stride_5)) + (let rmod_11: int32 = (let rmod_12: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_8: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_12 >= 0)) || ((any_dim_8 < 0) && (rmod_12 <= 0))), rdiv_8, (rdiv_8 - 1)) % any_dim_9) in select((((any_dim_9 >= 0) && (rmod_11 >= 0)) || ((any_dim_9 < 0) && (rmod_11 <= 0))), rmod_11, (rmod_11 + any_dim_9))*stride_6)) + (let rmod_13: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in select((((any_dim_8 >= 0) && (rmod_13 >= 0)) || ((any_dim_8 < 0) && (rmod_13 <= 0))), rmod_13, (rmod_13 + any_dim_8))*stride_7))] - (float32*)T_softmax_maxelem_2[let rmod_14: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_9: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_14 >= 0)) || ((any_dim_8 < 0) && (rmod_14 <= 0))), rdiv_9, (rdiv_9 - 1))]), dtype=float32)
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right((((any_dim_15: int32*any_dim_14)*any_dim_13)*any_dim_12), 9, dtype=int32);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_norm[((((let rmod_15: int32 = (let rmod_16: int32 = (let rmod_17: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_10: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_17 >= 0)) || ((any_dim_12 < 0) && (rmod_17 <= 0))), rdiv_10, (rdiv_10 - 1)) % any_dim_13) in let rdiv_11: int32 = (let rmod_17 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_10 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_17 >= 0)) || ((any_dim_12 < 0) && (rmod_17 <= 0))), rdiv_10, (rdiv_10 - 1)) / any_dim_13) in select((((any_dim_13 >= 0) && (rmod_16 >= 0)) || ((any_dim_13 < 0) && (rmod_16 <= 0))), rdiv_11, (rdiv_11 - 1)) % any_dim_14) in let rdiv_12: int32 = (let rmod_16 = (let rmod_17 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_10 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_17 >= 0)) || ((any_dim_12 < 0) && (rmod_17 <= 0))), rdiv_10, (rdiv_10 - 1)) % any_dim_13) in let rdiv_11 = (let rmod_17 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_10 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_17 >= 0)) || ((any_dim_12 < 0) && (rmod_17 <= 0))), rdiv_10, (rdiv_10 - 1)) / any_dim_13) in select((((any_dim_13 >= 0) && (rmod_16 >= 0)) || ((any_dim_13 < 0) && (rmod_16 <= 0))), rdiv_11, (rdiv_11 - 1)) / any_dim_14) in select((((any_dim_14 >= 0) && (rmod_15 >= 0)) || ((any_dim_14 < 0) && (rmod_15 <= 0))), rdiv_12, (rdiv_12 - 1))*stride_8) + (let rmod_18: int32 = (let rmod_19: int32 = (let rmod_20: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_13: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_20 >= 0)) || ((any_dim_12 < 0) && (rmod_20 <= 0))), rdiv_13, (rdiv_13 - 1)) % any_dim_13) in let rdiv_14: int32 = (let rmod_20 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_13 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_20 >= 0)) || ((any_dim_12 < 0) && (rmod_20 <= 0))), rdiv_13, (rdiv_13 - 1)) / any_dim_13) in select((((any_dim_13 >= 0) && (rmod_19 >= 0)) || ((any_dim_13 < 0) && (rmod_19 <= 0))), rdiv_14, (rdiv_14 - 1)) % any_dim_14) in select((((any_dim_14 >= 0) && (rmod_18 >= 0)) || ((any_dim_14 < 0) && (rmod_18 <= 0))), rmod_18, (rmod_18 + any_dim_14))*stride_9)) + (let rmod_21: int32 = (let rmod_22: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_15: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_22 >= 0)) || ((any_dim_12 < 0) && (rmod_22 <= 0))), rdiv_15, (rdiv_15 - 1)) % any_dim_13) in select((((any_dim_13 >= 0) && (rmod_21 >= 0)) || ((any_dim_13 < 0) && (rmod_21 <= 0))), rmod_21, (rmod_21 + any_dim_13))*stride_10)) + (let rmod_23: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in select((((any_dim_12 >= 0) && (rmod_23 >= 0)) || ((any_dim_12 < 0) && (rmod_23 <= 0))), rmod_23, (rmod_23 + any_dim_12))*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[let rmod_24: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_16: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_24 >= 0)) || ((any_dim_12 < 0) && (rmod_24 <= 0))), rdiv_16, (rdiv_16 - 1))])
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(T_softmax_maxelem: Pointer(float32), T_softmax_exp: Pointer(float32), any_dim: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right(((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32), 9, dtype=int32);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = 0f32
    for (k: int32, 0, any_dim) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = ((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] + (float32*)T_softmax_exp[((((blockIdx.x*512) + threadIdx.x)*any_dim) + k)])
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right(((any_dim_7: int32*any_dim_6)*any_dim_5), 9, dtype=int32);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k_1: int32, 0, any_dim_4) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder[((((let rmod: int32 = (let rmod_1: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_5) in let rdiv: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_5) in select((((any_dim_5 >= 0) && (rmod_1 >= 0)) || ((any_dim_5 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) % any_dim_6) in let rdiv_1: int32 = (let rmod_1 = (((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_5) in let rdiv = (((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_5) in select((((any_dim_5 >= 0) && (rmod_1 >= 0)) || ((any_dim_5 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) / any_dim_6) in select((((any_dim_6 >= 0) && (rmod >= 0)) || ((any_dim_6 < 0) && (rmod <= 0))), rdiv_1, (rdiv_1 - 1))*stride) + (let rmod_2: int32 = (let rmod_3: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_5) in let rdiv_2: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_5) in select((((any_dim_5 >= 0) && (rmod_3 >= 0)) || ((any_dim_5 < 0) && (rmod_3 <= 0))), rdiv_2, (rdiv_2 - 1)) % any_dim_6) in select((((any_dim_6 >= 0) && (rmod_2 >= 0)) || ((any_dim_6 < 0) && (rmod_2 <= 0))), rmod_2, (rmod_2 + any_dim_6))*stride_1)) + (let rmod_4: int32 = (((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_5) in select((((any_dim_5 >= 0) && (rmod_4 >= 0)) || ((any_dim_5 < 0) && (rmod_4 <= 0))), rmod_4, (rmod_4 + any_dim_5))*stride_2)) + (k_1*stride_3))])
    }
  }
}

primfn(T_softmax_exp_1: Pointer(float32), placeholder_1: Pointer(float32), T_softmax_maxelem_2: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right((((any_dim_11: int32*any_dim_10)*any_dim_9)*any_dim_8), 9, dtype=int32);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_exp_1[((blockIdx.x_2*512) + threadIdx.x_2)] = @tir.call_pure_extern("__expf", ((float32*)placeholder_1[((((let rmod_5: int32 = (let rmod_6: int32 = (let rmod_7: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_3: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_7 >= 0)) || ((any_dim_8 < 0) && (rmod_7 <= 0))), rdiv_3, (rdiv_3 - 1)) % any_dim_9) in let rdiv_4: int32 = (let rmod_7 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_3 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_7 >= 0)) || ((any_dim_8 < 0) && (rmod_7 <= 0))), rdiv_3, (rdiv_3 - 1)) / any_dim_9) in select((((any_dim_9 >= 0) && (rmod_6 >= 0)) || ((any_dim_9 < 0) && (rmod_6 <= 0))), rdiv_4, (rdiv_4 - 1)) % any_dim_10) in let rdiv_5: int32 = (let rmod_6 = (let rmod_7 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_3 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_7 >= 0)) || ((any_dim_8 < 0) && (rmod_7 <= 0))), rdiv_3, (rdiv_3 - 1)) % any_dim_9) in let rdiv_4 = (let rmod_7 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_3 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_7 >= 0)) || ((any_dim_8 < 0) && (rmod_7 <= 0))), rdiv_3, (rdiv_3 - 1)) / any_dim_9) in select((((any_dim_9 >= 0) && (rmod_6 >= 0)) || ((any_dim_9 < 0) && (rmod_6 <= 0))), rdiv_4, (rdiv_4 - 1)) / any_dim_10) in select((((any_dim_10 >= 0) && (rmod_5 >= 0)) || ((any_dim_10 < 0) && (rmod_5 <= 0))), rdiv_5, (rdiv_5 - 1))*stride_4) + (let rmod_8: int32 = (let rmod_9: int32 = (let rmod_10: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_6: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_10 >= 0)) || ((any_dim_8 < 0) && (rmod_10 <= 0))), rdiv_6, (rdiv_6 - 1)) % any_dim_9) in let rdiv_7: int32 = (let rmod_10 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_6 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_10 >= 0)) || ((any_dim_8 < 0) && (rmod_10 <= 0))), rdiv_6, (rdiv_6 - 1)) / any_dim_9) in select((((any_dim_9 >= 0) && (rmod_9 >= 0)) || ((any_dim_9 < 0) && (rmod_9 <= 0))), rdiv_7, (rdiv_7 - 1)) % any_dim_10) in select((((any_dim_10 >= 0) && (rmod_8 >= 0)) || ((any_dim_10 < 0) && (rmod_8 <= 0))), rmod_8, (rmod_8 + any_dim_10))*stride_5)) + (let rmod_11: int32 = (let rmod_12: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_8: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_12 >= 0)) || ((any_dim_8 < 0) && (rmod_12 <= 0))), rdiv_8, (rdiv_8 - 1)) % any_dim_9) in select((((any_dim_9 >= 0) && (rmod_11 >= 0)) || ((any_dim_9 < 0) && (rmod_11 <= 0))), rmod_11, (rmod_11 + any_dim_9))*stride_6)) + (let rmod_13: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in select((((any_dim_8 >= 0) && (rmod_13 >= 0)) || ((any_dim_8 < 0) && (rmod_13 <= 0))), rmod_13, (rmod_13 + any_dim_8))*stride_7))] - (float32*)T_softmax_maxelem_2[let rmod_14: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) % any_dim_8) in let rdiv_9: int32 = (((blockIdx.x_2*512) + threadIdx.x_2) / any_dim_8) in select((((any_dim_8 >= 0) && (rmod_14 >= 0)) || ((any_dim_8 < 0) && (rmod_14 <= 0))), rdiv_9, (rdiv_9 - 1))]), dtype=float32)
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right((((any_dim_15: int32*any_dim_14)*any_dim_13)*any_dim_12), 9, dtype=int32);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  T_softmax_norm[((((let rmod_15: int32 = (let rmod_16: int32 = (let rmod_17: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_10: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_17 >= 0)) || ((any_dim_12 < 0) && (rmod_17 <= 0))), rdiv_10, (rdiv_10 - 1)) % any_dim_13) in let rdiv_11: int32 = (let rmod_17 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_10 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_17 >= 0)) || ((any_dim_12 < 0) && (rmod_17 <= 0))), rdiv_10, (rdiv_10 - 1)) / any_dim_13) in select((((any_dim_13 >= 0) && (rmod_16 >= 0)) || ((any_dim_13 < 0) && (rmod_16 <= 0))), rdiv_11, (rdiv_11 - 1)) % any_dim_14) in let rdiv_12: int32 = (let rmod_16 = (let rmod_17 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_10 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_17 >= 0)) || ((any_dim_12 < 0) && (rmod_17 <= 0))), rdiv_10, (rdiv_10 - 1)) % any_dim_13) in let rdiv_11 = (let rmod_17 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_10 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_17 >= 0)) || ((any_dim_12 < 0) && (rmod_17 <= 0))), rdiv_10, (rdiv_10 - 1)) / any_dim_13) in select((((any_dim_13 >= 0) && (rmod_16 >= 0)) || ((any_dim_13 < 0) && (rmod_16 <= 0))), rdiv_11, (rdiv_11 - 1)) / any_dim_14) in select((((any_dim_14 >= 0) && (rmod_15 >= 0)) || ((any_dim_14 < 0) && (rmod_15 <= 0))), rdiv_12, (rdiv_12 - 1))*stride_8) + (let rmod_18: int32 = (let rmod_19: int32 = (let rmod_20: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_13: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_20 >= 0)) || ((any_dim_12 < 0) && (rmod_20 <= 0))), rdiv_13, (rdiv_13 - 1)) % any_dim_13) in let rdiv_14: int32 = (let rmod_20 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_13 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_20 >= 0)) || ((any_dim_12 < 0) && (rmod_20 <= 0))), rdiv_13, (rdiv_13 - 1)) / any_dim_13) in select((((any_dim_13 >= 0) && (rmod_19 >= 0)) || ((any_dim_13 < 0) && (rmod_19 <= 0))), rdiv_14, (rdiv_14 - 1)) % any_dim_14) in select((((any_dim_14 >= 0) && (rmod_18 >= 0)) || ((any_dim_14 < 0) && (rmod_18 <= 0))), rmod_18, (rmod_18 + any_dim_14))*stride_9)) + (let rmod_21: int32 = (let rmod_22: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_15: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_22 >= 0)) || ((any_dim_12 < 0) && (rmod_22 <= 0))), rdiv_15, (rdiv_15 - 1)) % any_dim_13) in select((((any_dim_13 >= 0) && (rmod_21 >= 0)) || ((any_dim_13 < 0) && (rmod_21 <= 0))), rmod_21, (rmod_21 + any_dim_13))*stride_10)) + (let rmod_23: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in select((((any_dim_12 >= 0) && (rmod_23 >= 0)) || ((any_dim_12 < 0) && (rmod_23 <= 0))), rmod_23, (rmod_23 + any_dim_12))*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[let rmod_24: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_12) in let rdiv_16: int32 = (((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_12) in select((((any_dim_12 >= 0) && (rmod_24 >= 0)) || ((any_dim_12 < 0) && (rmod_24 <= 0))), rdiv_16, (rdiv_16 - 1))])
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VerifyMemory
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InferFragment
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerThreadAllreduce
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_prod: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_1[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_1[k0])
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_multiply: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(int64) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter

[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget

[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerWarpMemory

[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify

[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes

[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin

[10:53:56] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo

[10:53:56] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1205: CODEGEN END

Raw module: 
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

Running on (cuda, cuda(0))
Finish in 0.55790 ms
