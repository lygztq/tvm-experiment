[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:916: LOWER START

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass RemoveUnusedFunctions
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToBasicBlockNormalForm
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass sequential
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass EtaExpand
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x)
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass SimplifyInference
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass SimplifyExpr
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Inline
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass DeadCodeElimination
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlinePrimitives
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldScaleAxis
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToANormalForm
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2 = %x1(%x);
  %x2
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2: Tensor[(?, ?, ?, ?), float32] = %x1(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x2
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass LambdaLift
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2: Tensor[(?, ?, ?, ?), float32] = %x1(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x2
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Inline
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = %0;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %0(%x);
  %x2
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass DeadCodeElimination
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlinePrimitives
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlineGlobals
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass RemoveUnusedFunctions
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[10:58:07] /workspace/home/codes/tvm/src/driver/driver_api.cc:139: LOWER INFERBOUND BEFORE
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, ): range(min=0, ext=4)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=4)): range(min=0, ext=4)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/driver/driver_api.cc:149: Func before opt
[10:58:07] /workspace/home/codes/tvm/src/driver/driver_api.cc:150: primfn(placeholder_1: handle, compute_1: handle) -> ()
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = add(32 /* ty=int64 */, 7 /* ty=int64 */) /* ty=int64 */;
  %4 = prod(%shape_func_out_0) /* ty=int64 */;
  %5 = divide(%3, 8 /* ty=int64 */) /* ty=int64 */;
  %6 = multiply(%4, %5) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%6, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %7 = (%x,);
  %8 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %7, %8) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main() -> int64 {
  %0 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  %0(32 /* ty=int64 */, 7 /* ty=int64 */) /* ty=int64 */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToANormalForm
type Storage {
  
}

def @main() -> int64 {
  let %x = 32 /* ty=int64 */;
  let %x1 = 7 /* ty=int64 */;
  let %x2 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3 = %x2(%x, %x1);
  %x3
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass EtaExpand
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1)
  };
  let %x3: int64 = %x2(%x, %x1);
  %x3
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [T_add] "realize_scope" = "";
  realize(T_add, [], True {
    T_add[] = (placeholder[] + placeholder_1[])
  })
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerReduction
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.PlanAndUpdateBufferAllocationLocation
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ConvertBlocksToOpaque
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CompactBufferAllocation
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.FlattenBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VerifyMemory
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Apply
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InferFragment
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerThreadAllreduce
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerWarpMemory

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Apply
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main() -> int64 {
  %0 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  %0(39 /* ty=int64 */, 8 /* ty=int64 */) /* ty=int64 */
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToANormalForm
type Storage {
  
}

def @main() -> int64 {
  let %x = 39 /* ty=int64 */;
  let %x1 = 8 /* ty=int64 */;
  let %x2 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3 = %x2(%x, %x1);
  %x3
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass EtaExpand
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1)
  };
  let %x3: int64 = %x2(%x, %x1);
  %x3
}

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  attr [T_divide] "realize_scope" = "";
  realize(T_divide, [], True {
    T_divide[] = (placeholder[] / placeholder_1[])
  })
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerReduction
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.PlanAndUpdateBufferAllocationLocation
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ConvertBlocksToOpaque
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CompactBufferAllocation
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.FlattenBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VerifyMemory
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Apply
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InferFragment
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerThreadAllreduce
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerWarpMemory

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Apply
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = prod(%shape_func_out_0) /* ty=int64 */;
  %4 = multiply(%3, 4 /* ty=int64 */) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%4, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %5 = (%x,);
  %6 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %5, %6) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = fn (%p02: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p02) /* ty=int64 */
  };
  %4 = %3(%shape_func_out_0) /* ty=int64 */;
  %5 = fn (%p01: int64, Primitive=1) -> int64 {
    multiply(%p01, 4 /* ty=int64 */) /* ty=int64 */
  };
  %6 = %5(%4) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%6, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %7 = (%x,);
  %8 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %7, %8) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass sequential
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass LabelOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32], hash="bf0e3f1e7c8a698e") -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1, hash="e2782cdc77404249") -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1, hash="75ec56f3169a1497") -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1, hash="e2e2680f0ff08f46") -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[10:58:07] /workspace/home/codes/tvm/src/driver/driver_api.cc:139: LOWER INFERBOUND BEFORE
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, ): range(min=0, ext=4)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=4)): range(min=0, ext=4)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/driver/driver_api.cc:149: Func before opt
[10:58:07] /workspace/home/codes/tvm/src/driver/driver_api.cc:150: primfn(placeholder_1: handle, compute_1: handle) -> ()
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(4), int64], Primitive=1, hash="75ec56f3169a1497") -> int64 {
  prod(%p0) /* ty=int64 */
}
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k0, ): range(min=0, ext=4)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k0, range(min=0, ext=4)): range(min=0, ext=4)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(singleton, range(min=0, ext=1)): range(min=0, ext=1)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  attr [placeholder_red] "realize_scope" = "";
  realize(placeholder_red, [], True {
    placeholder_red[] = 1i64
    for (k0: int32, 0, 4) {
      placeholder_red[] = (placeholder_red[]*placeholder[k0])
    }
  })
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: int64, Primitive=1, hash="e2e2680f0ff08f46") -> int64 {
  multiply(%p0, 4 /* ty=int64 */) /* ty=int64 */
}
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  attr [T_multiply] "realize_scope" = "";
  realize(T_multiply, [], True {
    T_multiply[] = (placeholder[]*4i64)
  })
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1, hash="e2782cdc77404249") -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
}
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:767: POS1
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (0 >= floordiv(floordiv(i0.i1.fused.i2.fused: int32, any_dim: int32), any_dim_1: int32))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= floordiv(floordiv(i0.i1.fused.i2.fused: int32, any_dim_1: int32), any_dim_2: int32))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (0 >= floormod(floordiv(i0.i1.fused.i2.fused: int32, any_dim: int32), any_dim_1: int32))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= floormod(floordiv(i0.i1.fused.i2.fused: int32, any_dim_1: int32), any_dim))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (0 >= floormod(i0.i1.fused.i2.fused: int32, any_dim: int32))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= floormod(i0.i1.fused.i2.fused: int32, any_dim))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (0 >= floordiv(floordiv(i0.i1.fused.i2.fused: int32, any_dim: int32), any_dim_1: int32))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= floordiv(floordiv(i0.i1.fused.i2.fused: int32, any_dim_1: int32), any_dim_2: int32))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (0 >= floormod(floordiv(i0.i1.fused.i2.fused: int32, any_dim: int32), any_dim_1: int32))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= floormod(floordiv(i0.i1.fused.i2.fused: int32, any_dim_1: int32), any_dim))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (0 >= floormod(i0.i1.fused.i2.fused: int32, any_dim: int32))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= floormod(i0.i1.fused.i2.fused: int32, any_dim))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove ((any_dim: int32 - 1) <= (any_dim - 1))
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i3, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i3, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i3, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused, ): range(min=0, ext=(any_dim*any_dim))
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(k, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0.i1.fused.i2.fused, ): range(min=0, ext=((any_dim*any_dim)*any_dim))
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i1, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i0, range(min=0, ext=any_dim)): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i2, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/te/schedule/bound.cc:256: iter_var(i3, ): range(min=0, ext=any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove True
[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (any_dim: int32 == any_dim)
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_norm] "realize_scope" = "";
  realize(T_softmax_norm, [0:any_dim, 0:any_dim_1, 0:any_dim_2, 0:any_dim_3], True {
    for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
      attr [T_softmax_maxelem: Buffer(T_softmax_maxelem_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2], [])] "realize_scope" = "";
      realize(T_softmax_maxelem, [0:any_dim, 0:any_dim_1, 0:any_dim_2], True {
        for (i0: int32, 0, any_dim) {
          for (i1: int32, 0, any_dim_1) {
            for (i2: int32, 0, any_dim_2) {
              T_softmax_maxelem[i0, i1, i2] = -3.40282e+38f32
              for (k: int32, 0, any_dim_3) {
                T_softmax_maxelem[i0, i1, i2] = max(T_softmax_maxelem[i0, i1, i2], placeholder[i0, i1, i2, k])
              }
            }
          }
        }
        attr [T_softmax_exp: Buffer(T_softmax_exp_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [])] "realize_scope" = "";
        realize(T_softmax_exp, [0:any_dim, 0:any_dim_1, 0:any_dim_2, 0:any_dim_3], True {
          for (i0_1: int32, 0, any_dim) {
            for (i1_1: int32, 0, any_dim_1) {
              for (i2_1: int32, 0, any_dim_2) {
                for (i3: int32, 0, any_dim_3) {
                  T_softmax_exp[i0_1, i1_1, i2_1, i3] = @tir.exp((placeholder[i0_1, i1_1, i2_1, i3] - T_softmax_maxelem[i0_1, i1_1, i2_1]), dtype=float32)
                }
              }
            }
          }
          attr [T_softmax_expsum: Buffer(T_softmax_expsum_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2], [])] "realize_scope" = "";
          realize(T_softmax_expsum, [0:any_dim, 0:any_dim_1, 0:any_dim_2], True {
            for (i0_2: int32, 0, any_dim) {
              for (i1_2: int32, 0, any_dim_1) {
                for (i2_2: int32, 0, any_dim_2) {
                  T_softmax_expsum[i0_2, i1_2, i2_2] = 0f32
                  for (k_1: int32, 0, any_dim_3) {
                    T_softmax_expsum[i0_2, i1_2, i2_2] = (T_softmax_expsum[i0_2, i1_2, i2_2] + T_softmax_exp[i0_2, i1_2, i2_2, k_1])
                  }
                }
              }
            }
            for (i3_1: int32, 0, any_dim_3) {
              T_softmax_norm[floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1), floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1), floormod(i0.i1.fused.i2.fused, any_dim_2), i3_1] = (T_softmax_exp[floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1), floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1), floormod(i0.i1.fused.i2.fused, any_dim_2), i3_1] / T_softmax_expsum[floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1), floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1), floormod(i0.i1.fused.i2.fused, any_dim_2)])
            }
          })
        })
      })
    }
  })
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
        attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_expsum[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_expsum[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/arith/analyzer.cc:139: Res = true when prove (floormod(max((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*32), (((any_dim*any_dim_1)*any_dim_2)*32)), 32) == 0)
[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
       {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
         {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
       {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
         {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
       {
        for (i0_1: int32, 0, any_dim) {
          for (i1_1: int32, 0, any_dim_1) {
            for (i2_1: int32, 0, any_dim_2) {
              for (i3: int32, 0, any_dim_3) {
                T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
              }
            }
          }
        }
         {
          for (i0_2: int32, 0, any_dim) {
            for (i1_2: int32, 0, any_dim_1) {
              for (i2_2: int32, 0, any_dim_2) {
                T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                for (k_1: int32, 0, any_dim_3) {
                  T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
          for (i3_1: int32, 0, any_dim_3) {
            T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
          }
        }
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_1: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_1: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_1: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_1*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_2*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/relay/backend/compile_engine.cc:778: POS4
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:982: LOWER END

[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1157: CODEGEN START

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}

primfn(placeholder_10: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder_9: Buffer(placeholder_11: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_10: placeholder_9, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_11[((((i0_1*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_11[((((i0_2*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VerifyMemory
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}

primfn(placeholder_10: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder_9: Buffer(placeholder_11: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_10: placeholder_9, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_11[((((i0_1*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_11[((((i0_2*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}

primfn(placeholder_10: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder_9: Buffer(placeholder_11: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_10: placeholder_9, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_11[((((i0_1*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_11[((((i0_2*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}

primfn(placeholder_10: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder_9: Buffer(placeholder_11: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_10: placeholder_9, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_11[((((i0_1*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_11[((((i0_2*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InferFragment
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}

primfn(placeholder_10: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder_9: Buffer(placeholder_11: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_10: placeholder_9, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_11[((((i0_1*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_11[((((i0_2*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerThreadAllreduce
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}

primfn(placeholder_4: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder_3: Buffer(placeholder_5: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_4: placeholder_3, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_5[k0])
  }
}

primfn(placeholder_7: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder_6: Buffer(placeholder_8: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_7: placeholder_6, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_8[0]*4i64)
}

primfn(placeholder_10: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder_9: Buffer(placeholder_11: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_10: placeholder_9, T_softmax_norm_1: T_softmax_norm} {
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_11[((((i0_1*stride_4) + (i1*stride_5)) + (i2*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_11[((((i0_2*stride_4) + (i1_1*stride_5)) + (i2_1*stride_6)) + (i3*stride_7))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm_2[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_1)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_2)) + (i3_1*stride_3))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 1;
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_6)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_3;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 1;
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_6)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_3;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 1;
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_6)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_3;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 1;
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      for (i0_1: int32, 0, any_dim) {
        for (i1: int32, 0, any_dim_1) {
          for (i2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
            for (k: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
            }
          }
        }
      }
      for (i0_2: int32, 0, any_dim) {
        for (i1_1: int32, 0, any_dim_1) {
          for (i2_1: int32, 0, any_dim_2) {
            for (i3: int32, 0, any_dim_3) {
              T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
            }
          }
        }
      }
      for (i0_3: int32, 0, any_dim) {
        for (i1_2: int32, 0, any_dim_1) {
          for (i2_2: int32, 0, any_dim_2) {
            T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
            for (k_1: int32, 0, any_dim_3) {
              T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
            }
          }
        }
      }
      for (i3_1: int32, 0, any_dim_3) {
        T_softmax_norm[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_6)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_3;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
              for (i0_1: int32, 0, any_dim) {
                for (i1: int32, 0, any_dim_1) {
                  for (i2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
                    for (k: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
                    }
                  }
                }
              }
              for (i0_2: int32, 0, any_dim) {
                for (i1_1: int32, 0, any_dim_1) {
                  for (i2_1: int32, 0, any_dim_2) {
                    for (i3: int32, 0, any_dim_3) {
                      T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
                    }
                  }
                }
              }
              for (i0_3: int32, 0, any_dim) {
                for (i1_2: int32, 0, any_dim_1) {
                  for (i2_2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                    for (k_1: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                    }
                  }
                }
              }
              for (i3_1: int32, 0, any_dim_3) {
                T_softmax_norm[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_6)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
              for (i0_1: int32, 0, any_dim) {
                for (i1: int32, 0, any_dim_1) {
                  for (i2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
                    for (k: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
                    }
                  }
                }
              }
              for (i0_2: int32, 0, any_dim) {
                for (i1_1: int32, 0, any_dim_1) {
                  for (i2_1: int32, 0, any_dim_2) {
                    for (i3: int32, 0, any_dim_3) {
                      T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.exp(((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
                    }
                  }
                }
              }
              for (i0_3: int32, 0, any_dim) {
                for (i1_2: int32, 0, any_dim_1) {
                  for (i2_2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                    for (k_1: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                    }
                  }
                }
              }
              for (i3_1: int32, 0, any_dim_3) {
                T_softmax_norm[((((floordiv(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(i0.i1.fused.i2.fused, any_dim_2), any_dim_1)*stride_6)) + (floormod(i0.i1.fused.i2.fused, any_dim_2)*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
              for (i0_1: int32, 0, any_dim) {
                for (i1: int32, 0, any_dim_1) {
                  for (i2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
                    for (k: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
                    }
                  }
                }
              }
              for (i0_2: int32, 0, any_dim) {
                for (i1_1: int32, 0, any_dim_1) {
                  for (i2_1: int32, 0, any_dim_2) {
                    for (i3: int32, 0, any_dim_3) {
                      T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.call_llvm_pure_intrin(54u32, 1u32, ((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
                    }
                  }
                }
              }
              for (i0_3: int32, 0, any_dim) {
                for (i1_2: int32, 0, any_dim_1) {
                  for (i2_2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                    for (k_1: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                    }
                  }
                }
              }
              for (i3_1: int32, 0, any_dim_3) {
                T_softmax_norm[((((let rmod: int32 = (let rmod_1: int32 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv: int32 = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_1 >= 0)) || ((any_dim_2 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) % any_dim_1) in let rdiv_1: int32 = (let rmod_1 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_1 >= 0)) || ((any_dim_2 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) / any_dim_1) in select((((any_dim_1 >= 0) && (rmod >= 0)) || ((any_dim_1 < 0) && (rmod <= 0))), rdiv_1, (rdiv_1 - 1))*stride_7) + (let rmod_2: int32 = (let rmod_3: int32 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv_2: int32 = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_3 >= 0)) || ((any_dim_2 < 0) && (rmod_3 <= 0))), rdiv_2, (rdiv_2 - 1)) % any_dim_1) in select((((any_dim_1 >= 0) && (rmod_2 >= 0)) || ((any_dim_1 < 0) && (rmod_2 <= 0))), rmod_2, (rmod_2 + any_dim_1))*stride_6)) + (let rmod_4: int32 = (i0.i1.fused.i2.fused % any_dim_2) in select((((any_dim_2 >= 0) && (rmod_4 >= 0)) || ((any_dim_2 < 0) && (rmod_4 <= 0))), rmod_4, (rmod_4 + any_dim_2))*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
              for (i0_1: int32, 0, any_dim) {
                for (i1: int32, 0, any_dim_1) {
                  for (i2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
                    for (k: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
                    }
                  }
                }
              }
              for (i0_2: int32, 0, any_dim) {
                for (i1_1: int32, 0, any_dim_1) {
                  for (i2_1: int32, 0, any_dim_2) {
                    for (i3: int32, 0, any_dim_3) {
                      T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.call_llvm_pure_intrin(54u32, 1u32, ((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
                    }
                  }
                }
              }
              for (i0_3: int32, 0, any_dim) {
                for (i1_2: int32, 0, any_dim_1) {
                  for (i2_2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                    for (k_1: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                    }
                  }
                }
              }
              for (i3_1: int32, 0, any_dim_3) {
                T_softmax_norm[((((let rmod: int32 = (let rmod_1: int32 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv: int32 = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_1 >= 0)) || ((any_dim_2 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) % any_dim_1) in let rdiv_1: int32 = (let rmod_1 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_1 >= 0)) || ((any_dim_2 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) / any_dim_1) in select((((any_dim_1 >= 0) && (rmod >= 0)) || ((any_dim_1 < 0) && (rmod <= 0))), rdiv_1, (rdiv_1 - 1))*stride_7) + (let rmod_2: int32 = (let rmod_3: int32 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv_2: int32 = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_3 >= 0)) || ((any_dim_2 < 0) && (rmod_3 <= 0))), rdiv_2, (rdiv_2 - 1)) % any_dim_1) in select((((any_dim_1 >= 0) && (rmod_2 >= 0)) || ((any_dim_1 < 0) && (rmod_2 <= 0))), rmod_2, (rmod_2 + any_dim_1))*stride_6)) + (let rmod_4: int32 = (i0.i1.fused.i2.fused % any_dim_2) in select((((any_dim_2 >= 0) && (rmod_4 >= 0)) || ((any_dim_2 < 0) && (rmod_4 <= 0))), rmod_4, (rmod_4 + any_dim_2))*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args_1 == 2), "fused_multiply: num_args should be 2")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder_1[0]*4i64)
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_2 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape_2[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape_2[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape_2[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape_2[3])
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), 1, cast(int32, (int64*)arg0.strides_2[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides_2[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides_2[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides_2[0]), dtype=int32), dtype=int32)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), 1, cast(int32, (int64*)arg1.strides_2[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides_2[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides_2[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides_2, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides_2[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (any_dim == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (any_dim == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape_2[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (any_dim == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape_2[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (any_dim == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_nn_softmax_compute_";
  for (i0.i1.fused.i2.fused: int32, 0, ((any_dim*any_dim_1)*any_dim_2)) "parallel" {
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(1, dev_id_2, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
              for (i0_1: int32, 0, any_dim) {
                for (i1: int32, 0, any_dim_1) {
                  for (i2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = -3.40282e+38f32
                    for (k: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)] = max((float32*)T_softmax_maxelem[((((i0_1*any_dim_1) + i1)*any_dim_2) + i2)], (float32*)placeholder_2[((((i0_1*stride_3) + (i1*stride_2)) + (i2*stride_1)) + (k*stride))])
                    }
                  }
                }
              }
              for (i0_2: int32, 0, any_dim) {
                for (i1_1: int32, 0, any_dim_1) {
                  for (i2_1: int32, 0, any_dim_2) {
                    for (i3: int32, 0, any_dim_3) {
                      T_softmax_exp[((((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)*any_dim_3) + i3)] = @tir.call_llvm_pure_intrin(54u32, 1u32, ((float32*)placeholder_2[((((i0_2*stride_3) + (i1_1*stride_2)) + (i2_1*stride_1)) + (i3*stride))] - (float32*)T_softmax_maxelem[((((i0_2*any_dim_1) + i1_1)*any_dim_2) + i2_1)]), dtype=float32)
                    }
                  }
                }
              }
              for (i0_3: int32, 0, any_dim) {
                for (i1_2: int32, 0, any_dim_1) {
                  for (i2_2: int32, 0, any_dim_2) {
                    T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = 0f32
                    for (k_1: int32, 0, any_dim_3) {
                      T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] = ((float32*)T_softmax_maxelem[((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)] + (float32*)T_softmax_exp[((((((i0_3*any_dim_1) + i1_2)*any_dim_2) + i2_2)*any_dim_3) + k_1)])
                    }
                  }
                }
              }
              for (i3_1: int32, 0, any_dim_3) {
                T_softmax_norm[((((let rmod: int32 = (let rmod_1: int32 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv: int32 = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_1 >= 0)) || ((any_dim_2 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) % any_dim_1) in let rdiv_1: int32 = (let rmod_1 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_1 >= 0)) || ((any_dim_2 < 0) && (rmod_1 <= 0))), rdiv, (rdiv - 1)) / any_dim_1) in select((((any_dim_1 >= 0) && (rmod >= 0)) || ((any_dim_1 < 0) && (rmod <= 0))), rdiv_1, (rdiv_1 - 1))*stride_7) + (let rmod_2: int32 = (let rmod_3: int32 = (i0.i1.fused.i2.fused % any_dim_2) in let rdiv_2: int32 = (i0.i1.fused.i2.fused / any_dim_2) in select((((any_dim_2 >= 0) && (rmod_3 >= 0)) || ((any_dim_2 < 0) && (rmod_3 <= 0))), rdiv_2, (rdiv_2 - 1)) % any_dim_1) in select((((any_dim_1 >= 0) && (rmod_2 >= 0)) || ((any_dim_1 < 0) && (rmod_2 <= 0))), rmod_2, (rmod_2 + any_dim_1))*stride_6)) + (let rmod_4: int32 = (i0.i1.fused.i2.fused % any_dim_2) in select((((any_dim_2 >= 0) && (rmod_4 >= 0)) || ((any_dim_2 < 0) && (rmod_4 <= 0))), rmod_4, (rmod_4 + any_dim_2))*stride_5)) + (i3_1*stride_4))] = ((float32*)T_softmax_exp[((i0.i1.fused.i2.fused*any_dim_3) + i3_1)] / (float32*)T_softmax_maxelem[i0.i1.fused.i2.fused])
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(1, dev_id_2, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_prod: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_3: Pointer(int64) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides_3[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder_3[k0])
      }
    }
  }
}


[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerWarpMemory

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin

[10:58:07] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo

[10:58:07] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1205: CODEGEN END

Raw module: 
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

Running on (llvm, cpu(0))
Finish in 0.58460 ms
