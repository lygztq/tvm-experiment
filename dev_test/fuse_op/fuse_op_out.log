[11:43:30] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:916: LOWER START

[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass RemoveUnusedFunctions
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) {
  %0 = reshape(%input, newshape=[-3, 768]);
  %1 = nn.dense(%0, %w_k, units=768);
  %2 = nn.bias_add(%1, %b_k);
  %3 = reshape(%2, newshape=[16, 128, 12, 64]);
  %4 = transpose(%3, axes=[0, 2, 1, 3]);
  %5 = nn.dense(%0, %w_q, units=768);
  %6 = nn.bias_add(%5, %b_q);
  %7 = reshape(%6, newshape=[16, 128, 12, 64]);
  %8 = transpose(%7, axes=[0, 2, 1, 3]);
  %9 = reshape(%4, newshape=[-3, -1, 64]);
  %10 = reshape(%8, newshape=[-3, -1, 64]);
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]);
  %12 = reshape(%11, newshape=[16, 12, 128, 128]);
  %13 = expand_dims(%input1, axis=1);
  %14 = cast(%13, dtype="float32");
  %15 = subtract(1f, %14);
  %16 = multiply(%12, 0.125f);
  %17 = multiply(%15, -10000f);
  %18 = add(%16, %17);
  %19 = nn.softmax(%18);
  %20 = nn.dense(%0, %w_v, units=768);
  %21 = nn.bias_add(%20, %b_v);
  %22 = reshape(%21, newshape=[16, 128, 12, 64]);
  %23 = transpose(%22, axes=[0, 2, 1, 3]);
  %24 = reshape(%23, newshape=[-3, 0, 0]);
  %25 = reshape(%19, newshape=[-3, 0, 0]);
  %26 = transpose(%24, axes=[0, 2, 1]);
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]);
  %28 = reshape(%27, newshape=[16, 128, 768]);
  %29 = reshape(%28, newshape=[-3, 0]);
  %30 = nn.dense(%29, %w_attr_out, units=None);
  %31 = nn.bias_add(%30, %b_attr_out);
  %32 = add(%31, %0);
  %33 = nn.dense(%32, %w_inter, units=None);
  %34 = nn.bias_add(%33, %b_inter);
  %35 = power(%34, 3f);
  %36 = multiply(0.044715f, %35);
  %37 = add(%34, %36);
  %38 = multiply(0.797885f, %37);
  %39 = tanh(%38);
  %40 = add(1f, %39);
  %41 = multiply(0.5f, %40);
  %42 = multiply(%34, %41);
  %43 = nn.dense(%42, %w_out, units=None);
  %44 = nn.bias_add(%43, %b_out);
  add(%44, %32)
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToBasicBlockNormalForm
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) {
  %0 = reshape(%input, newshape=[-3, 768]);
  %1 = nn.dense(%0, %w_k, units=768);
  %2 = nn.bias_add(%1, %b_k);
  %3 = reshape(%2, newshape=[16, 128, 12, 64]);
  %4 = transpose(%3, axes=[0, 2, 1, 3]);
  %5 = nn.dense(%0, %w_q, units=768);
  %6 = nn.bias_add(%5, %b_q);
  %7 = reshape(%6, newshape=[16, 128, 12, 64]);
  %8 = transpose(%7, axes=[0, 2, 1, 3]);
  %9 = reshape(%4, newshape=[-3, -1, 64]);
  %10 = reshape(%8, newshape=[-3, -1, 64]);
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]);
  %12 = reshape(%11, newshape=[16, 12, 128, 128]);
  %13 = expand_dims(%input1, axis=1);
  %14 = cast(%13, dtype="float32");
  %15 = subtract(1f, %14);
  %16 = multiply(%12, 0.125f);
  %17 = multiply(%15, -10000f);
  %18 = add(%16, %17);
  %19 = nn.softmax(%18);
  %20 = nn.dense(%0, %w_v, units=768);
  %21 = nn.bias_add(%20, %b_v);
  %22 = reshape(%21, newshape=[16, 128, 12, 64]);
  %23 = transpose(%22, axes=[0, 2, 1, 3]);
  %24 = reshape(%23, newshape=[-3, 0, 0]);
  %25 = reshape(%19, newshape=[-3, 0, 0]);
  %26 = transpose(%24, axes=[0, 2, 1]);
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]);
  %28 = reshape(%27, newshape=[16, 128, 768]);
  %29 = reshape(%28, newshape=[-3, 0]);
  %30 = nn.dense(%29, %w_attr_out, units=None);
  %31 = nn.bias_add(%30, %b_attr_out);
  %32 = add(%31, %0);
  %33 = nn.dense(%32, %w_inter, units=None);
  %34 = nn.bias_add(%33, %b_inter);
  %35 = power(%34, 3f);
  %36 = multiply(0.044715f, %35);
  %37 = add(%34, %36);
  %38 = multiply(0.797885f, %37);
  %39 = tanh(%38);
  %40 = add(1f, %39);
  %41 = multiply(0.5f, %40);
  %42 = multiply(%34, %41);
  %43 = nn.dense(%42, %w_out, units=None);
  %44 = nn.bias_add(%43, %b_out);
  add(%44, %32)
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[16, 128, 768]) /* ty=Tensor[(16, 128, 768), float32] */;
  %29 = reshape(%28, newshape=[-3, 0]) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.dense(%29, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %31 = nn.bias_add(%30, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %32 = add(%31, %0) /* ty=Tensor[(2048, 768), float32] */;
  %33 = nn.dense(%32, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = nn.bias_add(%33, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = power(%34, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = multiply(0.044715f /* ty=float32 */, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = add(%34, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = multiply(0.797885f /* ty=float32 */, %37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = tanh(%38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = add(1f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(0.5f /* ty=float32 */, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = multiply(%34, %41) /* ty=Tensor[(2048, 3072), float32] */;
  %43 = nn.dense(%42, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %44 = nn.bias_add(%43, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%44, %32) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[16, 128, 768]) /* ty=Tensor[(16, 128, 768), float32] */;
  %29 = reshape(%28, newshape=[-3, 0]) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.dense(%29, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %31 = nn.bias_add(%30, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %32 = add(%31, %0) /* ty=Tensor[(2048, 768), float32] */;
  %33 = nn.dense(%32, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = nn.bias_add(%33, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = power(%34, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = multiply(0.044715f /* ty=float32 */, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = add(%34, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = multiply(0.797885f /* ty=float32 */, %37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = tanh(%38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = add(1f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(0.5f /* ty=float32 */, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = multiply(%34, %41) /* ty=Tensor[(2048, 3072), float32] */;
  %43 = nn.dense(%42, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %44 = nn.bias_add(%43, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%44, %32) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass sequential
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[16, 128, 768]) /* ty=Tensor[(16, 128, 768), float32] */;
  %29 = reshape(%28, newshape=[-3, 0]) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.dense(%29, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %31 = nn.bias_add(%30, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %32 = add(%31, %0) /* ty=Tensor[(2048, 768), float32] */;
  %33 = nn.dense(%32, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = nn.bias_add(%33, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = power(%34, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = multiply(0.044715f /* ty=float32 */, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = add(%34, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = multiply(0.797885f /* ty=float32 */, %37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = tanh(%38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = add(1f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(0.5f /* ty=float32 */, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = multiply(%34, %41) /* ty=Tensor[(2048, 3072), float32] */;
  %43 = nn.dense(%42, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %44 = nn.bias_add(%43, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%44, %32) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Legalize
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[16, 128, 768]) /* ty=Tensor[(16, 128, 768), float32] */;
  %29 = reshape(%28, newshape=[-3, 0]) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.dense(%29, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %31 = nn.bias_add(%30, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %32 = add(%31, %0) /* ty=Tensor[(2048, 768), float32] */;
  %33 = nn.dense(%32, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = nn.bias_add(%33, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = power(%34, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = multiply(0.044715f /* ty=float32 */, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = add(%34, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = multiply(0.797885f /* ty=float32 */, %37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = tanh(%38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = add(1f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(0.5f /* ty=float32 */, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = multiply(%34, %41) /* ty=Tensor[(2048, 3072), float32] */;
  %43 = nn.dense(%42, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %44 = nn.bias_add(%43, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%44, %32) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass EtaExpand
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]);
  %1 = nn.dense(%0, %w_k, units=768);
  %2 = nn.bias_add(%1, %b_k);
  %3 = reshape(%2, newshape=[16, 128, 12, 64]);
  %4 = transpose(%3, axes=[0, 2, 1, 3]);
  %5 = nn.dense(%0, %w_q, units=768);
  %6 = nn.bias_add(%5, %b_q);
  %7 = reshape(%6, newshape=[16, 128, 12, 64]);
  %8 = transpose(%7, axes=[0, 2, 1, 3]);
  %9 = reshape(%4, newshape=[-3, -1, 64]);
  %10 = reshape(%8, newshape=[-3, -1, 64]);
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]);
  %12 = reshape(%11, newshape=[16, 12, 128, 128]);
  %13 = expand_dims(%input1, axis=1);
  %14 = cast(%13, dtype="float32");
  %15 = subtract(1f /* ty=float32 */, %14);
  %16 = multiply(%12, 0.125f /* ty=float32 */);
  %17 = multiply(%15, -10000f /* ty=float32 */);
  %18 = add(%16, %17);
  %19 = nn.softmax(%18);
  %20 = nn.dense(%0, %w_v, units=768);
  %21 = nn.bias_add(%20, %b_v);
  %22 = reshape(%21, newshape=[16, 128, 12, 64]);
  %23 = transpose(%22, axes=[0, 2, 1, 3]);
  %24 = reshape(%23, newshape=[-3, 0, 0]);
  %25 = reshape(%19, newshape=[-3, 0, 0]);
  %26 = transpose(%24, axes=[0, 2, 1]);
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]);
  %28 = reshape(%27, newshape=[16, 128, 768]);
  %29 = reshape(%28, newshape=[-3, 0]);
  %30 = nn.dense(%29, %w_attr_out, units=None);
  %31 = nn.bias_add(%30, %b_attr_out);
  %32 = add(%31, %0);
  %33 = nn.dense(%32, %w_inter, units=None);
  %34 = nn.bias_add(%33, %b_inter);
  %35 = power(%34, 3f /* ty=float32 */);
  %36 = multiply(0.044715f /* ty=float32 */, %35);
  %37 = add(%34, %36);
  %38 = multiply(0.797885f /* ty=float32 */, %37);
  %39 = tanh(%38);
  %40 = add(1f /* ty=float32 */, %39);
  %41 = multiply(0.5f /* ty=float32 */, %40);
  %42 = multiply(%34, %41);
  %43 = nn.dense(%42, %w_out, units=None);
  %44 = nn.bias_add(%43, %b_out);
  add(%44, %32)
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass SimplifyInference
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[16, 128, 768]) /* ty=Tensor[(16, 128, 768), float32] */;
  %29 = reshape(%28, newshape=[-3, 0]) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.dense(%29, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %31 = nn.bias_add(%30, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %32 = add(%31, %0) /* ty=Tensor[(2048, 768), float32] */;
  %33 = nn.dense(%32, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = nn.bias_add(%33, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = power(%34, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = multiply(0.044715f /* ty=float32 */, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = add(%34, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = multiply(0.797885f /* ty=float32 */, %37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = tanh(%38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = add(1f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(0.5f /* ty=float32 */, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = multiply(%34, %41) /* ty=Tensor[(2048, 3072), float32] */;
  %43 = nn.dense(%42, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %44 = nn.bias_add(%43, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%44, %32) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass SimplifyExpr
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %29 = nn.dense(%28, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.bias_add(%29, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %31 = add(%30, %0) /* ty=Tensor[(2048, 768), float32] */;
  %32 = nn.dense(%31, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %33 = nn.bias_add(%32, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = nn.dense(%41, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %43 = nn.bias_add(%42, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%43, %31) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Inline
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %29 = nn.dense(%28, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.bias_add(%29, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %31 = add(%30, %0) /* ty=Tensor[(2048, 768), float32] */;
  %32 = nn.dense(%31, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %33 = nn.bias_add(%32, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = nn.dense(%41, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %43 = nn.bias_add(%42, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%43, %31) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass DeadCodeElimination
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %29 = nn.dense(%28, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.bias_add(%29, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %31 = add(%30, %0) /* ty=Tensor[(2048, 768), float32] */;
  %32 = nn.dense(%31, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %33 = nn.bias_add(%32, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = nn.dense(%41, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %43 = nn.bias_add(%42, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%43, %31) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlinePrimitives
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %29 = nn.dense(%28, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.bias_add(%29, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %31 = add(%30, %0) /* ty=Tensor[(2048, 768), float32] */;
  %32 = nn.dense(%31, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %33 = nn.bias_add(%32, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = nn.dense(%41, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %43 = nn.bias_add(%42, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%43, %31) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %29 = nn.dense(%28, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.bias_add(%29, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %31 = add(%30, %0) /* ty=Tensor[(2048, 768), float32] */;
  %32 = nn.dense(%31, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %33 = nn.bias_add(%32, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = nn.dense(%41, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %43 = nn.bias_add(%42, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%43, %31) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %29 = nn.dense(%28, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.bias_add(%29, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %31 = add(%30, %0) /* ty=Tensor[(2048, 768), float32] */;
  %32 = nn.dense(%31, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %33 = nn.bias_add(%32, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = nn.dense(%41, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %43 = nn.bias_add(%42, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%43, %31) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldScaleAxis
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %29 = nn.dense(%28, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.bias_add(%29, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %31 = add(%30, %0) /* ty=Tensor[(2048, 768), float32] */;
  %32 = nn.dense(%31, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %33 = nn.bias_add(%32, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = nn.dense(%41, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %43 = nn.bias_add(%42, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%43, %31) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = reshape(%input, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.dense(%0, %w_k, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %2 = nn.bias_add(%1, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %3 = reshape(%2, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %5 = nn.dense(%0, %w_q, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %6 = nn.bias_add(%5, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %7 = reshape(%6, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %8 = transpose(%7, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %9 = reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %10 = reshape(%8, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = nn.batch_matmul(%9, %10, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %12 = reshape(%11, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %13 = expand_dims(%input1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %18 = add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = nn.softmax(%18) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = nn.dense(%0, %w_v, units=768) /* ty=Tensor[(2048, 768), float32] */;
  %21 = nn.bias_add(%20, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %22 = reshape(%21, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %23 = transpose(%22, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %24 = reshape(%23, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  %25 = reshape(%19, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */;
  %26 = transpose(%24, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = nn.batch_matmul(%25, %26, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = reshape(%27, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */;
  %29 = nn.dense(%28, %w_attr_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %30 = nn.bias_add(%29, %b_attr_out) /* ty=Tensor[(2048, 768), float32] */;
  %31 = add(%30, %0) /* ty=Tensor[(2048, 768), float32] */;
  %32 = nn.dense(%31, %w_inter, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %33 = nn.bias_add(%32, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
  %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
  %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
  %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
  %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
  %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
  %41 = multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */;
  %42 = nn.dense(%41, %w_out, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %43 = nn.bias_add(%42, %b_out) /* ty=Tensor[(2048, 768), float32] */;
  add(%43, %31) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %22 = fn (%p011: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p011, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  %23 = %22(%input) /* ty=Tensor[(2048, 768), float32] */;
  %24 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %21 = nn.dense(%p010, %p16, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%21, %p23) /* ty=Tensor[(2048, 768), float32] */
  };
  %25 = %24(%23, %w_k, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %26 = fn (%p09: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %19 = reshape(%p09, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %20 = transpose(%19, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%20, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %30 = fn (%p013: Tensor[(2048, 768), float32], %p17: Tensor[(768, 768), float32], %p24: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %29 = nn.dense(%p013, %p17, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%29, %p24) /* ty=Tensor[(2048, 768), float32] */
  };
  %31 = %30(%23, %w_q, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %32 = fn (%p012: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %27 = reshape(%p012, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %28 = transpose(%27, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%28, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %33 = %26(%25) /* ty=Tensor[(192, 128, 64), float32] */;
  %34 = %32(%31) /* ty=Tensor[(192, 128, 64), float32] */;
  %35 = fn (%p08: Tensor[(192, 128, 64), float32], %p15: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p08, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %36 = %35(%33, %34) /* ty=Tensor[(192, 128, 128), float32] */;
  %37 = fn (%p07: Tensor[(192, 128, 128), float32], %p14: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %13 = reshape(%p07, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %14 = expand_dims(%p14, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %15 = cast(%14, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %16 = subtract(1f /* ty=float32 */, %15) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %17 = multiply(%13, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %18 = multiply(%16, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%17, %18) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %38 = %37(%36, %input1) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %39 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %40 = %39(%38) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %41 = fn (%p05: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p05, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %46 = fn (%p015: Tensor[(2048, 768), float32], %p18: Tensor[(768, 768), float32], %p25: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %45 = nn.dense(%p015, %p18, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%45, %p25) /* ty=Tensor[(2048, 768), float32] */
  };
  %47 = %46(%23, %w_v, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p014: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %42 = reshape(%p014, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %43 = transpose(%42, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %44 = reshape(%43, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%44, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %49 = %41(%40) /* ty=Tensor[(192, 128, 128), float32] */;
  %50 = %48(%47) /* ty=Tensor[(192, 64, 128), float32] */;
  %51 = fn (%p04: Tensor[(192, 128, 128), float32], %p13: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p04, %p13, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %52 = %51(%49, %50) /* ty=Tensor[(192, 128, 64), float32] */;
  %53 = fn (%p03: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p03, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  %54 = %53(%52) /* ty=Tensor[(2048, 768), float32] */;
  %55 = fn (%p02: Tensor[(2048, 768), float32], %p12: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %11 = nn.dense(%p02, %p12, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %12 = nn.bias_add(%11, %p22) /* ty=Tensor[(2048, 768), float32] */;
    add(%12, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %56 = %55(%54, %w_attr_out, %b_attr_out, %23) /* ty=Tensor[(2048, 768), float32] */;
  %57 = fn (%p01: Tensor[(2048, 768), float32], %p11: Tensor[(3072, 768), float32], %p21: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %2 = nn.dense(%p01, %p11, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %3 = nn.bias_add(%2, %p21) /* ty=Tensor[(2048, 3072), float32] */;
    %4 = power(%3, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %5 = multiply(0.044715f /* ty=float32 */, %4) /* ty=Tensor[(2048, 3072), float32] */;
    %6 = add(%3, %5) /* ty=Tensor[(2048, 3072), float32] */;
    %7 = multiply(0.797885f /* ty=float32 */, %6) /* ty=Tensor[(2048, 3072), float32] */;
    %8 = tanh(%7) /* ty=Tensor[(2048, 3072), float32] */;
    %9 = add(1f /* ty=float32 */, %8) /* ty=Tensor[(2048, 3072), float32] */;
    %10 = multiply(0.5f /* ty=float32 */, %9) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%3, %10) /* ty=Tensor[(2048, 3072), float32] */
  };
  %58 = %57(%56, %w_inter, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %59 = fn (%p0: Tensor[(2048, 3072), float32], %p1: Tensor[(768, 3072), float32], %p2: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %1 = nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */;
    add(%1, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %59(%58, %w_out, %b_out, %56) /* ty=Tensor[(2048, 768), float32] */
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ToANormalForm
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x = fn (%p0: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p0, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x1 = %x(%input);
  let %x2 = fn (%p01: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p01, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x3 = %x2(%x1, %w_k, %b_k);
  let %x4 = fn (%p02: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %1 = reshape(%p02, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %2 = transpose(%1, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%2, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x5 = %x4(%x3);
  let %x6 = fn (%p03: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %3 = nn.dense(%p03, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%3, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x7 = %x6(%x1, %w_q, %b_q);
  let %x8 = fn (%p04: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p04, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x9 = %x8(%x7);
  let %x10 = fn (%p05: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p05, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x11 = %x10(%x5, %x9);
  let %x12 = fn (%p06: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %6 = reshape(%p06, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %7 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %8 = cast(%7, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %9 = subtract(1f /* ty=float32 */, %8) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %10 = multiply(%6, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %11 = multiply(%9, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%10, %11) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x13 = %x12(%x11, %input1);
  let %x14 = fn (%p07: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p07) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x15 = %x14(%x13);
  let %x16 = fn (%p08: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p08, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x17 = %x16(%x15);
  let %x18 = fn (%p09: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %12 = nn.dense(%p09, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%12, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x19 = %x18(%x1, %w_v, %b_v);
  let %x20 = fn (%p010: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %13 = reshape(%p010, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %15 = reshape(%14, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%15, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  let %x21 = %x20(%x19);
  let %x22 = fn (%p011: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p011, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x23 = %x22(%x17, %x21);
  let %x24 = fn (%p012: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p012, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x25 = %x24(%x23);
  let %x26 = fn (%p013: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %16 = nn.dense(%p013, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %17 = nn.bias_add(%16, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%17, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x27 = %x26(%x25, %w_attr_out, %b_attr_out, %x1);
  let %x28 = fn (%p014: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %18 = nn.dense(%p014, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %19 = nn.bias_add(%18, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %20 = power(%19, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %21 = multiply(0.044715f /* ty=float32 */, %20) /* ty=Tensor[(2048, 3072), float32] */;
    %22 = add(%19, %21) /* ty=Tensor[(2048, 3072), float32] */;
    %23 = multiply(0.797885f /* ty=float32 */, %22) /* ty=Tensor[(2048, 3072), float32] */;
    %24 = tanh(%23) /* ty=Tensor[(2048, 3072), float32] */;
    %25 = add(1f /* ty=float32 */, %24) /* ty=Tensor[(2048, 3072), float32] */;
    %26 = multiply(0.5f /* ty=float32 */, %25) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%19, %26) /* ty=Tensor[(2048, 3072), float32] */
  };
  let %x29 = %x28(%x27, %w_inter, %b_inter);
  let %x30 = fn (%p015: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %27 = nn.dense(%p015, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %28 = nn.bias_add(%27, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%28, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x31 = %x30(%x29, %w_out, %b_out, %x27);
  %x31
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: fn (Tensor[(16, 128, 768), float32]) -> Tensor[(2048, 768), float32] = fn (%p0: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p0, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x1: Tensor[(2048, 768), float32] = %x(%input) /* ty=Tensor[(2048, 768), float32] */;
  let %x2: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = fn (%p01: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p01, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x3: Tensor[(2048, 768), float32] = %x2(%x1, %w_k, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  let %x4: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 128, 64), float32] = fn (%p02: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %1 = reshape(%p02, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %2 = transpose(%1, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%2, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x5: Tensor[(192, 128, 64), float32] = %x4(%x3) /* ty=Tensor[(192, 128, 64), float32] */;
  let %x6: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = fn (%p03: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %3 = nn.dense(%p03, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%3, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x7: Tensor[(2048, 768), float32] = %x6(%x1, %w_q, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  let %x8: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 128, 64), float32] = fn (%p04: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p04, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x9: Tensor[(192, 128, 64), float32] = %x8(%x7) /* ty=Tensor[(192, 128, 64), float32] */;
  let %x10: fn (Tensor[(192, 128, 64), float32], Tensor[(192, 128, 64), float32]) -> Tensor[(192, 128, 128), float32] = fn (%p05: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p05, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x11: Tensor[(192, 128, 128), float32] = %x10(%x5, %x9) /* ty=Tensor[(192, 128, 128), float32] */;
  let %x12: fn (Tensor[(192, 128, 128), float32], Tensor[(16, 128, 128), int32]) -> Tensor[(16, 12, 128, 128), float32] = fn (%p06: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %6 = reshape(%p06, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %7 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %8 = cast(%7, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %9 = subtract(1f /* ty=float32 */, %8) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %10 = multiply(%6, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %11 = multiply(%9, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%10, %11) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x13: Tensor[(16, 12, 128, 128), float32] = %x12(%x11, %input1) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  let %x14: fn (Tensor[(16, 12, 128, 128), float32]) -> Tensor[(16, 12, 128, 128), float32] = fn (%p07: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p07) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x15: Tensor[(16, 12, 128, 128), float32] = %x14(%x13) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  let %x16: fn (Tensor[(16, 12, 128, 128), float32]) -> Tensor[(192, 128, 128), float32] = fn (%p08: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p08, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x17: Tensor[(192, 128, 128), float32] = %x16(%x15) /* ty=Tensor[(192, 128, 128), float32] */;
  let %x18: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = fn (%p09: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %12 = nn.dense(%p09, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%12, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x19: Tensor[(2048, 768), float32] = %x18(%x1, %w_v, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  let %x20: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 64, 128), float32] = fn (%p010: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %13 = reshape(%p010, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %15 = reshape(%14, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%15, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  let %x21: Tensor[(192, 64, 128), float32] = %x20(%x19) /* ty=Tensor[(192, 64, 128), float32] */;
  let %x22: fn (Tensor[(192, 128, 128), float32], Tensor[(192, 64, 128), float32]) -> Tensor[(192, 128, 64), float32] = fn (%p011: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p011, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x23: Tensor[(192, 128, 64), float32] = %x22(%x17, %x21) /* ty=Tensor[(192, 128, 64), float32] */;
  let %x24: fn (Tensor[(192, 128, 64), float32]) -> Tensor[(2048, 768), float32] = fn (%p012: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p012, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x25: Tensor[(2048, 768), float32] = %x24(%x23) /* ty=Tensor[(2048, 768), float32] */;
  let %x26: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32], Tensor[(2048, 768), float32]) -> Tensor[(2048, 768), float32] = fn (%p013: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %16 = nn.dense(%p013, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %17 = nn.bias_add(%16, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%17, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x27: Tensor[(2048, 768), float32] = %x26(%x25, %w_attr_out, %b_attr_out, %x1) /* ty=Tensor[(2048, 768), float32] */;
  let %x28: fn (Tensor[(2048, 768), float32], Tensor[(3072, 768), float32], Tensor[(3072), float32]) -> Tensor[(2048, 3072), float32] = fn (%p014: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %18 = nn.dense(%p014, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %19 = nn.bias_add(%18, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %20 = power(%19, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %21 = multiply(0.044715f /* ty=float32 */, %20) /* ty=Tensor[(2048, 3072), float32] */;
    %22 = add(%19, %21) /* ty=Tensor[(2048, 3072), float32] */;
    %23 = multiply(0.797885f /* ty=float32 */, %22) /* ty=Tensor[(2048, 3072), float32] */;
    %24 = tanh(%23) /* ty=Tensor[(2048, 3072), float32] */;
    %25 = add(1f /* ty=float32 */, %24) /* ty=Tensor[(2048, 3072), float32] */;
    %26 = multiply(0.5f /* ty=float32 */, %25) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%19, %26) /* ty=Tensor[(2048, 3072), float32] */
  };
  let %x29: Tensor[(2048, 3072), float32] = %x28(%x27, %w_inter, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  let %x30: fn (Tensor[(2048, 3072), float32], Tensor[(768, 3072), float32], Tensor[(768), float32], Tensor[(2048, 768), float32]) -> Tensor[(2048, 768), float32] = fn (%p015: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %27 = nn.dense(%p015, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %28 = nn.bias_add(%27, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%28, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x31: Tensor[(2048, 768), float32] = %x30(%x29, %w_out, %b_out, %x27) /* ty=Tensor[(2048, 768), float32] */;
  %x31
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass LambdaLift
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: fn (Tensor[(16, 128, 768), float32]) -> Tensor[(2048, 768), float32] = fn (%p0: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p0, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x1: Tensor[(2048, 768), float32] = %x(%input) /* ty=Tensor[(2048, 768), float32] */;
  let %x2: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = fn (%p01: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p01, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x3: Tensor[(2048, 768), float32] = %x2(%x1, %w_k, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  let %x4: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 128, 64), float32] = fn (%p02: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %1 = reshape(%p02, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %2 = transpose(%1, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%2, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x5: Tensor[(192, 128, 64), float32] = %x4(%x3) /* ty=Tensor[(192, 128, 64), float32] */;
  let %x6: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = fn (%p03: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %3 = nn.dense(%p03, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%3, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x7: Tensor[(2048, 768), float32] = %x6(%x1, %w_q, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  let %x8: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 128, 64), float32] = fn (%p04: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p04, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x9: Tensor[(192, 128, 64), float32] = %x8(%x7) /* ty=Tensor[(192, 128, 64), float32] */;
  let %x10: fn (Tensor[(192, 128, 64), float32], Tensor[(192, 128, 64), float32]) -> Tensor[(192, 128, 128), float32] = fn (%p05: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p05, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x11: Tensor[(192, 128, 128), float32] = %x10(%x5, %x9) /* ty=Tensor[(192, 128, 128), float32] */;
  let %x12: fn (Tensor[(192, 128, 128), float32], Tensor[(16, 128, 128), int32]) -> Tensor[(16, 12, 128, 128), float32] = fn (%p06: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %6 = reshape(%p06, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %7 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %8 = cast(%7, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %9 = subtract(1f /* ty=float32 */, %8) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %10 = multiply(%6, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %11 = multiply(%9, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%10, %11) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x13: Tensor[(16, 12, 128, 128), float32] = %x12(%x11, %input1) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  let %x14: fn (Tensor[(16, 12, 128, 128), float32]) -> Tensor[(16, 12, 128, 128), float32] = fn (%p07: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p07) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x15: Tensor[(16, 12, 128, 128), float32] = %x14(%x13) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  let %x16: fn (Tensor[(16, 12, 128, 128), float32]) -> Tensor[(192, 128, 128), float32] = fn (%p08: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p08, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x17: Tensor[(192, 128, 128), float32] = %x16(%x15) /* ty=Tensor[(192, 128, 128), float32] */;
  let %x18: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = fn (%p09: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %12 = nn.dense(%p09, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%12, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x19: Tensor[(2048, 768), float32] = %x18(%x1, %w_v, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  let %x20: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 64, 128), float32] = fn (%p010: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %13 = reshape(%p010, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %15 = reshape(%14, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%15, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  let %x21: Tensor[(192, 64, 128), float32] = %x20(%x19) /* ty=Tensor[(192, 64, 128), float32] */;
  let %x22: fn (Tensor[(192, 128, 128), float32], Tensor[(192, 64, 128), float32]) -> Tensor[(192, 128, 64), float32] = fn (%p011: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p011, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x23: Tensor[(192, 128, 64), float32] = %x22(%x17, %x21) /* ty=Tensor[(192, 128, 64), float32] */;
  let %x24: fn (Tensor[(192, 128, 64), float32]) -> Tensor[(2048, 768), float32] = fn (%p012: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p012, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x25: Tensor[(2048, 768), float32] = %x24(%x23) /* ty=Tensor[(2048, 768), float32] */;
  let %x26: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32], Tensor[(2048, 768), float32]) -> Tensor[(2048, 768), float32] = fn (%p013: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %16 = nn.dense(%p013, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %17 = nn.bias_add(%16, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%17, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x27: Tensor[(2048, 768), float32] = %x26(%x25, %w_attr_out, %b_attr_out, %x1) /* ty=Tensor[(2048, 768), float32] */;
  let %x28: fn (Tensor[(2048, 768), float32], Tensor[(3072, 768), float32], Tensor[(3072), float32]) -> Tensor[(2048, 3072), float32] = fn (%p014: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %18 = nn.dense(%p014, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %19 = nn.bias_add(%18, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %20 = power(%19, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %21 = multiply(0.044715f /* ty=float32 */, %20) /* ty=Tensor[(2048, 3072), float32] */;
    %22 = add(%19, %21) /* ty=Tensor[(2048, 3072), float32] */;
    %23 = multiply(0.797885f /* ty=float32 */, %22) /* ty=Tensor[(2048, 3072), float32] */;
    %24 = tanh(%23) /* ty=Tensor[(2048, 3072), float32] */;
    %25 = add(1f /* ty=float32 */, %24) /* ty=Tensor[(2048, 3072), float32] */;
    %26 = multiply(0.5f /* ty=float32 */, %25) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%19, %26) /* ty=Tensor[(2048, 3072), float32] */
  };
  let %x29: Tensor[(2048, 3072), float32] = %x28(%x27, %w_inter, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  let %x30: fn (Tensor[(2048, 3072), float32], Tensor[(768, 3072), float32], Tensor[(768), float32], Tensor[(2048, 768), float32]) -> Tensor[(2048, 768), float32] = fn (%p015: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %27 = nn.dense(%p015, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %28 = nn.bias_add(%27, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%28, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x31: Tensor[(2048, 768), float32] = %x30(%x29, %w_out, %b_out, %x27) /* ty=Tensor[(2048, 768), float32] */;
  %x31
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Inline
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = fn (%p0: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p0, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x: fn (Tensor[(16, 128, 768), float32]) -> Tensor[(2048, 768), float32] = %0;
  let %x1: Tensor[(2048, 768), float32] = %0(%input);
  %2 = fn (%p01: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %1 = nn.dense(%p01, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%1, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x2: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = %2;
  let %x3: Tensor[(2048, 768), float32] = %2(%x1, %w_k, %b_k);
  %5 = fn (%p02: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %3 = reshape(%p02, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x4: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 128, 64), float32] = %5;
  let %x5: Tensor[(192, 128, 64), float32] = %5(%x3);
  %7 = fn (%p03: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %6 = nn.dense(%p03, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%6, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x6: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = %7;
  let %x7: Tensor[(2048, 768), float32] = %7(%x1, %w_q, %b_q);
  %10 = fn (%p04: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %8 = reshape(%p04, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %9 = transpose(%8, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%9, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x8: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 128, 64), float32] = %10;
  let %x9: Tensor[(192, 128, 64), float32] = %10(%x7);
  %11 = fn (%p05: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p05, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x10: fn (Tensor[(192, 128, 64), float32], Tensor[(192, 128, 64), float32]) -> Tensor[(192, 128, 128), float32] = %11;
  let %x11: Tensor[(192, 128, 128), float32] = %11(%x5, %x9);
  %18 = fn (%p06: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %12 = reshape(%p06, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %13 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x12: fn (Tensor[(192, 128, 128), float32], Tensor[(16, 128, 128), int32]) -> Tensor[(16, 12, 128, 128), float32] = %18;
  let %x13: Tensor[(16, 12, 128, 128), float32] = %18(%x11, %input1);
  %19 = fn (%p07: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p07) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x14: fn (Tensor[(16, 12, 128, 128), float32]) -> Tensor[(16, 12, 128, 128), float32] = %19;
  let %x15: Tensor[(16, 12, 128, 128), float32] = %19(%x13);
  %20 = fn (%p08: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p08, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x16: fn (Tensor[(16, 12, 128, 128), float32]) -> Tensor[(192, 128, 128), float32] = %20;
  let %x17: Tensor[(192, 128, 128), float32] = %20(%x15);
  %22 = fn (%p09: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %21 = nn.dense(%p09, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%21, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x18: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32]) -> Tensor[(2048, 768), float32] = %22;
  let %x19: Tensor[(2048, 768), float32] = %22(%x1, %w_v, %b_v);
  %26 = fn (%p010: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %23 = reshape(%p010, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %24 = transpose(%23, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %25 = reshape(%24, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  let %x20: fn (Tensor[(2048, 768), float32]) -> Tensor[(192, 64, 128), float32] = %26;
  let %x21: Tensor[(192, 64, 128), float32] = %26(%x19);
  %27 = fn (%p011: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p011, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x22: fn (Tensor[(192, 128, 128), float32], Tensor[(192, 64, 128), float32]) -> Tensor[(192, 128, 64), float32] = %27;
  let %x23: Tensor[(192, 128, 64), float32] = %27(%x17, %x21);
  %28 = fn (%p012: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p012, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x24: fn (Tensor[(192, 128, 64), float32]) -> Tensor[(2048, 768), float32] = %28;
  let %x25: Tensor[(2048, 768), float32] = %28(%x23);
  %31 = fn (%p013: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %29 = nn.dense(%p013, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %30 = nn.bias_add(%29, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%30, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x26: fn (Tensor[(2048, 768), float32], Tensor[(768, 768), float32], Tensor[(768), float32], Tensor[(2048, 768), float32]) -> Tensor[(2048, 768), float32] = %31;
  let %x27: Tensor[(2048, 768), float32] = %31(%x25, %w_attr_out, %b_attr_out, %x1);
  %41 = fn (%p014: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %32 = nn.dense(%p014, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %33 = nn.bias_add(%32, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
    %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
    %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
    %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
    %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
    %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */
  };
  let %x28: fn (Tensor[(2048, 768), float32], Tensor[(3072, 768), float32], Tensor[(3072), float32]) -> Tensor[(2048, 3072), float32] = %41;
  let %x29: Tensor[(2048, 3072), float32] = %41(%x27, %w_inter, %b_inter);
  %44 = fn (%p015: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %42 = nn.dense(%p015, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %43 = nn.bias_add(%42, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%43, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x30: fn (Tensor[(2048, 3072), float32], Tensor[(768, 3072), float32], Tensor[(768), float32], Tensor[(2048, 768), float32]) -> Tensor[(2048, 768), float32] = %44;
  let %x31: Tensor[(2048, 768), float32] = %44(%x29, %w_out, %b_out, %x27);
  %x31
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass DeadCodeElimination
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = fn (%p0: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p0, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x: Tensor[(2048, 768), float32] = %0(%input) /* ty=Tensor[(2048, 768), float32] */;
  %2 = fn (%p01: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %1 = nn.dense(%p01, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%1, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x1: Tensor[(2048, 768), float32] = %2(%x, %w_k, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %5 = fn (%p02: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %3 = reshape(%p02, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x2: Tensor[(192, 128, 64), float32] = %5(%x1) /* ty=Tensor[(192, 128, 64), float32] */;
  %7 = fn (%p03: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %6 = nn.dense(%p03, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%6, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x3: Tensor[(2048, 768), float32] = %7(%x, %w_q, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p04: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %8 = reshape(%p04, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %9 = transpose(%8, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%9, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x4: Tensor[(192, 128, 64), float32] = %10(%x3) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = fn (%p05: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p05, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x5: Tensor[(192, 128, 128), float32] = %11(%x2, %x4) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p06: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %12 = reshape(%p06, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %13 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x6: Tensor[(16, 12, 128, 128), float32] = %18(%x5, %input1) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = fn (%p07: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p07) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x7: Tensor[(16, 12, 128, 128), float32] = %19(%x6) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = fn (%p08: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p08, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x8: Tensor[(192, 128, 128), float32] = %20(%x7) /* ty=Tensor[(192, 128, 128), float32] */;
  %22 = fn (%p09: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %21 = nn.dense(%p09, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%21, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x9: Tensor[(2048, 768), float32] = %22(%x, %w_v, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %26 = fn (%p010: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %23 = reshape(%p010, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %24 = transpose(%23, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %25 = reshape(%24, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  let %x10: Tensor[(192, 64, 128), float32] = %26(%x9) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = fn (%p011: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p011, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x11: Tensor[(192, 128, 64), float32] = %27(%x8, %x10) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = fn (%p012: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p012, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x12: Tensor[(2048, 768), float32] = %28(%x11) /* ty=Tensor[(2048, 768), float32] */;
  %31 = fn (%p013: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %29 = nn.dense(%p013, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %30 = nn.bias_add(%29, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%30, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x13: Tensor[(2048, 768), float32] = %31(%x12, %w_attr_out, %b_attr_out, %x) /* ty=Tensor[(2048, 768), float32] */;
  %41 = fn (%p014: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %32 = nn.dense(%p014, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %33 = nn.bias_add(%32, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
    %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
    %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
    %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
    %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
    %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */
  };
  let %x14: Tensor[(2048, 3072), float32] = %41(%x13, %w_inter, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %44 = fn (%p015: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %42 = nn.dense(%p015, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %43 = nn.bias_add(%42, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%43, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x15: Tensor[(2048, 768), float32] = %44(%x14, %w_out, %b_out, %x13) /* ty=Tensor[(2048, 768), float32] */;
  %x15
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlinePrimitives
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = fn (%p0: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p0, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x: Tensor[(2048, 768), float32] = %0(%input) /* ty=Tensor[(2048, 768), float32] */;
  %2 = fn (%p01: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %1 = nn.dense(%p01, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%1, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x1: Tensor[(2048, 768), float32] = %2(%x, %w_k, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %5 = fn (%p02: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %3 = reshape(%p02, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x2: Tensor[(192, 128, 64), float32] = %5(%x1) /* ty=Tensor[(192, 128, 64), float32] */;
  %7 = fn (%p03: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %6 = nn.dense(%p03, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%6, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x3: Tensor[(2048, 768), float32] = %7(%x, %w_q, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p04: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %8 = reshape(%p04, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %9 = transpose(%8, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%9, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x4: Tensor[(192, 128, 64), float32] = %10(%x3) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = fn (%p05: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p05, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x5: Tensor[(192, 128, 128), float32] = %11(%x2, %x4) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p06: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %12 = reshape(%p06, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %13 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x6: Tensor[(16, 12, 128, 128), float32] = %18(%x5, %input1) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = fn (%p07: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p07) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x7: Tensor[(16, 12, 128, 128), float32] = %19(%x6) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = fn (%p08: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p08, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x8: Tensor[(192, 128, 128), float32] = %20(%x7) /* ty=Tensor[(192, 128, 128), float32] */;
  %22 = fn (%p09: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %21 = nn.dense(%p09, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%21, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x9: Tensor[(2048, 768), float32] = %22(%x, %w_v, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %26 = fn (%p010: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %23 = reshape(%p010, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %24 = transpose(%23, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %25 = reshape(%24, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  let %x10: Tensor[(192, 64, 128), float32] = %26(%x9) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = fn (%p011: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p011, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x11: Tensor[(192, 128, 64), float32] = %27(%x8, %x10) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = fn (%p012: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p012, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x12: Tensor[(2048, 768), float32] = %28(%x11) /* ty=Tensor[(2048, 768), float32] */;
  %31 = fn (%p013: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %29 = nn.dense(%p013, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %30 = nn.bias_add(%29, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%30, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x13: Tensor[(2048, 768), float32] = %31(%x12, %w_attr_out, %b_attr_out, %x) /* ty=Tensor[(2048, 768), float32] */;
  %41 = fn (%p014: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %32 = nn.dense(%p014, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %33 = nn.bias_add(%32, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
    %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
    %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
    %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
    %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
    %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */
  };
  let %x14: Tensor[(2048, 3072), float32] = %41(%x13, %w_inter, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %44 = fn (%p015: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %42 = nn.dense(%p015, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %43 = nn.bias_add(%42, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%43, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x15: Tensor[(2048, 768), float32] = %44(%x14, %w_out, %b_out, %x13) /* ty=Tensor[(2048, 768), float32] */;
  %x15
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InlineGlobals
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = fn (%p0: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p0, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x: Tensor[(2048, 768), float32] = %0(%input) /* ty=Tensor[(2048, 768), float32] */;
  %2 = fn (%p01: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %1 = nn.dense(%p01, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%1, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x1: Tensor[(2048, 768), float32] = %2(%x, %w_k, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %5 = fn (%p02: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %3 = reshape(%p02, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x2: Tensor[(192, 128, 64), float32] = %5(%x1) /* ty=Tensor[(192, 128, 64), float32] */;
  %7 = fn (%p03: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %6 = nn.dense(%p03, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%6, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x3: Tensor[(2048, 768), float32] = %7(%x, %w_q, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p04: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %8 = reshape(%p04, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %9 = transpose(%8, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%9, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x4: Tensor[(192, 128, 64), float32] = %10(%x3) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = fn (%p05: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p05, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x5: Tensor[(192, 128, 128), float32] = %11(%x2, %x4) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p06: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %12 = reshape(%p06, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %13 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x6: Tensor[(16, 12, 128, 128), float32] = %18(%x5, %input1) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = fn (%p07: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p07) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x7: Tensor[(16, 12, 128, 128), float32] = %19(%x6) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = fn (%p08: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p08, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x8: Tensor[(192, 128, 128), float32] = %20(%x7) /* ty=Tensor[(192, 128, 128), float32] */;
  %22 = fn (%p09: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %21 = nn.dense(%p09, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%21, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x9: Tensor[(2048, 768), float32] = %22(%x, %w_v, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %26 = fn (%p010: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %23 = reshape(%p010, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %24 = transpose(%23, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %25 = reshape(%24, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  let %x10: Tensor[(192, 64, 128), float32] = %26(%x9) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = fn (%p011: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p011, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x11: Tensor[(192, 128, 64), float32] = %27(%x8, %x10) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = fn (%p012: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p012, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x12: Tensor[(2048, 768), float32] = %28(%x11) /* ty=Tensor[(2048, 768), float32] */;
  %31 = fn (%p013: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %29 = nn.dense(%p013, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %30 = nn.bias_add(%29, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%30, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x13: Tensor[(2048, 768), float32] = %31(%x12, %w_attr_out, %b_attr_out, %x) /* ty=Tensor[(2048, 768), float32] */;
  %41 = fn (%p014: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %32 = nn.dense(%p014, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %33 = nn.bias_add(%32, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
    %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
    %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
    %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
    %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
    %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */
  };
  let %x14: Tensor[(2048, 3072), float32] = %41(%x13, %w_inter, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %44 = fn (%p015: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %42 = nn.dense(%p015, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %43 = nn.bias_add(%42, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%43, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x15: Tensor[(2048, 768), float32] = %44(%x14, %w_out, %b_out, %x13) /* ty=Tensor[(2048, 768), float32] */;
  %x15
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass RemoveUnusedFunctions
def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  %0 = fn (%p0: Tensor[(16, 128, 768), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p0, newshape=[-3, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x: Tensor[(2048, 768), float32] = %0(%input) /* ty=Tensor[(2048, 768), float32] */;
  %2 = fn (%p01: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %1 = nn.dense(%p01, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%1, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x1: Tensor[(2048, 768), float32] = %2(%x, %w_k, %b_k) /* ty=Tensor[(2048, 768), float32] */;
  %5 = fn (%p02: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %3 = reshape(%p02, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %4 = transpose(%3, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%4, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x2: Tensor[(192, 128, 64), float32] = %5(%x1) /* ty=Tensor[(192, 128, 64), float32] */;
  %7 = fn (%p03: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %6 = nn.dense(%p03, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%6, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x3: Tensor[(2048, 768), float32] = %7(%x, %w_q, %b_q) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p04: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %8 = reshape(%p04, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %9 = transpose(%8, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%9, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x4: Tensor[(192, 128, 64), float32] = %10(%x3) /* ty=Tensor[(192, 128, 64), float32] */;
  %11 = fn (%p05: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p05, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x5: Tensor[(192, 128, 128), float32] = %11(%x2, %x4) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p06: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %12 = reshape(%p06, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %13 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %14 = cast(%13, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %15 = subtract(1f /* ty=float32 */, %14) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %16 = multiply(%12, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %17 = multiply(%15, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%16, %17) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x6: Tensor[(16, 12, 128, 128), float32] = %18(%x5, %input1) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %19 = fn (%p07: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p07) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  let %x7: Tensor[(16, 12, 128, 128), float32] = %19(%x6) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %20 = fn (%p08: Tensor[(16, 12, 128, 128), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(192, 128, 128), float32] {
    reshape(%p08, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  let %x8: Tensor[(192, 128, 128), float32] = %20(%x7) /* ty=Tensor[(192, 128, 128), float32] */;
  %22 = fn (%p09: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %21 = nn.dense(%p09, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%21, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x9: Tensor[(2048, 768), float32] = %22(%x, %w_v, %b_v) /* ty=Tensor[(2048, 768), float32] */;
  %26 = fn (%p010: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %23 = reshape(%p010, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %24 = transpose(%23, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %25 = reshape(%24, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  let %x10: Tensor[(192, 64, 128), float32] = %26(%x9) /* ty=Tensor[(192, 64, 128), float32] */;
  %27 = fn (%p011: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p011, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  let %x11: Tensor[(192, 128, 64), float32] = %27(%x8, %x10) /* ty=Tensor[(192, 128, 64), float32] */;
  %28 = fn (%p012: Tensor[(192, 128, 64), float32], Primitive=1, relay.reshape_only=1) -> Tensor[(2048, 768), float32] {
    reshape(%p012, newshape=[2048, 768]) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x12: Tensor[(2048, 768), float32] = %28(%x11) /* ty=Tensor[(2048, 768), float32] */;
  %31 = fn (%p013: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %29 = nn.dense(%p013, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %30 = nn.bias_add(%29, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%30, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x13: Tensor[(2048, 768), float32] = %31(%x12, %w_attr_out, %b_attr_out, %x) /* ty=Tensor[(2048, 768), float32] */;
  %41 = fn (%p014: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %32 = nn.dense(%p014, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %33 = nn.bias_add(%32, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %34 = power(%33, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %35 = multiply(0.044715f /* ty=float32 */, %34) /* ty=Tensor[(2048, 3072), float32] */;
    %36 = add(%33, %35) /* ty=Tensor[(2048, 3072), float32] */;
    %37 = multiply(0.797885f /* ty=float32 */, %36) /* ty=Tensor[(2048, 3072), float32] */;
    %38 = tanh(%37) /* ty=Tensor[(2048, 3072), float32] */;
    %39 = add(1f /* ty=float32 */, %38) /* ty=Tensor[(2048, 3072), float32] */;
    %40 = multiply(0.5f /* ty=float32 */, %39) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%33, %40) /* ty=Tensor[(2048, 3072), float32] */
  };
  let %x14: Tensor[(2048, 3072), float32] = %41(%x13, %w_inter, %b_inter) /* ty=Tensor[(2048, 3072), float32] */;
  %44 = fn (%p015: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %42 = nn.dense(%p015, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %43 = nn.bias_add(%42, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%43, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  let %x15: Tensor[(2048, 768), float32] = %44(%x14, %w_out, %b_out, %x13) /* ty=Tensor[(2048, 768), float32] */;
  %x15
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FuseOps
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass ManifestAlloc
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass FoldConstant
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass sequential
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:30] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass InferType
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32]) -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1) -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1) -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1) -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1) -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1) -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass LabelOps
type Storage {
  
}

def @main(%w_k: Tensor[(768, 768), float32], %w_q: Tensor[(768, 768), float32], %w_v: Tensor[(768, 768), float32], %b_k: Tensor[(768), float32], %b_q: Tensor[(768), float32], %b_v: Tensor[(768), float32], %w_attr_out: Tensor[(768, 768), float32], %b_attr_out: Tensor[(768), float32], %w_inter: Tensor[(3072, 768), float32], %b_inter: Tensor[(3072), float32], %w_out: Tensor[(768, 3072), float32], %b_out: Tensor[(768), float32], %input: Tensor[(16, 128, 768), float32], %input1: Tensor[(16, 128, 128), int32], hash="393b150aa7a1c359") -> Tensor[(2048, 768), float32] {
  let %x: Tensor[(2048, 768), float32] = vm.reshape_tensor(%input, meta[relay.Constant][0] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_0: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(2048, 768), float32] */;
  %1 = fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1, hash="53aabff2b510d377") -> Tensor[(2048, 768), float32] {
    %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
  };
  %2 = (%x, %w_k, %b_k);
  %3 = (%tensor_0,);
  let %x1: () = vm.invoke_tvm_op(%1, %2, %3) /* ty=() */;
  let %x2: Tensor[(2048, 768), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */;
  %6 = fn (%p01: Tensor[(2048, 768), float32], Primitive=1, hash="ad3422d84a96c835") -> Tensor[(192, 128, 64), float32] {
    %4 = reshape(%p01, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %5 = transpose(%4, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%5, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %7 = (%x2,);
  %8 = (%tensor_01,);
  let %x3: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %x4: Tensor[(192, 128, 64), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  %10 = fn (%p02: Tensor[(2048, 768), float32], %p11: Tensor[(768, 768), float32], %p21: Tensor[(768), float32], Primitive=1, hash="53aabff2b510d377") -> Tensor[(2048, 768), float32] {
    %9 = nn.dense(%p02, %p11, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%9, %p21) /* ty=Tensor[(2048, 768), float32] */
  };
  %11 = (%x, %w_q, %b_q);
  %12 = (%tensor_02,);
  let %x5: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x6: Tensor[(2048, 768), float32] = %tensor_02;
  let %storage_03: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(192, 128, 64), float32] */;
  %15 = fn (%p03: Tensor[(2048, 768), float32], Primitive=1, hash="ad3422d84a96c835") -> Tensor[(192, 128, 64), float32] {
    %13 = reshape(%p03, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %14 = transpose(%13, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    reshape(%14, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %16 = (%x6,);
  %17 = (%tensor_03,);
  let %x7: () = vm.invoke_tvm_op(%15, %16, %17) /* ty=() */;
  let %x8: Tensor[(192, 128, 64), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(192, 128, 128), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][5] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(192, 128, 128), float32] */;
  %18 = fn (%p04: Tensor[(192, 128, 64), float32], %p12: Tensor[(192, 128, 64), float32], Primitive=1, hash="9cb388a7d40bb0d2") -> Tensor[(192, 128, 128), float32] {
    nn.batch_matmul(%p04, %p12, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
  };
  %19 = (%x4, %x8);
  %20 = (%tensor_04,);
  let %x9: () = vm.invoke_tvm_op(%18, %19, %20) /* ty=() */;
  let %x10: Tensor[(192, 128, 128), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %27 = fn (%p05: Tensor[(192, 128, 128), float32], %p13: Tensor[(16, 128, 128), int32], Primitive=1, hash="cdb9af5d9e869928") -> Tensor[(16, 12, 128, 128), float32] {
    %21 = reshape(%p05, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %22 = expand_dims(%p13, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
    %23 = cast(%22, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %24 = subtract(1f /* ty=float32 */, %23) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    %25 = multiply(%21, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
    %26 = multiply(%24, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
    add(%25, %26) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %28 = (%x10, %input1);
  %29 = (%tensor_05,);
  let %x11: () = vm.invoke_tvm_op(%27, %28, %29) /* ty=() */;
  let %x12: Tensor[(16, 12, 128, 128), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(12582912 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(16, 12, 128, 128), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %30 = fn (%p06: Tensor[(16, 12, 128, 128), float32], Primitive=1, hash="f87a6cf3e39ecea2") -> Tensor[(16, 12, 128, 128), float32] {
    nn.softmax(%p06) /* ty=Tensor[(16, 12, 128, 128), float32] */
  };
  %31 = (%x12,);
  %32 = (%tensor_06,);
  let %x13: () = vm.invoke_tvm_op(%30, %31, %32) /* ty=() */;
  let %x14: Tensor[(16, 12, 128, 128), float32] = %tensor_06;
  let %x15: Tensor[(192, 128, 128), float32] = vm.reshape_tensor(%x14, meta[relay.Constant][8] /* ty=Tensor[(3), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(192, 128, 128), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(2048, 768), float32] */;
  %34 = fn (%p07: Tensor[(2048, 768), float32], %p14: Tensor[(768, 768), float32], %p22: Tensor[(768), float32], Primitive=1, hash="53aabff2b510d377") -> Tensor[(2048, 768), float32] {
    %33 = nn.dense(%p07, %p14, units=768) /* ty=Tensor[(2048, 768), float32] */;
    nn.bias_add(%33, %p22) /* ty=Tensor[(2048, 768), float32] */
  };
  %35 = (%x, %w_v, %b_v);
  %36 = (%tensor_07,);
  let %x16: () = vm.invoke_tvm_op(%34, %35, %36) /* ty=() */;
  let %x17: Tensor[(2048, 768), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(192, 64, 128), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(192, 64, 128), float32] */;
  %40 = fn (%p08: Tensor[(2048, 768), float32], Primitive=1, hash="f7f3d6915ea0d5ba") -> Tensor[(192, 64, 128), float32] {
    %37 = reshape(%p08, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
    %38 = transpose(%37, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
    %39 = reshape(%38, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
    transpose(%39, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
  };
  %41 = (%x17,);
  %42 = (%tensor_08,);
  let %x18: () = vm.invoke_tvm_op(%40, %41, %42) /* ty=() */;
  let %x19: Tensor[(192, 64, 128), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(192, 128, 64), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][11] /* ty=Tensor[(3), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(192, 128, 64), float32] */;
  %43 = fn (%p09: Tensor[(192, 128, 128), float32], %p15: Tensor[(192, 64, 128), float32], Primitive=1, hash="f7bf5b8325d36518") -> Tensor[(192, 128, 64), float32] {
    nn.batch_matmul(%p09, %p15, meta[relay.attrs.BatchMatmulAttrs][1]) /* ty=Tensor[(192, 128, 64), float32] */
  };
  %44 = (%x15, %x19);
  %45 = (%tensor_09,);
  let %x20: () = vm.invoke_tvm_op(%43, %44, %45) /* ty=() */;
  let %x21: Tensor[(192, 128, 64), float32] = %tensor_09;
  let %x22: Tensor[(2048, 768), float32] = vm.reshape_tensor(%x21, meta[relay.Constant][12] /* ty=Tensor[(2), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(2048, 768), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(2048, 768), float32] */;
  %48 = fn (%p010: Tensor[(2048, 768), float32], %p16: Tensor[(768, 768), float32], %p23: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1, hash="f55746157c32aa1f") -> Tensor[(2048, 768), float32] {
    %46 = nn.dense(%p010, %p16, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %47 = nn.bias_add(%46, %p23) /* ty=Tensor[(2048, 768), float32] */;
    add(%47, %p3) /* ty=Tensor[(2048, 768), float32] */
  };
  %49 = (%x22, %w_attr_out, %b_attr_out, %x);
  %50 = (%tensor_010,);
  let %x23: () = vm.invoke_tvm_op(%48, %49, %50) /* ty=() */;
  let %x24: Tensor[(2048, 768), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(25165824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(2048, 3072), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(2048, 3072), float32] */;
  %60 = fn (%p011: Tensor[(2048, 768), float32], %p17: Tensor[(3072, 768), float32], %p24: Tensor[(3072), float32], Primitive=1, hash="c84f9e27bab379ba") -> Tensor[(2048, 3072), float32] {
    %51 = nn.dense(%p011, %p17, units=None) /* ty=Tensor[(2048, 3072), float32] */;
    %52 = nn.bias_add(%51, %p24) /* ty=Tensor[(2048, 3072), float32] */;
    %53 = power(%52, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
    %54 = multiply(0.044715f /* ty=float32 */, %53) /* ty=Tensor[(2048, 3072), float32] */;
    %55 = add(%52, %54) /* ty=Tensor[(2048, 3072), float32] */;
    %56 = multiply(0.797885f /* ty=float32 */, %55) /* ty=Tensor[(2048, 3072), float32] */;
    %57 = tanh(%56) /* ty=Tensor[(2048, 3072), float32] */;
    %58 = add(1f /* ty=float32 */, %57) /* ty=Tensor[(2048, 3072), float32] */;
    %59 = multiply(0.5f /* ty=float32 */, %58) /* ty=Tensor[(2048, 3072), float32] */;
    multiply(%52, %59) /* ty=Tensor[(2048, 3072), float32] */
  };
  %61 = (%x24, %w_inter, %b_inter);
  %62 = (%tensor_011,);
  let %x25: () = vm.invoke_tvm_op(%60, %61, %62) /* ty=() */;
  let %x26: Tensor[(2048, 3072), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(6291456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(2048, 768), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(2048, 768), float32] */;
  %65 = fn (%p012: Tensor[(2048, 3072), float32], %p18: Tensor[(768, 3072), float32], %p25: Tensor[(768), float32], %p31: Tensor[(2048, 768), float32], Primitive=1, hash="924abff814ab640f") -> Tensor[(2048, 768), float32] {
    %63 = nn.dense(%p012, %p18, units=None) /* ty=Tensor[(2048, 768), float32] */;
    %64 = nn.bias_add(%63, %p25) /* ty=Tensor[(2048, 768), float32] */;
    add(%64, %p31) /* ty=Tensor[(2048, 768), float32] */
  };
  %66 = (%x26, %w_out, %b_out, %x24);
  %67 = (%tensor_012,);
  let %x27: () = vm.invoke_tvm_op(%65, %66, %67) /* ty=() */;
  let %x28: Tensor[(2048, 768), float32] = %tensor_012;
  %x28
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1, hash="53aabff2b510d377") -> Tensor[(2048, 768), float32] {
  %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
  nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
}
One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.
[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Buffer(matmul_cublas_1: Pointer(float32), float32, [2048, 768], [])] "realize_scope" = "";
  realize(matmul_cublas, [0:2048, 0:768], True {
    attr [[placeholder_9: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []), placeholder]] "buffer_bind_scope" = @tir.tvm_tuple(0, 2048, 0, 768, dtype=handle);
    attr [[placeholder_11: Buffer(placeholder_12: Pointer(float32), float32, [768, 768], []), placeholder_1]] "buffer_bind_scope" = @tir.tvm_tuple(0, 768, 0, 768, dtype=handle);
    attr [[matmul_cublas_2: Buffer(matmul_cublas_3: Pointer(float32), float32, [2048, 768], []), matmul_cublas]] "buffer_bind_scope" = @tir.tvm_tuple(0, 2048, 0, 768, dtype=handle);
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_12, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [T_add] "realize_scope" = "";
    realize(T_add, [0:2048, 0:768], True {
      attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
      attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      T_add[floordiv((threadIdx.x + (blockIdx.x*1024)), 768), floormod((threadIdx.x + (blockIdx.x*1024)), 768)] = (matmul_cublas[floordiv((threadIdx.x + (blockIdx.x*1024)), 768), floormod((threadIdx.x + (blockIdx.x*1024)), 768)] + placeholder_2[floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
    })
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 768), float32], Primitive=1, hash="ad3422d84a96c835") -> Tensor[(192, 128, 64), float32] {
  %0 = reshape(%p0, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %1 = transpose(%0, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  reshape(%1, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [T_reshape] "realize_scope" = "";
  realize(T_reshape, [0:192, 0:128, 0:64], True {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
      T_reshape[floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128), floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128), floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)] = placeholder[floormod(floordiv(((((((floormod(floordiv(floordiv(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128)*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128))*64) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)), 64), 128), 12), 16)*128) + floormod(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128)*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128))*64) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)), 64), 128))*12) + floormod(floordiv(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128)*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128))*64) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)), 64), 128), 12))*64) + floormod(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128)*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128))*64) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)), 64)), 768), 2048), floormod(((((((floormod(floordiv(floordiv(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128)*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128))*64) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)), 64), 128), 12), 16)*128) + floormod(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128)*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128))*64) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)), 64), 128))*12) + floormod(floordiv(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128)*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128))*64) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)), 64), 128), 12))*64) + floormod(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128)*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64), 128))*64) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 64)), 64)), 768)]
    }
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 192), 12)*128) + floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64) + floormod(threadIdx.x, 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 192), 12)*128) + floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64) + floormod(threadIdx.x, 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 192), 12)*128) + floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64) + floormod(threadIdx.x, 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 192), 12)*128) + floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64) + floormod(threadIdx.x, 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 192), 12)*128) + floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64) + floormod(threadIdx.x, 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 192), 12)*128) + floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64) + floormod(threadIdx.x, 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 128)), 12)*64)) + floormod(threadIdx.x, 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1, hash="53aabff2b510d377") -> Tensor[(2048, 768), float32] {
  %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
  nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 768), float32], Primitive=1, hash="ad3422d84a96c835") -> Tensor[(192, 128, 64), float32] {
  %0 = reshape(%p0, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %1 = transpose(%0, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  reshape(%1, newshape=[-3, -1, 64]) /* ty=Tensor[(192, 128, 64), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(192, 128, 64), float32], %p1: Tensor[(192, 128, 64), float32], Primitive=1, hash="9cb388a7d40bb0d2") -> Tensor[(192, 128, 128), float32] {
  nn.batch_matmul(%p0, %p1, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 128), float32] */
}

[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [batch_matmul_cublas] "realize_scope" = "";
  realize(batch_matmul_cublas, [0:192, 0:128, 0:128], True {
    attr [[placeholder_6: Buffer(placeholder_7: Pointer(float32), float32, [192, 128, 64], []), placeholder]] "buffer_bind_scope" = @tir.tvm_tuple(0, 192, 0, 128, 0, 64, dtype=handle);
    attr [[placeholder_8: Buffer(placeholder_9: Pointer(float32), float32, [192, 128, 64], []), placeholder_1]] "buffer_bind_scope" = @tir.tvm_tuple(0, 192, 0, 128, 0, 64, dtype=handle);
    attr [[batch_matmul_cublas_3: Buffer(batch_matmul_cublas_4: Pointer(float32), float32, [192, 128, 128], []), batch_matmul_cublas]] "buffer_bind_scope" = @tir.tvm_tuple(0, 192, 0, 128, 0, 128, dtype=handle);
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(192, 128, 128), float32], %p1: Tensor[(16, 128, 128), int32], Primitive=1, hash="cdb9af5d9e869928") -> Tensor[(16, 12, 128, 128), float32] {
  %0 = reshape(%p0, newshape=[16, 12, 128, 128]) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %1 = expand_dims(%p1, axis=1) /* ty=Tensor[(16, 1, 128, 128), int32] */;
  %2 = cast(%1, dtype="float32") /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %3 = subtract(1f /* ty=float32 */, %2) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  %4 = multiply(%0, 0.125f /* ty=float32 */) /* ty=Tensor[(16, 12, 128, 128), float32] */;
  %5 = multiply(%3, -10000f /* ty=float32 */) /* ty=Tensor[(16, 1, 128, 128), float32] */;
  add(%4, %5) /* ty=Tensor[(16, 12, 128, 128), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [T_add] "realize_scope" = "";
  realize(T_add, [0:16, 0:12, 0:128, 0:128], True {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
      T_add[floordiv(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128)] = ((placeholder[floormod(floordiv(floordiv(((((((floordiv(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12)*12) + floormod(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12))*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128))*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128)), 128), 128), 192), floormod(floordiv(((((((floordiv(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12)*12) + floormod(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12))*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128))*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128)), 128), 128), floormod(((((((floordiv(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12)*12) + floormod(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12))*128) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128))*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128)), 128)]*0.125f32) + ((1f32 - cast(float32, placeholder_1[floordiv(floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128), 128), floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144)), 128)]))*-10000f32))
    }
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 192)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 192)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 192)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 192)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 192)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 192)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128))*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128))*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128))*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128))*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128))*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128))*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128))*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x*8) + floordiv(threadIdx.x, 128))*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x*8) + floordiv(threadIdx.x, 128))*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x*8) + floordiv(threadIdx.x, 128))*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int32), int32, [16, 128, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_2[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (((float32*)placeholder_4[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x*8) + floordiv(threadIdx.x, 128))*128)) + floormod(threadIdx.x, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_5[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 128)*128)) + floormod(threadIdx.x, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(16, 12, 128, 128), float32], Primitive=1, hash="f87a6cf3e39ecea2") -> Tensor[(16, 12, 128, 128), float32] {
  nn.softmax(%p0) /* ty=Tensor[(16, 12, 128, 128), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Buffer(T_softmax_maxelem_1: Pointer(float32), float32, [16, 12, 128], [])] "realize_scope" = "";
  realize(T_softmax_maxelem, [0:16, 0:12, 0:128], True {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*1024)), 128), 12), floormod(floordiv((threadIdx.x + (blockIdx.x*1024)), 128), 12), floormod((threadIdx.x + (blockIdx.x*1024)), 128)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*1024)), 128), 12), floormod(floordiv((threadIdx.x + (blockIdx.x*1024)), 128), 12), floormod((threadIdx.x + (blockIdx.x*1024)), 128)] = max(T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*1024)), 128), 12), floormod(floordiv((threadIdx.x + (blockIdx.x*1024)), 128), 12), floormod((threadIdx.x + (blockIdx.x*1024)), 128)], placeholder[floordiv(floordiv((threadIdx.x + (blockIdx.x*1024)), 128), 12), floormod(floordiv((threadIdx.x + (blockIdx.x*1024)), 128), 12), floormod((threadIdx.x + (blockIdx.x*1024)), 128), k])
      }
    }
    attr [T_softmax_exp: Buffer(T_softmax_exp_1: Pointer(float32), float32, [16, 12, 128, 128], [])] "realize_scope" = "";
    realize(T_softmax_exp, [0:16, 0:12, 0:128, 0:128], True {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[floordiv(floordiv(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128), floormod(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128)] = @tir.exp((placeholder[floordiv(floordiv(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128), floormod(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128)] - T_softmax_maxelem[floordiv(floordiv(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128), 12), floormod(floordiv(((threadIdx.x_1 + (blockIdx.x_1*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer*262144)), 128), 128)]), dtype=float32)
      }
      attr [T_softmax_expsum: Buffer(T_softmax_expsum_1: Pointer(float32), float32, [16, 12, 128], [])] "realize_scope" = "";
      realize(T_softmax_expsum, [0:16, 0:12, 0:128], True {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), 12), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), 12), floormod((threadIdx.x_2 + (blockIdx.x_2*1024)), 128)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), 12), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), 12), floormod((threadIdx.x_2 + (blockIdx.x_2*1024)), 128)] = (T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), 12), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), 12), floormod((threadIdx.x_2 + (blockIdx.x_2*1024)), 128)] + T_softmax_exp[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), 12), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), 12), floormod((threadIdx.x_2 + (blockIdx.x_2*1024)), 128), k_1])
          }
        }
        attr [T_softmax_norm] "realize_scope" = "";
        realize(T_softmax_norm, [0:16, 0:12, 0:128, 0:128], True {
          attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
          attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
          for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
            T_softmax_norm[floordiv(floordiv(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128), 12), floormod(floordiv(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128), 12), floormod(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128), floormod(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128)] = (T_softmax_exp[floordiv(floordiv(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128), 12), floormod(floordiv(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128), 12), floormod(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128), floormod(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128)] / T_softmax_expsum[floordiv(floordiv(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128), 12), floormod(floordiv(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128), 12), floormod(floordiv(((threadIdx.x_3 + (blockIdx.x_3*1024)) + (i0.i1.fused.i2.fused.i3.fused.outer_1*262144)), 128), 128)])
          }
        })
      })
    })
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[((i0.i1.fused.i2.fused.i3.fused.outer*2048) + ((blockIdx.x_1*8) + floordiv(threadIdx.x_1, 128)))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + ((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[((i0.i1.fused.i2.fused.i3.fused.outer*2048) + ((blockIdx.x_1*8) + floordiv(threadIdx.x_1, 128)))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + ((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[((i0.i1.fused.i2.fused.i3.fused.outer*2048) + ((blockIdx.x_1*8) + floordiv(threadIdx.x_1, 128)))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + ((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[((i0.i1.fused.i2.fused.i3.fused.outer*2048) + ((blockIdx.x_1*8) + floordiv(threadIdx.x_1, 128)))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + ((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[((i0.i1.fused.i2.fused.i3.fused.outer*2048) + ((blockIdx.x_1*8) + floordiv(threadIdx.x_1, 128)))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + ((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[((i0.i1.fused.i2.fused.i3.fused.outer*2048) + ((blockIdx.x_1*8) + floordiv(threadIdx.x_1, 128)))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + ((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [16, 12, 128]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [16, 12, 128, 128]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [16, 12, 128]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_expsum[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
      }
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
      }
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
        T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
      }
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
          T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
          for (k_1: int32, 0, 128) {
            T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
          T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*1024) + threadIdx.x)], (float32*)placeholder_2[(((blockIdx.x*131072) + (threadIdx.x*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_1*1024)) + threadIdx.x_1)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_1*8)) + floordiv(threadIdx.x_1, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)T_softmax_exp[(((blockIdx.x_2*131072) + (threadIdx.x_2*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_3*8)) + floordiv(threadIdx.x_3, 128))])
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], Primitive=1, hash="53aabff2b510d377") -> Tensor[(2048, 768), float32] {
  %0 = nn.dense(%p0, %p1, units=768) /* ty=Tensor[(2048, 768), float32] */;
  nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 768), float32], Primitive=1, hash="f7f3d6915ea0d5ba") -> Tensor[(192, 64, 128), float32] {
  %0 = reshape(%p0, newshape=[16, 128, 12, 64]) /* ty=Tensor[(16, 128, 12, 64), float32] */;
  %1 = transpose(%0, axes=[0, 2, 1, 3]) /* ty=Tensor[(16, 12, 128, 64), float32] */;
  %2 = reshape(%1, newshape=[-3, 0, 0]) /* ty=Tensor[(192, 128, 64), float32] */;
  transpose(%2, axes=[0, 2, 1]) /* ty=Tensor[(192, 64, 128), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [T_transpose] "realize_scope" = "";
  realize(T_transpose, [0:192, 0:64, 0:128], True {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
      T_transpose[floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64), floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64), floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128)] = placeholder[floormod(floordiv(((((((floormod(floordiv(floordiv(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128))*64) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)), 64), 128), 12), 16)*128) + floormod(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128))*64) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)), 64), 128))*12) + floormod(floordiv(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128))*64) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)), 64), 128), 12))*64) + floormod(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128))*64) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)), 64)), 768), 2048), floormod(((((((floormod(floordiv(floordiv(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128))*64) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)), 64), 128), 12), 16)*128) + floormod(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128))*64) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)), 64), 128))*12) + floormod(floordiv(floordiv(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128))*64) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)), 64), 128), 12))*64) + floormod(((((floordiv(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)*128) + floormod(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128))*64) + floormod(floordiv(((threadIdx.x + (blockIdx.x*1024)) + (ax0.ax1.fused.ax2.fused.outer*262144)), 128), 64)), 64)), 768)]
    }
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 192), 12)*128) + floormod(threadIdx.x, 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 192), 12)*128) + floormod(threadIdx.x, 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 192), 12)*128) + floormod(threadIdx.x, 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 192), 12)*128) + floormod(threadIdx.x, 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 192), 12)*128) + floormod(threadIdx.x, 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 192), 12)*128) + floormod(threadIdx.x, 128))*768) + ((floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_1: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_1: placeholder, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = (float32*)placeholder_2[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*98304) + (floormod(threadIdx.x, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64)), 12)*64)) + floormod(((blockIdx.x*8) + floordiv(threadIdx.x, 128)), 64))]
  }
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(192, 128, 128), float32], %p1: Tensor[(192, 64, 128), float32], Primitive=1, hash="f7bf5b8325d36518") -> Tensor[(192, 128, 64), float32] {
  nn.batch_matmul(%p0, %p1, meta[relay.attrs.BatchMatmulAttrs][0]) /* ty=Tensor[(192, 128, 64), float32] */
}

[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [batch_matmul_cublas] "realize_scope" = "";
  realize(batch_matmul_cublas, [0:192, 0:128, 0:64], True {
    attr [[placeholder_6: Buffer(placeholder_7: Pointer(float32), float32, [192, 128, 128], []), placeholder]] "buffer_bind_scope" = @tir.tvm_tuple(0, 192, 0, 128, 0, 128, dtype=handle);
    attr [[placeholder_8: Buffer(placeholder_9: Pointer(float32), float32, [192, 64, 128], []), placeholder_1]] "buffer_bind_scope" = @tir.tvm_tuple(0, 192, 0, 64, 0, 128, dtype=handle);
    attr [[batch_matmul_cublas_3: Buffer(batch_matmul_cublas_4: Pointer(float32), float32, [192, 128, 64], []), batch_matmul_cublas]] "buffer_bind_scope" = @tir.tvm_tuple(0, 192, 0, 128, 0, 64, dtype=handle);
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_4, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder: Buffer(placeholder_4: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_1: Buffer(placeholder_5: Pointer(float32), float32, [192, 64, 128], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(768, 768), float32], %p2: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1, hash="f55746157c32aa1f") -> Tensor[(2048, 768), float32] {
  %0 = nn.dense(%p0, %p1, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */;
  add(%1, %p3) /* ty=Tensor[(2048, 768), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Buffer(matmul_cublas_1: Pointer(float32), float32, [2048, 768], [])] "realize_scope" = "";
  realize(matmul_cublas, [0:2048, 0:768], True {
    attr [[placeholder_12: Buffer(placeholder_13: Pointer(float32), float32, [2048, 768], []), placeholder_2]] "buffer_bind_scope" = @tir.tvm_tuple(0, 2048, 0, 768, dtype=handle);
    attr [[placeholder_14: Buffer(placeholder_15: Pointer(float32), float32, [768, 768], []), placeholder]] "buffer_bind_scope" = @tir.tvm_tuple(0, 768, 0, 768, dtype=handle);
    attr [[matmul_cublas_2: Buffer(matmul_cublas_3: Pointer(float32), float32, [2048, 768], []), matmul_cublas]] "buffer_bind_scope" = @tir.tvm_tuple(0, 2048, 0, 768, dtype=handle);
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_13, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_15, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [T_add] "realize_scope" = "";
    realize(T_add, [0:2048, 0:768], True {
      attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
      attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      T_add[floordiv((threadIdx.x + (blockIdx.x*1024)), 768), floormod((threadIdx.x + (blockIdx.x*1024)), 768)] = ((matmul_cublas[floordiv((threadIdx.x + (blockIdx.x*1024)), 768), floormod((threadIdx.x + (blockIdx.x*1024)), 768)] + placeholder_3[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + placeholder_1[floordiv((threadIdx.x + (blockIdx.x*1024)), 768), floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
    })
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True}
  buffers = {placeholder_3: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder: Buffer(placeholder_11: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {T_add_1: T_add, placeholder_5: placeholder, placeholder_7: placeholder_1, placeholder_4: placeholder_2, placeholder_6: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_9[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 768), float32], %p1: Tensor[(3072, 768), float32], %p2: Tensor[(3072), float32], Primitive=1, hash="c84f9e27bab379ba") -> Tensor[(2048, 3072), float32] {
  %0 = nn.dense(%p0, %p1, units=None) /* ty=Tensor[(2048, 3072), float32] */;
  %1 = nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 3072), float32] */;
  %2 = power(%1, 3f /* ty=float32 */) /* ty=Tensor[(2048, 3072), float32] */;
  %3 = multiply(0.044715f /* ty=float32 */, %2) /* ty=Tensor[(2048, 3072), float32] */;
  %4 = add(%1, %3) /* ty=Tensor[(2048, 3072), float32] */;
  %5 = multiply(0.797885f /* ty=float32 */, %4) /* ty=Tensor[(2048, 3072), float32] */;
  %6 = tanh(%5) /* ty=Tensor[(2048, 3072), float32] */;
  %7 = add(1f /* ty=float32 */, %6) /* ty=Tensor[(2048, 3072), float32] */;
  %8 = multiply(0.5f /* ty=float32 */, %7) /* ty=Tensor[(2048, 3072), float32] */;
  multiply(%1, %8) /* ty=Tensor[(2048, 3072), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Buffer(matmul_cublas_1: Pointer(float32), float32, [2048, 3072], [])] "realize_scope" = "";
  realize(matmul_cublas, [0:2048, 0:3072], True {
    attr [[placeholder_9: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []), placeholder]] "buffer_bind_scope" = @tir.tvm_tuple(0, 2048, 0, 768, dtype=handle);
    attr [[placeholder_11: Buffer(placeholder_12: Pointer(float32), float32, [3072, 768], []), placeholder_1]] "buffer_bind_scope" = @tir.tvm_tuple(0, 3072, 0, 768, dtype=handle);
    attr [[matmul_cublas_2: Buffer(matmul_cublas_3: Pointer(float32), float32, [2048, 3072], []), matmul_cublas]] "buffer_bind_scope" = @tir.tvm_tuple(0, 2048, 0, 3072, dtype=handle);
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_12, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [T_multiply] "realize_scope" = "";
    realize(T_multiply, [0:2048, 0:3072], True {
      attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
      attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      T_multiply[floordiv((threadIdx.x + (blockIdx.x*1024)), 3072), floormod((threadIdx.x + (blockIdx.x*1024)), 3072)] = ((matmul_cublas[floordiv((threadIdx.x + (blockIdx.x*1024)), 3072), floormod((threadIdx.x + (blockIdx.x*1024)), 3072)] + placeholder_2[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*((matmul_cublas[floordiv((threadIdx.x + (blockIdx.x*1024)), 3072), floormod((threadIdx.x + (blockIdx.x*1024)), 3072)] + placeholder_2[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]) + (0.044715f32*@tir.pow((matmul_cublas[floordiv((threadIdx.x + (blockIdx.x*1024)), 3072), floormod((threadIdx.x + (blockIdx.x*1024)), 3072)] + placeholder_2[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
    })
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod((threadIdx.x + (blockIdx.x*1024)), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 3072]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True}
  buffers = {placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [3072], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_multiply_1: T_multiply} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:548: Lower Function Start
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:549: fn (%p0: Tensor[(2048, 3072), float32], %p1: Tensor[(768, 3072), float32], %p2: Tensor[(768), float32], %p3: Tensor[(2048, 768), float32], Primitive=1, hash="924abff814ab640f") -> Tensor[(2048, 768), float32] {
  %0 = nn.dense(%p0, %p1, units=None) /* ty=Tensor[(2048, 768), float32] */;
  %1 = nn.bias_add(%0, %p2) /* ty=Tensor[(2048, 768), float32] */;
  add(%1, %p3) /* ty=Tensor[(2048, 768), float32] */
}
[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectPrefetch
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Buffer(matmul_cublas_1: Pointer(float32), float32, [2048, 768], [])] "realize_scope" = "";
  realize(matmul_cublas, [0:2048, 0:768], True {
    attr [[placeholder_12: Buffer(placeholder_13: Pointer(float32), float32, [2048, 3072], []), placeholder_1]] "buffer_bind_scope" = @tir.tvm_tuple(0, 2048, 0, 3072, dtype=handle);
    attr [[placeholder_14: Buffer(placeholder_15: Pointer(float32), float32, [768, 3072], []), placeholder_3]] "buffer_bind_scope" = @tir.tvm_tuple(0, 768, 0, 3072, dtype=handle);
    attr [[matmul_cublas_2: Buffer(matmul_cublas_3: Pointer(float32), float32, [2048, 768], []), matmul_cublas]] "buffer_bind_scope" = @tir.tvm_tuple(0, 2048, 0, 768, dtype=handle);
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_13, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_15, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [T_add] "realize_scope" = "";
    realize(T_add, [0:2048, 0:768], True {
      attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
      attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
      T_add[floordiv((threadIdx.x + (blockIdx.x*1024)), 768), floormod((threadIdx.x + (blockIdx.x*1024)), 768)] = ((matmul_cublas[floordiv((threadIdx.x + (blockIdx.x*1024)), 768), floormod((threadIdx.x + (blockIdx.x*1024)), 768)] + placeholder_2[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + placeholder[floordiv((threadIdx.x + (blockIdx.x*1024)), 768), floormod((threadIdx.x + (blockIdx.x*1024)), 768)])
    })
  })
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageFlatten
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Promote
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16CastElimination
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16TypeLowering
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.BF16Legalize
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.NarrowDataType
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod((threadIdx.x + (blockIdx.x*1024)), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LoopPartition
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VectorizeLoop
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectVirtualThread
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InjectDoubleBuffer
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [2048, 768]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.StorageRewrite
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.UnrollLoop
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RemoveNoOp
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.RewriteUnsafeSelect
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.HoistIfThenElse
primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [768], []),
             placeholder_3: Buffer(placeholder_9: Pointer(float32), float32, [768, 3072], []),
             placeholder: Buffer(placeholder_10: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [2048, 3072], [])}
  buffer_map = {placeholder_7: placeholder, placeholder_4: placeholder_1, placeholder_6: placeholder_2, T_add_1: T_add, placeholder_5: placeholder_3} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_9, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = (((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_8[floormod(((blockIdx.x*1024) + threadIdx.x), 768)]) + (float32*)placeholder_10[((blockIdx.x*1024) + threadIdx.x)])
  }
}


[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:551: Lower Function End
[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:982: LOWER END

[11:43:31] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1157: CODEGEN START

[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}

primfn(placeholder_12: handle, placeholder_13: handle, placeholder_14: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_11: Buffer(placeholder_15: Pointer(float32), float32, [3072], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_10: Buffer(placeholder_16: Pointer(float32), float32, [3072, 768], []),
             placeholder_9: Buffer(placeholder_17: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_12: placeholder_9, placeholder_13: placeholder_10, placeholder_14: placeholder_11, T_multiply_1: T_multiply} {
  attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_1, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_17, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_16, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}

primfn(placeholder_22: handle, placeholder_23: handle, placeholder_24: handle, placeholder_25: handle, T_add_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_3: Buffer(T_add_5: Pointer(float32), float32, [2048, 768], []),
             placeholder_20: Buffer(placeholder_26: Pointer(float32), float32, [768], []),
             placeholder_19: Buffer(placeholder_27: Pointer(float32), float32, [2048, 3072], []),
             placeholder_21: Buffer(placeholder_28: Pointer(float32), float32, [768, 3072], []),
             placeholder_18: Buffer(placeholder_29: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_25: placeholder_18, placeholder_22: placeholder_19, placeholder_24: placeholder_20, T_add_4: T_add_3, placeholder_23: placeholder_21} {
  attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_2, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_27, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_28, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_5[((blockIdx.x_2*1024) + threadIdx.x_2)] = (((float32*)matmul_cublas_2[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)placeholder_26[floormod(((blockIdx.x_2*1024) + threadIdx.x_2), 768)]) + (float32*)placeholder_29[((blockIdx.x_2*1024) + threadIdx.x_2)])
  }
}

primfn(placeholder_31: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_30: Buffer(placeholder_32: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_31: placeholder_30, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_32[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(placeholder_34: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_33: Buffer(placeholder_35: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_34: placeholder_33, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_35[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] = @tir.exp(((float32*)placeholder_35[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_5*8)) + floordiv(threadIdx.x_5, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = ((float32*)T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] + (float32*)T_softmax_exp[(((blockIdx.x_6*131072) + (threadIdx.x_6*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_7*8)) + floordiv(threadIdx.x_7, 128))])
    }
  }
}

primfn(placeholder_38: handle, placeholder_39: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_37: Buffer(placeholder_40: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_36: Buffer(placeholder_41: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_38: placeholder_36, placeholder_39: placeholder_37, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_41, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_40, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_46: handle, placeholder_47: handle, placeholder_48: handle, placeholder_49: handle, T_add_7: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_45: Buffer(placeholder_50: Pointer(float32), float32, [768], []),
             placeholder_43: Buffer(placeholder_51: Pointer(float32), float32, [2048, 768], []),
             placeholder_42: Buffer(placeholder_52: Pointer(float32), float32, [768, 768], []),
             placeholder_44: Buffer(placeholder_53: Pointer(float32), float32, [2048, 768], []),
             T_add_6: Buffer(T_add_8: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {T_add_7: T_add_6, placeholder_47: placeholder_42, placeholder_49: placeholder_43, placeholder_46: placeholder_44, placeholder_48: placeholder_45} {
  attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_3, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_53, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_52, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_8[((blockIdx.x_8*1024) + threadIdx.x_8)] = (((float32*)matmul_cublas_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)placeholder_50[floormod(((blockIdx.x_8*1024) + threadIdx.x_8), 768)]) + (float32*)placeholder_51[((blockIdx.x_8*1024) + threadIdx.x_8)])
  }
}

primfn(placeholder_56: handle, placeholder_57: handle, batch_matmul_cublas_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_55: Buffer(placeholder_58: Pointer(float32), float32, [192, 128, 64], []),
             batch_matmul_cublas_3: Buffer(batch_matmul_cublas_5: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_54: Buffer(placeholder_59: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_56: placeholder_54, placeholder_57: placeholder_55, batch_matmul_cublas_4: batch_matmul_cublas_3} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_59, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_58, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_5, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_61: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_60: Buffer(placeholder_62: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_61: placeholder_60, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_9*1024)) + threadIdx.x_9)] = (float32*)placeholder_62[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*64)) + floormod(threadIdx.x_9, 64))]
  }
}

primfn(placeholder_65: handle, placeholder_66: handle, T_add_10: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_9: Buffer(T_add_11: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_64: Buffer(placeholder_67: Pointer(int32), int32, [16, 128, 128], []),
             placeholder_63: Buffer(placeholder_68: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_65: placeholder_63, placeholder_66: placeholder_64, T_add_10: T_add_9} {
  attr [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_11[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_68[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_67[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.VerifyMemory
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}

primfn(placeholder_12: handle, placeholder_13: handle, placeholder_14: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_11: Buffer(placeholder_15: Pointer(float32), float32, [3072], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_10: Buffer(placeholder_16: Pointer(float32), float32, [3072, 768], []),
             placeholder_9: Buffer(placeholder_17: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_12: placeholder_9, placeholder_13: placeholder_10, placeholder_14: placeholder_11, T_multiply_1: T_multiply} {
  attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_1, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_17, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_16, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}

primfn(placeholder_22: handle, placeholder_23: handle, placeholder_24: handle, placeholder_25: handle, T_add_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_3: Buffer(T_add_5: Pointer(float32), float32, [2048, 768], []),
             placeholder_20: Buffer(placeholder_26: Pointer(float32), float32, [768], []),
             placeholder_19: Buffer(placeholder_27: Pointer(float32), float32, [2048, 3072], []),
             placeholder_21: Buffer(placeholder_28: Pointer(float32), float32, [768, 3072], []),
             placeholder_18: Buffer(placeholder_29: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_25: placeholder_18, placeholder_22: placeholder_19, placeholder_24: placeholder_20, T_add_4: T_add_3, placeholder_23: placeholder_21} {
  attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_2, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_27, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_28, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_5[((blockIdx.x_2*1024) + threadIdx.x_2)] = (((float32*)matmul_cublas_2[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)placeholder_26[floormod(((blockIdx.x_2*1024) + threadIdx.x_2), 768)]) + (float32*)placeholder_29[((blockIdx.x_2*1024) + threadIdx.x_2)])
  }
}

primfn(placeholder_31: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_30: Buffer(placeholder_32: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_31: placeholder_30, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_32[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(placeholder_34: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_33: Buffer(placeholder_35: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_34: placeholder_33, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_35[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] = @tir.exp(((float32*)placeholder_35[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_5*8)) + floordiv(threadIdx.x_5, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = ((float32*)T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] + (float32*)T_softmax_exp[(((blockIdx.x_6*131072) + (threadIdx.x_6*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_7*8)) + floordiv(threadIdx.x_7, 128))])
    }
  }
}

primfn(placeholder_38: handle, placeholder_39: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_37: Buffer(placeholder_40: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_36: Buffer(placeholder_41: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_38: placeholder_36, placeholder_39: placeholder_37, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_41, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_40, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_46: handle, placeholder_47: handle, placeholder_48: handle, placeholder_49: handle, T_add_7: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_45: Buffer(placeholder_50: Pointer(float32), float32, [768], []),
             placeholder_43: Buffer(placeholder_51: Pointer(float32), float32, [2048, 768], []),
             placeholder_42: Buffer(placeholder_52: Pointer(float32), float32, [768, 768], []),
             placeholder_44: Buffer(placeholder_53: Pointer(float32), float32, [2048, 768], []),
             T_add_6: Buffer(T_add_8: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {T_add_7: T_add_6, placeholder_47: placeholder_42, placeholder_49: placeholder_43, placeholder_46: placeholder_44, placeholder_48: placeholder_45} {
  attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_3, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_53, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_52, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_8[((blockIdx.x_8*1024) + threadIdx.x_8)] = (((float32*)matmul_cublas_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)placeholder_50[floormod(((blockIdx.x_8*1024) + threadIdx.x_8), 768)]) + (float32*)placeholder_51[((blockIdx.x_8*1024) + threadIdx.x_8)])
  }
}

primfn(placeholder_56: handle, placeholder_57: handle, batch_matmul_cublas_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_55: Buffer(placeholder_58: Pointer(float32), float32, [192, 128, 64], []),
             batch_matmul_cublas_3: Buffer(batch_matmul_cublas_5: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_54: Buffer(placeholder_59: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_56: placeholder_54, placeholder_57: placeholder_55, batch_matmul_cublas_4: batch_matmul_cublas_3} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_59, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_58, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_5, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_61: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_60: Buffer(placeholder_62: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_61: placeholder_60, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_9*1024)) + threadIdx.x_9)] = (float32*)placeholder_62[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*64)) + floormod(threadIdx.x_9, 64))]
  }
}

primfn(placeholder_65: handle, placeholder_66: handle, T_add_10: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_9: Buffer(T_add_11: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_64: Buffer(placeholder_67: Pointer(int32), int32, [16, 128, 128], []),
             placeholder_63: Buffer(placeholder_68: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_65: placeholder_63, placeholder_66: placeholder_64, T_add_10: T_add_9} {
  attr [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_11[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_68[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_67[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}

primfn(placeholder_12: handle, placeholder_13: handle, placeholder_14: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_11: Buffer(placeholder_15: Pointer(float32), float32, [3072], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_10: Buffer(placeholder_16: Pointer(float32), float32, [3072, 768], []),
             placeholder_9: Buffer(placeholder_17: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_12: placeholder_9, placeholder_13: placeholder_10, placeholder_14: placeholder_11, T_multiply_1: T_multiply} {
  attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_1, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_17, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_16, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}

primfn(placeholder_22: handle, placeholder_23: handle, placeholder_24: handle, placeholder_25: handle, T_add_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_3: Buffer(T_add_5: Pointer(float32), float32, [2048, 768], []),
             placeholder_20: Buffer(placeholder_26: Pointer(float32), float32, [768], []),
             placeholder_19: Buffer(placeholder_27: Pointer(float32), float32, [2048, 3072], []),
             placeholder_21: Buffer(placeholder_28: Pointer(float32), float32, [768, 3072], []),
             placeholder_18: Buffer(placeholder_29: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_25: placeholder_18, placeholder_22: placeholder_19, placeholder_24: placeholder_20, T_add_4: T_add_3, placeholder_23: placeholder_21} {
  attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_2, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_27, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_28, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_5[((blockIdx.x_2*1024) + threadIdx.x_2)] = (((float32*)matmul_cublas_2[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)placeholder_26[floormod(((blockIdx.x_2*1024) + threadIdx.x_2), 768)]) + (float32*)placeholder_29[((blockIdx.x_2*1024) + threadIdx.x_2)])
  }
}

primfn(placeholder_31: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_30: Buffer(placeholder_32: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_31: placeholder_30, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_32[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(placeholder_34: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_33: Buffer(placeholder_35: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_34: placeholder_33, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_35[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] = @tir.exp(((float32*)placeholder_35[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_5*8)) + floordiv(threadIdx.x_5, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = ((float32*)T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] + (float32*)T_softmax_exp[(((blockIdx.x_6*131072) + (threadIdx.x_6*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_7*8)) + floordiv(threadIdx.x_7, 128))])
    }
  }
}

primfn(placeholder_38: handle, placeholder_39: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_37: Buffer(placeholder_40: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_36: Buffer(placeholder_41: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_38: placeholder_36, placeholder_39: placeholder_37, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_41, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_40, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_46: handle, placeholder_47: handle, placeholder_48: handle, placeholder_49: handle, T_add_7: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_45: Buffer(placeholder_50: Pointer(float32), float32, [768], []),
             placeholder_43: Buffer(placeholder_51: Pointer(float32), float32, [2048, 768], []),
             placeholder_42: Buffer(placeholder_52: Pointer(float32), float32, [768, 768], []),
             placeholder_44: Buffer(placeholder_53: Pointer(float32), float32, [2048, 768], []),
             T_add_6: Buffer(T_add_8: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {T_add_7: T_add_6, placeholder_47: placeholder_42, placeholder_49: placeholder_43, placeholder_46: placeholder_44, placeholder_48: placeholder_45} {
  attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_3, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_53, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_52, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_8[((blockIdx.x_8*1024) + threadIdx.x_8)] = (((float32*)matmul_cublas_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)placeholder_50[floormod(((blockIdx.x_8*1024) + threadIdx.x_8), 768)]) + (float32*)placeholder_51[((blockIdx.x_8*1024) + threadIdx.x_8)])
  }
}

primfn(placeholder_56: handle, placeholder_57: handle, batch_matmul_cublas_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_55: Buffer(placeholder_58: Pointer(float32), float32, [192, 128, 64], []),
             batch_matmul_cublas_3: Buffer(batch_matmul_cublas_5: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_54: Buffer(placeholder_59: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_56: placeholder_54, placeholder_57: placeholder_55, batch_matmul_cublas_4: batch_matmul_cublas_3} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_59, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_58, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_5, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_61: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_60: Buffer(placeholder_62: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_61: placeholder_60, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_9*1024)) + threadIdx.x_9)] = (float32*)placeholder_62[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*64)) + floormod(threadIdx.x_9, 64))]
  }
}

primfn(placeholder_65: handle, placeholder_66: handle, T_add_10: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_9: Buffer(T_add_11: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_64: Buffer(placeholder_67: Pointer(int32), int32, [16, 128, 128], []),
             placeholder_63: Buffer(placeholder_68: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_65: placeholder_63, placeholder_66: placeholder_64, T_add_10: T_add_9} {
  attr [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_11[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_68[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_67[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.ThreadSync
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}

primfn(placeholder_12: handle, placeholder_13: handle, placeholder_14: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_11: Buffer(placeholder_15: Pointer(float32), float32, [3072], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_10: Buffer(placeholder_16: Pointer(float32), float32, [3072, 768], []),
             placeholder_9: Buffer(placeholder_17: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_12: placeholder_9, placeholder_13: placeholder_10, placeholder_14: placeholder_11, T_multiply_1: T_multiply} {
  attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_1, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_17, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_16, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}

primfn(placeholder_22: handle, placeholder_23: handle, placeholder_24: handle, placeholder_25: handle, T_add_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_3: Buffer(T_add_5: Pointer(float32), float32, [2048, 768], []),
             placeholder_20: Buffer(placeholder_26: Pointer(float32), float32, [768], []),
             placeholder_19: Buffer(placeholder_27: Pointer(float32), float32, [2048, 3072], []),
             placeholder_21: Buffer(placeholder_28: Pointer(float32), float32, [768, 3072], []),
             placeholder_18: Buffer(placeholder_29: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_25: placeholder_18, placeholder_22: placeholder_19, placeholder_24: placeholder_20, T_add_4: T_add_3, placeholder_23: placeholder_21} {
  attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_2, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_27, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_28, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_5[((blockIdx.x_2*1024) + threadIdx.x_2)] = (((float32*)matmul_cublas_2[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)placeholder_26[floormod(((blockIdx.x_2*1024) + threadIdx.x_2), 768)]) + (float32*)placeholder_29[((blockIdx.x_2*1024) + threadIdx.x_2)])
  }
}

primfn(placeholder_31: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_30: Buffer(placeholder_32: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_31: placeholder_30, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_32[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(placeholder_34: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_33: Buffer(placeholder_35: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_34: placeholder_33, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_35[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] = @tir.exp(((float32*)placeholder_35[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_5*8)) + floordiv(threadIdx.x_5, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = ((float32*)T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] + (float32*)T_softmax_exp[(((blockIdx.x_6*131072) + (threadIdx.x_6*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_7*8)) + floordiv(threadIdx.x_7, 128))])
    }
  }
}

primfn(placeholder_38: handle, placeholder_39: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_37: Buffer(placeholder_40: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_36: Buffer(placeholder_41: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_38: placeholder_36, placeholder_39: placeholder_37, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_41, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_40, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_46: handle, placeholder_47: handle, placeholder_48: handle, placeholder_49: handle, T_add_7: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_45: Buffer(placeholder_50: Pointer(float32), float32, [768], []),
             placeholder_43: Buffer(placeholder_51: Pointer(float32), float32, [2048, 768], []),
             placeholder_42: Buffer(placeholder_52: Pointer(float32), float32, [768, 768], []),
             placeholder_44: Buffer(placeholder_53: Pointer(float32), float32, [2048, 768], []),
             T_add_6: Buffer(T_add_8: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {T_add_7: T_add_6, placeholder_47: placeholder_42, placeholder_49: placeholder_43, placeholder_46: placeholder_44, placeholder_48: placeholder_45} {
  attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_3, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_53, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_52, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_8[((blockIdx.x_8*1024) + threadIdx.x_8)] = (((float32*)matmul_cublas_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)placeholder_50[floormod(((blockIdx.x_8*1024) + threadIdx.x_8), 768)]) + (float32*)placeholder_51[((blockIdx.x_8*1024) + threadIdx.x_8)])
  }
}

primfn(placeholder_56: handle, placeholder_57: handle, batch_matmul_cublas_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_55: Buffer(placeholder_58: Pointer(float32), float32, [192, 128, 64], []),
             batch_matmul_cublas_3: Buffer(batch_matmul_cublas_5: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_54: Buffer(placeholder_59: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_56: placeholder_54, placeholder_57: placeholder_55, batch_matmul_cublas_4: batch_matmul_cublas_3} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_59, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_58, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_5, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_61: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_60: Buffer(placeholder_62: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_61: placeholder_60, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_9*1024)) + threadIdx.x_9)] = (float32*)placeholder_62[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*64)) + floormod(threadIdx.x_9, 64))]
  }
}

primfn(placeholder_65: handle, placeholder_66: handle, T_add_10: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_9: Buffer(T_add_11: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_64: Buffer(placeholder_67: Pointer(int32), int32, [16, 128, 128], []),
             placeholder_63: Buffer(placeholder_68: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_65: placeholder_63, placeholder_66: placeholder_64, T_add_10: T_add_9} {
  attr [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_11[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_68[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_67[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.InferFragment
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}

primfn(placeholder_12: handle, placeholder_13: handle, placeholder_14: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_11: Buffer(placeholder_15: Pointer(float32), float32, [3072], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_10: Buffer(placeholder_16: Pointer(float32), float32, [3072, 768], []),
             placeholder_9: Buffer(placeholder_17: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_12: placeholder_9, placeholder_13: placeholder_10, placeholder_14: placeholder_11, T_multiply_1: T_multiply} {
  attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_1, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_17, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_16, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}

primfn(placeholder_22: handle, placeholder_23: handle, placeholder_24: handle, placeholder_25: handle, T_add_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_3: Buffer(T_add_5: Pointer(float32), float32, [2048, 768], []),
             placeholder_20: Buffer(placeholder_26: Pointer(float32), float32, [768], []),
             placeholder_19: Buffer(placeholder_27: Pointer(float32), float32, [2048, 3072], []),
             placeholder_21: Buffer(placeholder_28: Pointer(float32), float32, [768, 3072], []),
             placeholder_18: Buffer(placeholder_29: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_25: placeholder_18, placeholder_22: placeholder_19, placeholder_24: placeholder_20, T_add_4: T_add_3, placeholder_23: placeholder_21} {
  attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_2, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_27, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_28, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_5[((blockIdx.x_2*1024) + threadIdx.x_2)] = (((float32*)matmul_cublas_2[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)placeholder_26[floormod(((blockIdx.x_2*1024) + threadIdx.x_2), 768)]) + (float32*)placeholder_29[((blockIdx.x_2*1024) + threadIdx.x_2)])
  }
}

primfn(placeholder_31: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_30: Buffer(placeholder_32: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_31: placeholder_30, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_32[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(placeholder_34: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_33: Buffer(placeholder_35: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_34: placeholder_33, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_35[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] = @tir.exp(((float32*)placeholder_35[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_5*8)) + floordiv(threadIdx.x_5, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = ((float32*)T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] + (float32*)T_softmax_exp[(((blockIdx.x_6*131072) + (threadIdx.x_6*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_7*8)) + floordiv(threadIdx.x_7, 128))])
    }
  }
}

primfn(placeholder_38: handle, placeholder_39: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_37: Buffer(placeholder_40: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_36: Buffer(placeholder_41: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_38: placeholder_36, placeholder_39: placeholder_37, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_41, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_40, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_46: handle, placeholder_47: handle, placeholder_48: handle, placeholder_49: handle, T_add_7: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_45: Buffer(placeholder_50: Pointer(float32), float32, [768], []),
             placeholder_43: Buffer(placeholder_51: Pointer(float32), float32, [2048, 768], []),
             placeholder_42: Buffer(placeholder_52: Pointer(float32), float32, [768, 768], []),
             placeholder_44: Buffer(placeholder_53: Pointer(float32), float32, [2048, 768], []),
             T_add_6: Buffer(T_add_8: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {T_add_7: T_add_6, placeholder_47: placeholder_42, placeholder_49: placeholder_43, placeholder_46: placeholder_44, placeholder_48: placeholder_45} {
  attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_3, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_53, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_52, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_8[((blockIdx.x_8*1024) + threadIdx.x_8)] = (((float32*)matmul_cublas_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)placeholder_50[floormod(((blockIdx.x_8*1024) + threadIdx.x_8), 768)]) + (float32*)placeholder_51[((blockIdx.x_8*1024) + threadIdx.x_8)])
  }
}

primfn(placeholder_56: handle, placeholder_57: handle, batch_matmul_cublas_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_55: Buffer(placeholder_58: Pointer(float32), float32, [192, 128, 64], []),
             batch_matmul_cublas_3: Buffer(batch_matmul_cublas_5: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_54: Buffer(placeholder_59: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_56: placeholder_54, placeholder_57: placeholder_55, batch_matmul_cublas_4: batch_matmul_cublas_3} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_59, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_58, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_5, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_61: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_60: Buffer(placeholder_62: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_61: placeholder_60, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_9*1024)) + threadIdx.x_9)] = (float32*)placeholder_62[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*64)) + floormod(threadIdx.x_9, 64))]
  }
}

primfn(placeholder_65: handle, placeholder_66: handle, T_add_10: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_9: Buffer(T_add_11: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_64: Buffer(placeholder_67: Pointer(int32), int32, [16, 128, 128], []),
             placeholder_63: Buffer(placeholder_68: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_65: placeholder_63, placeholder_66: placeholder_64, T_add_10: T_add_9} {
  attr [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_11[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_68[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_67[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerThreadAllreduce
primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(float32), float32, [2048, 768], []),
             placeholder_2: Buffer(placeholder_6: Pointer(float32), float32, [768], []),
             placeholder: Buffer(placeholder_7: Pointer(float32), float32, [2048, 768], []),
             placeholder_1: Buffer(placeholder_8: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add} {
  attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_2[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_6[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
  }
}

primfn(placeholder_12: handle, placeholder_13: handle, placeholder_14: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_11: Buffer(placeholder_15: Pointer(float32), float32, [3072], []),
             T_multiply: Buffer(T_multiply_2: Pointer(float32), float32, [2048, 3072], []),
             placeholder_10: Buffer(placeholder_16: Pointer(float32), float32, [3072, 768], []),
             placeholder_9: Buffer(placeholder_17: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_12: placeholder_9, placeholder_13: placeholder_10, placeholder_14: placeholder_11, T_multiply_1: T_multiply} {
  attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_1, float32, [6291456]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_17, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_16, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_multiply_2[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_15[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
  }
}

primfn(placeholder_22: handle, placeholder_23: handle, placeholder_24: handle, placeholder_25: handle, T_add_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_3: Buffer(T_add_5: Pointer(float32), float32, [2048, 768], []),
             placeholder_20: Buffer(placeholder_26: Pointer(float32), float32, [768], []),
             placeholder_19: Buffer(placeholder_27: Pointer(float32), float32, [2048, 3072], []),
             placeholder_21: Buffer(placeholder_28: Pointer(float32), float32, [768, 3072], []),
             placeholder_18: Buffer(placeholder_29: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_25: placeholder_18, placeholder_22: placeholder_19, placeholder_24: placeholder_20, T_add_4: T_add_3, placeholder_23: placeholder_21} {
  attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_2, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_27, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_28, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_5[((blockIdx.x_2*1024) + threadIdx.x_2)] = (((float32*)matmul_cublas_2[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)placeholder_26[floormod(((blockIdx.x_2*1024) + threadIdx.x_2), 768)]) + (float32*)placeholder_29[((blockIdx.x_2*1024) + threadIdx.x_2)])
  }
}

primfn(placeholder_31: handle, T_transpose_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_transpose: Buffer(T_transpose_2: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_30: Buffer(placeholder_32: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_31: placeholder_30, T_transpose_1: T_transpose} {
  attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose_2[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_32[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(placeholder_34: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_33: Buffer(placeholder_35: Pointer(float32), float32, [16, 12, 128, 128], [])}
  buffer_map = {placeholder_34: placeholder_33, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [24576]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [3145728]) {
    attr [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
      for (k: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_35[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
      }
    }
    attr [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
      T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] = @tir.exp(((float32*)placeholder_35[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_5*8)) + floordiv(threadIdx.x_5, 128))]), dtype=float32)
    }
    attr [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
    attr [IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
      T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = 0f32
      for (k_1: int32, 0, 128) {
        T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = ((float32*)T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] + (float32*)T_softmax_exp[(((blockIdx.x_6*131072) + (threadIdx.x_6*128)) + k_1)])
      }
    }
    attr [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
    attr [IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
      T_softmax_norm_2[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_7*8)) + floordiv(threadIdx.x_7, 128))])
    }
  }
}

primfn(placeholder_38: handle, placeholder_39: handle, batch_matmul_cublas_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {batch_matmul_cublas: Buffer(batch_matmul_cublas_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_37: Buffer(placeholder_40: Pointer(float32), float32, [192, 64, 128], []),
             placeholder_36: Buffer(placeholder_41: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_38: placeholder_36, placeholder_39: placeholder_37, batch_matmul_cublas_1: batch_matmul_cublas} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_41, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_40, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_2, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_46: handle, placeholder_47: handle, placeholder_48: handle, placeholder_49: handle, T_add_7: handle) -> ()
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_45: Buffer(placeholder_50: Pointer(float32), float32, [768], []),
             placeholder_43: Buffer(placeholder_51: Pointer(float32), float32, [2048, 768], []),
             placeholder_42: Buffer(placeholder_52: Pointer(float32), float32, [768, 768], []),
             placeholder_44: Buffer(placeholder_53: Pointer(float32), float32, [2048, 768], []),
             T_add_6: Buffer(T_add_8: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {T_add_7: T_add_6, placeholder_47: placeholder_42, placeholder_49: placeholder_43, placeholder_46: placeholder_44, placeholder_48: placeholder_45} {
  attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
  allocate(matmul_cublas_3, float32, [1572864]) {
    attr [0] "extern_scope" = 0;
    @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_53, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_52, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
    attr [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
    attr [IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
    T_add_8[((blockIdx.x_8*1024) + threadIdx.x_8)] = (((float32*)matmul_cublas_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)placeholder_50[floormod(((blockIdx.x_8*1024) + threadIdx.x_8), 768)]) + (float32*)placeholder_51[((blockIdx.x_8*1024) + threadIdx.x_8)])
  }
}

primfn(placeholder_56: handle, placeholder_57: handle, batch_matmul_cublas_4: handle) -> ()
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_55: Buffer(placeholder_58: Pointer(float32), float32, [192, 128, 64], []),
             batch_matmul_cublas_3: Buffer(batch_matmul_cublas_5: Pointer(float32), float32, [192, 128, 128], []),
             placeholder_54: Buffer(placeholder_59: Pointer(float32), float32, [192, 128, 64], [])}
  buffer_map = {placeholder_56: placeholder_54, placeholder_57: placeholder_55, batch_matmul_cublas_4: batch_matmul_cublas_3} {
  attr [0] "extern_scope" = 0;
  @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_59, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_58, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_5, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
}

primfn(placeholder_61: handle, T_reshape_1: handle) -> ()
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_reshape: Buffer(T_reshape_2: Pointer(float32), float32, [192, 128, 64], []),
             placeholder_60: Buffer(placeholder_62: Pointer(float32), float32, [2048, 768], [])}
  buffer_map = {placeholder_61: placeholder_60, T_reshape_1: T_reshape} {
  attr [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape_2[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_9*1024)) + threadIdx.x_9)] = (float32*)placeholder_62[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*64)) + floormod(threadIdx.x_9, 64))]
  }
}

primfn(placeholder_65: handle, placeholder_66: handle, T_add_10: handle) -> ()
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add_9: Buffer(T_add_11: Pointer(float32), float32, [16, 12, 128, 128], []),
             placeholder_64: Buffer(placeholder_67: Pointer(int32), int32, [16, 128, 128], []),
             placeholder_63: Buffer(placeholder_68: Pointer(float32), float32, [192, 128, 128], [])}
  buffer_map = {placeholder_65: placeholder_63, placeholder_66: placeholder_64, T_add_10: T_add_9} {
  attr [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_11[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_68[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_67[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let T_add: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (768 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (768 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
            @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
            allocate(matmul_cublas, float32, [1572864]) {
              attr [0] "extern_scope" = 0;
              @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_1, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
              attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
              attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
              T_add[((blockIdx.x*1024) + threadIdx.x)] = ((float32*)matmul_cublas[((blockIdx.x*1024) + threadIdx.x)] + (float32*)placeholder_2[floormod(((blockIdx.x*1024) + threadIdx.x), 768)])
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (3072 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
            @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_1, dtype=int32)
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
            allocate(matmul_cublas_1, float32, [6291456]) {
              attr [0] "extern_scope" = 0;
              @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
              attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
              attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
              T_multiply[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_5[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_5[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_5[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add_1", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_2 == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let arg4: handle = @tir.tvm_struct_get(args_2, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids_2[4]
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (3072 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (3072 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (768 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_2 == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
              @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_2, dtype=int32)
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
              allocate(matmul_cublas_2, float32, [1572864]) {
                attr [0] "extern_scope" = 0;
                @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_6, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
                attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
                attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
                T_add_1[((blockIdx.x_2*1024) + threadIdx.x_2)] = (((float32*)matmul_cublas_2[((blockIdx.x_2*1024) + threadIdx.x_2)] + (float32*)placeholder_8[floormod(((blockIdx.x_2*1024) + threadIdx.x_2), 768)]) + (float32*)placeholder_9[((blockIdx.x_2*1024) + threadIdx.x_2)])
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"global_symbol": "fused_reshape_transpose_reshape_transpose", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_3;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_3, dtype=int32)
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_";
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
          T_transpose[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_10[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
        }
      }
    }
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_4;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_4, dtype=int32)
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_maxelem, float32, [24576]);
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_exp, float32, [3145728]) {
          attr [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
          attr [IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
            T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
            for (k: int32, 0, 128) {
              T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_11[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
            }
          }
          attr [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
          attr [IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
          for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
            T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] = @tir.exp(((float32*)placeholder_11[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x_5*8)) + floordiv(threadIdx.x_5, 128))]), dtype=float32)
          }
          attr [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
          attr [IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
            T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = 0f32
            for (k_1: int32, 0, 128) {
              T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] = ((float32*)T_softmax_maxelem[((blockIdx.x_6*1024) + threadIdx.x_6)] + (float32*)T_softmax_exp[(((blockIdx.x_6*131072) + (threadIdx.x_6*128)) + k_1)])
            }
          }
          attr [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
          attr [IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
          for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
            T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] = ((float32*)T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_7*1024)) + threadIdx.x_7)] / (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_7*8)) + floordiv(threadIdx.x_7, 128))])
          }
        }
      }
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"global_symbol": "fused_nn_batch_matmul_1", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_13: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_13] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_5;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_5, dtype=int32)
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0;
          @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_12, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_13, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"global_symbol": "fused_nn_dense_nn_bias_add_add", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_6 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_6, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_6[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_6, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_6[4]
  let placeholder_14: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_14] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_15: Pointer(float32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_15] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  let placeholder_17: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_17] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  attr ["default"] "device_id" = dev_id_6;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_6[1])) && (768 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_6[1])) && (768 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_4[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_6 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_6 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
              @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_6, dtype=int32)
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
              allocate(matmul_cublas_3, float32, [1572864]) {
                attr [0] "extern_scope" = 0;
                @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_14, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_15, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
                attr [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
                attr [IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
                T_add_2[((blockIdx.x_8*1024) + threadIdx.x_8)] = (((float32*)matmul_cublas_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)placeholder_16[floormod(((blockIdx.x_8*1024) + threadIdx.x_8), 768)]) + (float32*)placeholder_17[((blockIdx.x_8*1024) + threadIdx.x_8)])
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"global_symbol": "fused_nn_batch_matmul", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_19: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_19] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_7;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_7, dtype=int32)
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0;
          @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_18, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_19, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_1, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"global_symbol": "fused_reshape_transpose_reshape", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_8 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let T_reshape: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [T_reshape] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_8;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_8[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_8[2])) && (64 == cast(int32, (int64*)arg1.strides_8[1]))) && (8192 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_8, dtype=int32)
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_";
        attr [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
        attr [IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
        for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
          T_reshape[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_9*1024)) + threadIdx.x_9)] = (float32*)placeholder_20[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_9*16) + floordiv(threadIdx.x_9, 64)), 128)), 12)*64)) + floormod(threadIdx.x_9, 64))]
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args_9 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_9, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_9[2]
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let placeholder_22: Pointer(int32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  let T_add_3: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [T_add_3] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_9;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_9[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_9[2])) && (128 == cast(int32, (int64*)arg0.strides_9[1]))) && (16384 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (128 == cast(int32, (int64*)arg1.strides_9[1]))) && (16384 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_6[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_6[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_6[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_6[3])) && (128 == cast(int32, (int64*)arg2.strides_6[2]))) && (16384 == cast(int32, (int64*)arg2.strides_6[1]))) && (196608 == cast(int32, (int64*)arg2.strides_6[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_9 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_9, dtype=int32)
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_";
          attr [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
          attr [IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
          for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
            T_add_3[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_21[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_22[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
          }
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.SplitHostDevice
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
    T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.exp(((float32*)placeholder[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x*8)) + floordiv(threadIdx.x, 128))]), dtype=float32)
  }
}

primfn(T_add: Pointer(float32), matmul_cublas: Pointer(float32), placeholder_1: Pointer(float32), placeholder_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_1_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_1[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 768)]) + (float32*)placeholder_2[((blockIdx.x_1*1024) + threadIdx.x_1)])
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_1: Pointer(float32), T_softmax_maxelem_1: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
    T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] = ((float32*)T_softmax_exp_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] / (float32*)T_softmax_maxelem_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_2*8)) + floordiv(threadIdx.x_2, 128))])
  }
}

primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add_1", "calling_conv": 1} {
  assert((num_args == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let arg4: handle = @tir.tvm_struct_get(args, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids[4]
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (3072 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (3072 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
              @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
              allocate(matmul_cublas_1, float32, [1572864]) {
                attr [0] "extern_scope" = 0;
                @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_3, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
                @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_add_1_kernel0", T_add_1, matmul_cublas_1, placeholder_5, placeholder_6, 1536, 1024, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add", "calling_conv": 1} {
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (768 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
            @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_1, dtype=int32)
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
            allocate(matmul_cublas_2, float32, [1572864]) {
              attr [0] "extern_scope" = 0;
              @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
              @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_kernel0", T_add_2, matmul_cublas_2, placeholder_9, 1536, 1024, dtype=int32)
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "calling_conv": 1} {
  assert((num_args_2 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (768 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (768 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (3072 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
            @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_2, dtype=int32)
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
            allocate(matmul_cublas_3, float32, [6291456]) {
              attr [0] "extern_scope" = 0;
              @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_10, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_11, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
              @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", T_multiply, matmul_cublas_3, placeholder_12, 6144, 1024, dtype=int32)
            }
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_13: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_2[((blockIdx.x_3*1024) + threadIdx.x_3)] = -3.40282e+38f32
    for (k: int32, 0, 128) {
      T_softmax_maxelem_2[((blockIdx.x_3*1024) + threadIdx.x_3)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_3*1024) + threadIdx.x_3)], (float32*)placeholder_13[(((blockIdx.x_3*131072) + (threadIdx.x_3*128)) + k)])
    }
  }
}

primfn(T_multiply_1: Pointer(float32), matmul_cublas_4: Pointer(float32), placeholder_14: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_4, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
  attr [IterVar(threadIdx.x_4, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_multiply_1[((blockIdx.x_4*1024) + threadIdx.x_4)] = (((float32*)matmul_cublas_4[((blockIdx.x_4*1024) + threadIdx.x_4)] + (float32*)placeholder_14[floormod(((blockIdx.x_4*1024) + threadIdx.x_4), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_4[((blockIdx.x_4*1024) + threadIdx.x_4)] + (float32*)placeholder_14[floormod(((blockIdx.x_4*1024) + threadIdx.x_4), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_4[((blockIdx.x_4*1024) + threadIdx.x_4)] + (float32*)placeholder_14[floormod(((blockIdx.x_4*1024) + threadIdx.x_4), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
}

primfn(T_reshape: Pointer(float32), placeholder_15: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_5, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_5, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_reshape[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_5*1024)) + threadIdx.x_5)] = (float32*)placeholder_15[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_5*16) + floordiv(threadIdx.x_5, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_5*16) + floordiv(threadIdx.x_5, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_5*16) + floordiv(threadIdx.x_5, 64)), 128)), 12)*64)) + floormod(threadIdx.x_5, 64))]
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape_transpose", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_3;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_3, dtype=int32)
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_";
        @tir.tvm_call_packed("fused_reshape_transpose_reshape_transpose_kernel0", T_transpose, placeholder_16, 256, 1024, dtype=int32)
      }
    }
  }
}

primfn(T_transpose_1: Pointer(float32), placeholder_17: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_transpose_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_6, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_6, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_transpose_1[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_6*1024)) + threadIdx.x_6)] = (float32*)placeholder_17[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*8) + floordiv(threadIdx.x_6, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_6, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*8) + floordiv(threadIdx.x_6, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_6*8) + floordiv(threadIdx.x_6, 128)), 64))]
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm_1: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm_1] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_4;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_4, dtype=int32)
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem_3: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_maxelem_3, float32, [24576]);
        attr [T_softmax_exp_2: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_exp_2, float32, [3145728]) {
          @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem_3, placeholder_18, 24, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp_2, placeholder_18, T_softmax_maxelem_3, 256, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem_3, T_softmax_exp_2, 24, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm_1, T_softmax_exp_2, T_softmax_maxelem_3, 256, 1024, dtype=int32)
        }
      }
    }
  }
}

primfn(T_add_3: Pointer(float32), matmul_cublas_5: Pointer(float32), placeholder_19: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_7, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_7, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_3[((blockIdx.x_7*1024) + threadIdx.x_7)] = ((float32*)matmul_cublas_5[((blockIdx.x_7*1024) + threadIdx.x_7)] + (float32*)placeholder_19[floormod(((blockIdx.x_7*1024) + threadIdx.x_7), 768)])
}

primfn(T_softmax_maxelem_4: Pointer(float32), T_softmax_exp_3: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_8, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_8, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_4[((blockIdx.x_8*1024) + threadIdx.x_8)] = 0f32
    for (k_1: int32, 0, 128) {
      T_softmax_maxelem_4[((blockIdx.x_8*1024) + threadIdx.x_8)] = ((float32*)T_softmax_maxelem_4[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)T_softmax_exp_3[(((blockIdx.x_8*131072) + (threadIdx.x_8*128)) + k_1)])
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul_1", "calling_conv": 1} {
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_5;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_5, dtype=int32)
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0;
          @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_20, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_21, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "calling_conv": 1} {
  assert((num_args_6 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let placeholder_22: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_23: Pointer(int32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_23] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let T_add_4: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [T_add_4] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_6;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_6[2])) && (128 == cast(int32, (int64*)arg0.strides_6[1]))) && (16384 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_6[2])) && (128 == cast(int32, (int64*)arg1.strides_6[1]))) && (16384 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_4[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_4[3])) && (128 == cast(int32, (int64*)arg2.strides_4[2]))) && (16384 == cast(int32, (int64*)arg2.strides_4[1]))) && (196608 == cast(int32, (int64*)arg2.strides_4[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_6, dtype=int32)
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_";
          @tir.tvm_call_packed("fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", T_add_4, placeholder_22, placeholder_23, 256, 1024, dtype=int32)
        }
      }
    }
  }
}

primfn(T_add_5: Pointer(float32), matmul_cublas_6: Pointer(float32), placeholder_24: Pointer(float32), placeholder_25: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_9, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_9, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_5[((blockIdx.x_9*1024) + threadIdx.x_9)] = (((float32*)matmul_cublas_6[((blockIdx.x_9*1024) + threadIdx.x_9)] + (float32*)placeholder_24[floormod(((blockIdx.x_9*1024) + threadIdx.x_9), 768)]) + (float32*)placeholder_25[((blockIdx.x_9*1024) + threadIdx.x_9)])
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul", "calling_conv": 1} {
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_26: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_26] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_27: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_27] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_7;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_7, dtype=int32)
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0;
          @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_26, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_27, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_1, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add", "calling_conv": 1} {
  assert((num_args_8 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_8, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_8[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_8, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_8[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_8, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_8[4]
  let placeholder_28: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_28] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let placeholder_29: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [placeholder_29] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  let placeholder_30: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [placeholder_30] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  let placeholder_31: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_31] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_6: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_6] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  attr ["default"] "device_id" = dev_id_8;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_8[1])) && (768 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_6[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_8 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_8 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_8 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
              @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_8, dtype=int32)
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_7: Pointer(float32)] "storage_scope" = "global";
              allocate(matmul_cublas_7, float32, [1572864]) {
                attr [0] "extern_scope" = 0;
                @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_28, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_29, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
                @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_add_kernel0", T_add_6, matmul_cublas_7, placeholder_30, placeholder_31, 1536, 1024, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape", "calling_conv": 1} {
  assert((num_args_9 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let placeholder_32: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_32] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let T_reshape_1: Pointer(float32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [T_reshape_1] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_9;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_9[1])) && (768 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (64 == cast(int32, (int64*)arg1.strides_9[1]))) && (8192 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_9, dtype=int32)
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_";
        @tir.tvm_call_packed("fused_reshape_transpose_reshape_kernel0", T_reshape_1, placeholder_32, 256, 1024, dtype=int32)
      }
    }
  }
}

primfn(T_add_7: Pointer(float32), placeholder_33: Pointer(float32), placeholder_34: Pointer(int32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_10, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_7[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_33[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_34[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add_1", "calling_conv": 1} {
  assert((num_args == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let arg4: handle = @tir.tvm_struct_get(args, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids[4]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  let T_add: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (3072 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (3072 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
              @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
              allocate(matmul_cublas, float32, [1572864]) {
                attr [0] "extern_scope" = 0;
                @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_1, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
                @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_add_1_kernel0", T_add, matmul_cublas, placeholder_2, placeholder_3, 1536, 1024, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add", "calling_conv": 1} {
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (768 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
            @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_1, dtype=int32)
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
            allocate(matmul_cublas_1, float32, [1572864]) {
              attr [0] "extern_scope" = 0;
              @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
              @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_kernel0", T_add_1, matmul_cublas_1, placeholder_6, 1536, 1024, dtype=int32)
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "calling_conv": 1} {
  assert((num_args_2 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (768 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (768 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (3072 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
            @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_2, dtype=int32)
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
            allocate(matmul_cublas_2, float32, [6291456]) {
              attr [0] "extern_scope" = 0;
              @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
              @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", T_multiply, matmul_cublas_2, placeholder_9, 6144, 1024, dtype=int32)
            }
          }
        }
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape_transpose", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_3;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_3, dtype=int32)
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_";
        @tir.tvm_call_packed("fused_reshape_transpose_reshape_transpose_kernel0", T_transpose, placeholder_10, 256, 1024, dtype=int32)
      }
    }
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_4;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_4, dtype=int32)
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_maxelem, float32, [24576]);
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_exp, float32, [3145728]) {
          @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem, placeholder_11, 24, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp, placeholder_11, T_softmax_maxelem, 256, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem, T_softmax_exp, 24, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm, T_softmax_exp, T_softmax_maxelem, 256, 1024, dtype=int32)
        }
      }
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul_1", "calling_conv": 1} {
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_13: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_13] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_5;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_5, dtype=int32)
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0;
          @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_12, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_13, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "calling_conv": 1} {
  assert((num_args_6 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let placeholder_14: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_14] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_15: Pointer(int32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_15] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_6;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_6[2])) && (128 == cast(int32, (int64*)arg0.strides_6[1]))) && (16384 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_6[2])) && (128 == cast(int32, (int64*)arg1.strides_6[1]))) && (16384 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_4[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_4[3])) && (128 == cast(int32, (int64*)arg2.strides_4[2]))) && (16384 == cast(int32, (int64*)arg2.strides_4[1]))) && (196608 == cast(int32, (int64*)arg2.strides_4[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_6, dtype=int32)
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_";
          @tir.tvm_call_packed("fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", T_add_2, placeholder_14, placeholder_15, 256, 1024, dtype=int32)
        }
      }
    }
  }
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul", "calling_conv": 1} {
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_17: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_17] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_7;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_7, dtype=int32)
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0;
          @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_16, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_17, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_1, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add", "calling_conv": 1} {
  assert((num_args_8 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_8, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_8[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_8, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_8[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_8, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_8[4]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let placeholder_19: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [placeholder_19] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_3: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_3] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  attr ["default"] "device_id" = dev_id_8;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_8[1])) && (768 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_6[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_8 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_8 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_8 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
              @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_8, dtype=int32)
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
              allocate(matmul_cublas_3, float32, [1572864]) {
                attr [0] "extern_scope" = 0;
                @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_18, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_19, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
                @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_add_kernel0", T_add_3, matmul_cublas_3, placeholder_20, placeholder_21, 1536, 1024, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape", "calling_conv": 1} {
  assert((num_args_9 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let placeholder_22: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let T_reshape: Pointer(float32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [T_reshape] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_9;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_9[1])) && (768 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (64 == cast(int32, (int64*)arg1.strides_9[1]))) && (8192 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_9, dtype=int32)
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_";
        @tir.tvm_call_packed("fused_reshape_transpose_reshape_kernel0", T_reshape, placeholder_22, 256, 1024, dtype=int32)
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add_1", "calling_conv": 1} {
  assert((num_args == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let arg4: handle = @tir.tvm_struct_get(args, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids[4]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  let T_add: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (3072 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (3072 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
              @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
              allocate(matmul_cublas, float32, [1572864]) {
                attr [0] "extern_scope" = 0;
                @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_1, @tir.tvm_stack_make_shape(768, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
                @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_add_1_kernel0", T_add, matmul_cublas, placeholder_2, placeholder_3, 1536, 1024, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add", "calling_conv": 1} {
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  attr ["default"] "device_id" = dev_id_1;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (768 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
            @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_1, dtype=int32)
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
            allocate(matmul_cublas_1, float32, [1572864]) {
              attr [0] "extern_scope" = 0;
              @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_4, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_5, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_1, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
              @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_kernel0", T_add_1, matmul_cublas_1, placeholder_6, 1536, 1024, dtype=int32)
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "calling_conv": 1} {
  assert((num_args_2 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  attr ["default"] "device_id" = dev_id_2;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (768 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (768 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (3072 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
            @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_2, dtype=int32)
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
            allocate(matmul_cublas_2, float32, [6291456]) {
              attr [0] "extern_scope" = 0;
              @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_7, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_8, @tir.tvm_stack_make_shape(3072, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_2, @tir.tvm_stack_make_shape(2048, 3072, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
              @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", T_multiply, matmul_cublas_2, placeholder_9, 6144, 1024, dtype=int32)
            }
          }
        }
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape_transpose", "calling_conv": 1} {
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_3;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_3, dtype=int32)
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_";
        @tir.tvm_call_packed("fused_reshape_transpose_reshape_transpose_kernel0", T_transpose, placeholder_10, 256, 1024, dtype=int32)
      }
    }
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_4;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_4, dtype=int32)
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_maxelem, float32, [24576]);
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        allocate(T_softmax_exp, float32, [3145728]) {
          @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem, placeholder_11, 24, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp, placeholder_11, T_softmax_maxelem, 256, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem, T_softmax_exp, 24, 1024, dtype=int32)
          @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm, T_softmax_exp, T_softmax_maxelem, 256, 1024, dtype=int32)
        }
      }
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul_1", "calling_conv": 1} {
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_13: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_13] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_5;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_5, dtype=int32)
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0;
          @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_12, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_13, @tir.tvm_stack_make_shape(192, 64, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "calling_conv": 1} {
  assert((num_args_6 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let placeholder_14: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_14] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_15: Pointer(int32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_15] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_6;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_6[2])) && (128 == cast(int32, (int64*)arg0.strides_6[1]))) && (16384 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_6[2])) && (128 == cast(int32, (int64*)arg1.strides_6[1]))) && (16384 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_4[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_4[3])) && (128 == cast(int32, (int64*)arg2.strides_4[2]))) && (16384 == cast(int32, (int64*)arg2.strides_4[1]))) && (196608 == cast(int32, (int64*)arg2.strides_4[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_6, dtype=int32)
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_";
          @tir.tvm_call_packed("fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", T_add_2, placeholder_14, placeholder_15, 256, 1024, dtype=int32)
        }
      }
    }
  }
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul", "calling_conv": 1} {
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_17: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_17] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id_7;
  attr ["default"] "device_type" = 2;
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
          @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_7, dtype=int32)
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0;
          @tir.tvm_call_packed("tvm.contrib.cublas.batch_matmul", @tir.tvm_stack_make_array(placeholder_16, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_17, @tir.tvm_stack_make_shape(192, 128, 64, dtype=handle), 0, 3, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(batch_matmul_cublas_1, @tir.tvm_stack_make_shape(192, 128, 128, dtype=handle), 0, 3, 0f32, 0, dtype=handle), False, True, dtype=int32)
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add", "calling_conv": 1} {
  assert((num_args_8 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_8, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_8[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_8, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_8[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_8, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_8[4]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let placeholder_19: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [placeholder_19] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_3: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_3] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  attr ["default"] "device_id" = dev_id_8;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_8[1])) && (768 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_6[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_8 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_8 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_8 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
              @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_8, dtype=int32)
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
              allocate(matmul_cublas_3, float32, [1572864]) {
                attr [0] "extern_scope" = 0;
                @tir.tvm_call_packed("tvm.contrib.cublas.matmul", @tir.tvm_stack_make_array(placeholder_18, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(placeholder_19, @tir.tvm_stack_make_shape(768, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), @tir.tvm_stack_make_array(matmul_cublas_3, @tir.tvm_stack_make_shape(2048, 768, dtype=handle), 0, 2, 0f32, 0, dtype=handle), False, True, dtype=int32)
                @tir.tvm_call_packed("fused_nn_dense_nn_bias_add_add_kernel0", T_add_3, matmul_cublas_3, placeholder_20, placeholder_21, 1536, 1024, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape", "calling_conv": 1} {
  assert((num_args_9 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let placeholder_22: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let T_reshape: Pointer(float32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [T_reshape] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id_9;
  attr ["default"] "device_type" = 2;
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_9[1])) && (768 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (64 == cast(int32, (int64*)arg1.strides_9[1]))) && (8192 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
        @tir.tvm_call_packed("__tvm_set_device", 2, dev_id_9, dtype=int32)
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_";
        @tir.tvm_call_packed("fused_reshape_transpose_reshape_kernel0", T_reshape, placeholder_22, 256, 1024, dtype=int32)
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add_1", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let arg4: handle = @tir.tvm_struct_get(args, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids[4]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  let T_add: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (3072 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (3072 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode[0] = 0
                @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
                stack_tcode[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas] "storage_alignment" = 128 {
                let matmul_cublas = @tir.TVMBackendAllocWorkspace(2, dev_id, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape[0] = 2048i64
                      stack_shape[1] = 3072i64
                      @tir.tvm_struct_set(stack_array, 0, 1, placeholder, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 2, @tir.address_of((int64*)stack_shape[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 10, 2, dtype=int32)
                      stack_shape[2] = 768i64
                      stack_shape[3] = 3072i64
                      @tir.tvm_struct_set(stack_array, 1, 1, placeholder_1, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 2, @tir.address_of((int64*)stack_shape[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 10, 2, dtype=int32)
                      stack_shape[4] = 2048i64
                      stack_shape[5] = 768i64
                      @tir.tvm_struct_set(stack_array, 2, 1, matmul_cublas, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 2, @tir.address_of((int64*)stack_shape[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value, 0, 12, @tir.tvm_struct_get(stack_array, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode[0] = 7
                      @tir.tvm_struct_set(stack_value, 1, 12, @tir.tvm_struct_get(stack_array, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode[1] = 7
                      @tir.tvm_struct_set(stack_value, 2, 12, @tir.tvm_struct_get(stack_array, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode[2] = 7
                      @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode[3] = 0
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value, stack_tcode, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value, 0, 12, T_add, dtype=int32)
                      stack_tcode[0] = 3
                      @tir.tvm_struct_set(stack_value, 1, 12, matmul_cublas, dtype=int32)
                      stack_tcode[1] = 3
                      @tir.tvm_struct_set(stack_value, 2, 12, placeholder_2, dtype=int32)
                      stack_tcode[2] = 3
                      @tir.tvm_struct_set(stack_value, 3, 12, placeholder_3, dtype=int32)
                      stack_tcode[3] = 3
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_1_kernel0", stack_value, stack_tcode, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id, matmul_cublas, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add", "calling_conv": 1} {
  let stack_tcode_1: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_1: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_1: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_1: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (768 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_1, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_1[0] = 0
              @tir.tvm_struct_set(stack_value_1, 1, 12, cast(int64, dev_id_1), dtype=int32)
              stack_tcode_1[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_1, stack_tcode_1, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_1] "storage_alignment" = 128 {
              let matmul_cublas_1 = @tir.TVMBackendAllocWorkspace(2, dev_id_1, 6291456u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_1, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_1[0] = 2048i64
                    stack_shape_1[1] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 0, 1, placeholder_4, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 2, @tir.address_of((int64*)stack_shape_1[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 10, 2, dtype=int32)
                    stack_shape_1[2] = 768i64
                    stack_shape_1[3] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 1, 1, placeholder_5, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 2, @tir.address_of((int64*)stack_shape_1[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 10, 2, dtype=int32)
                    stack_shape_1[4] = 2048i64
                    stack_shape_1[5] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 2, 1, matmul_cublas_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 2, @tir.address_of((int64*)stack_shape_1[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_1, 0, 12, @tir.tvm_struct_get(stack_array_1, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[0] = 7
                    @tir.tvm_struct_set(stack_value_1, 1, 12, @tir.tvm_struct_get(stack_array_1, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[1] = 7
                    @tir.tvm_struct_set(stack_value_1, 2, 12, @tir.tvm_struct_get(stack_array_1, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[2] = 7
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_1, 0, 12, T_add_1, dtype=int32)
                    stack_tcode_1[0] = 3
                    @tir.tvm_struct_set(stack_value_1, 1, 12, matmul_cublas_1, dtype=int32)
                    stack_tcode_1[1] = 3
                    @tir.tvm_struct_set(stack_value_1, 2, 12, placeholder_6, dtype=int32)
                    stack_tcode_1[2] = 3
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, 1536), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_kernel0", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_1, matmul_cublas_1, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "calling_conv": 1} {
  let stack_tcode_2: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_2: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_2: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_2: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_2 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (768 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (768 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (3072 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_2, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_2[0] = 0
              @tir.tvm_struct_set(stack_value_2, 1, 12, cast(int64, dev_id_2), dtype=int32)
              stack_tcode_2[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_2, stack_tcode_2, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_2] "storage_alignment" = 128 {
              let matmul_cublas_2 = @tir.TVMBackendAllocWorkspace(2, dev_id_2, 25165824u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_2, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_2[0] = 2048i64
                    stack_shape_2[1] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 0, 1, placeholder_7, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 2, @tir.address_of((int64*)stack_shape_2[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 10, 2, dtype=int32)
                    stack_shape_2[2] = 3072i64
                    stack_shape_2[3] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 1, 1, placeholder_8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 2, @tir.address_of((int64*)stack_shape_2[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 10, 2, dtype=int32)
                    stack_shape_2[4] = 2048i64
                    stack_shape_2[5] = 3072i64
                    @tir.tvm_struct_set(stack_array_2, 2, 1, matmul_cublas_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 2, @tir.address_of((int64*)stack_shape_2[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_2, 0, 12, @tir.tvm_struct_get(stack_array_2, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[0] = 7
                    @tir.tvm_struct_set(stack_value_2, 1, 12, @tir.tvm_struct_get(stack_array_2, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[1] = 7
                    @tir.tvm_struct_set(stack_value_2, 2, 12, @tir.tvm_struct_get(stack_array_2, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[2] = 7
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_2, 0, 12, T_multiply, dtype=int32)
                    stack_tcode_2[0] = 3
                    @tir.tvm_struct_set(stack_value_2, 1, 12, matmul_cublas_2, dtype=int32)
                    stack_tcode_2[1] = 3
                    @tir.tvm_struct_set(stack_value_2, 2, 12, placeholder_9, dtype=int32)
                    stack_tcode_2[2] = 3
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, 6144), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_2, matmul_cublas_2, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape_transpose", "calling_conv": 1} {
  let stack_tcode_3: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_3: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_3, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_3[0] = 0
          @tir.tvm_struct_set(stack_value_3, 1, 12, cast(int64, dev_id_3), dtype=int32)
          stack_tcode_3[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_3, stack_tcode_3, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_" {
          @tir.tvm_struct_set(stack_value_3, 0, 12, T_transpose, dtype=int32)
          stack_tcode_3[0] = 3
          @tir.tvm_struct_set(stack_value_3, 1, 12, placeholder_10, dtype=int32)
          stack_tcode_3[1] = 3
          @tir.tvm_struct_set(stack_value_3, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_3[2] = 0
          @tir.tvm_struct_set(stack_value_3, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_3[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_transpose_kernel0", stack_value_3, stack_tcode_3, 0, 4, dtype=int32)
        }
      }
    }
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode_4: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_4: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_4, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_4[0] = 0
          @tir.tvm_struct_set(stack_value_4, 1, 12, cast(int64, dev_id_4), dtype=int32)
          stack_tcode_4[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_4, stack_tcode_4, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_maxelem] "storage_alignment" = 128 {
          let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 98304u64, 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
            attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
            attr [T_softmax_exp] "storage_alignment" = 128 {
              let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 12582912u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(T_softmax_exp, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_norm, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_exp, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_maxelem, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul_1", "calling_conv": 1} {
  let stack_tcode_5: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_5: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_3: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_3: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_13: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_13] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_5, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_5[0] = 0
            @tir.tvm_struct_set(stack_value_5, 1, 12, cast(int64, dev_id_5), dtype=int32)
            stack_tcode_5[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_5, stack_tcode_5, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_3[0] = 192i64
            stack_shape_3[1] = 128i64
            stack_shape_3[2] = 128i64
            @tir.tvm_struct_set(stack_array_3, 0, 1, placeholder_12, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 2, @tir.address_of((int64*)stack_shape_3[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 10, 2, dtype=int32)
            stack_shape_3[3] = 192i64
            stack_shape_3[4] = 64i64
            stack_shape_3[5] = 128i64
            @tir.tvm_struct_set(stack_array_3, 1, 1, placeholder_13, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 2, @tir.address_of((int64*)stack_shape_3[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 10, 2, dtype=int32)
            stack_shape_3[6] = 192i64
            stack_shape_3[7] = 128i64
            stack_shape_3[8] = 64i64
            @tir.tvm_struct_set(stack_array_3, 2, 1, batch_matmul_cublas, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 2, @tir.address_of((int64*)stack_shape_3[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_5, 0, 12, @tir.tvm_struct_get(stack_array_3, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_5[0] = 7
            @tir.tvm_struct_set(stack_value_5, 1, 12, @tir.tvm_struct_get(stack_array_3, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_5[1] = 7
            @tir.tvm_struct_set(stack_value_5, 2, 12, @tir.tvm_struct_get(stack_array_3, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_5[2] = 7
            @tir.tvm_struct_set(stack_value_5, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_5[3] = 0
            @tir.tvm_struct_set(stack_value_5, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_5[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_5, stack_tcode_5, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "calling_conv": 1} {
  let stack_tcode_6: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_6: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_6 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let placeholder_14: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_14] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_15: Pointer(int32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_15] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_6[2])) && (128 == cast(int32, (int64*)arg0.strides_6[1]))) && (16384 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_6[2])) && (128 == cast(int32, (int64*)arg1.strides_6[1]))) && (16384 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_4[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_4[3])) && (128 == cast(int32, (int64*)arg2.strides_4[2]))) && (16384 == cast(int32, (int64*)arg2.strides_4[1]))) && (196608 == cast(int32, (int64*)arg2.strides_4[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_6, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_6[0] = 0
            @tir.tvm_struct_set(stack_value_6, 1, 12, cast(int64, dev_id_6), dtype=int32)
            stack_tcode_6[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_6, stack_tcode_6, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_" {
            @tir.tvm_struct_set(stack_value_6, 0, 12, T_add_2, dtype=int32)
            stack_tcode_6[0] = 3
            @tir.tvm_struct_set(stack_value_6, 1, 12, placeholder_14, dtype=int32)
            stack_tcode_6[1] = 3
            @tir.tvm_struct_set(stack_value_6, 2, 12, placeholder_15, dtype=int32)
            stack_tcode_6[2] = 3
            @tir.tvm_struct_set(stack_value_6, 3, 12, cast(int64, 256), dtype=int32)
            stack_tcode_6[3] = 0
            @tir.tvm_struct_set(stack_value_6, 4, 12, cast(int64, 1024), dtype=int32)
            stack_tcode_6[4] = 0
            @tir.tvm_call_packed_lowered("fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", stack_value_6, stack_tcode_6, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul", "calling_conv": 1} {
  let stack_tcode_7: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_7: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_4: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_4: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_17: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_17] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_7, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_7[0] = 0
            @tir.tvm_struct_set(stack_value_7, 1, 12, cast(int64, dev_id_7), dtype=int32)
            stack_tcode_7[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_7, stack_tcode_7, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_4[0] = 192i64
            stack_shape_4[1] = 128i64
            stack_shape_4[2] = 64i64
            @tir.tvm_struct_set(stack_array_4, 0, 1, placeholder_16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 2, @tir.address_of((int64*)stack_shape_4[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 10, 2, dtype=int32)
            stack_shape_4[3] = 192i64
            stack_shape_4[4] = 128i64
            stack_shape_4[5] = 64i64
            @tir.tvm_struct_set(stack_array_4, 1, 1, placeholder_17, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 2, @tir.address_of((int64*)stack_shape_4[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 10, 2, dtype=int32)
            stack_shape_4[6] = 192i64
            stack_shape_4[7] = 128i64
            stack_shape_4[8] = 128i64
            @tir.tvm_struct_set(stack_array_4, 2, 1, batch_matmul_cublas_1, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 2, @tir.address_of((int64*)stack_shape_4[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_7, 0, 12, @tir.tvm_struct_get(stack_array_4, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_7[0] = 7
            @tir.tvm_struct_set(stack_value_7, 1, 12, @tir.tvm_struct_get(stack_array_4, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_7[1] = 7
            @tir.tvm_struct_set(stack_value_7, 2, 12, @tir.tvm_struct_get(stack_array_4, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_7[2] = 7
            @tir.tvm_struct_set(stack_value_7, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_7[3] = 0
            @tir.tvm_struct_set(stack_value_7, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_7[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_7, stack_tcode_7, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add", "calling_conv": 1} {
  let stack_tcode_8: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value_8: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array_5: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_5: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_8 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_8, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_8[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_8, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_8[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_8, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_8[4]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let placeholder_19: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [placeholder_19] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_3: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_3] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_8[1])) && (768 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_6[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_8 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_8 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_8 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value_8, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode_8[0] = 0
                @tir.tvm_struct_set(stack_value_8, 1, 12, cast(int64, dev_id_8), dtype=int32)
                stack_tcode_8[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_8, stack_tcode_8, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas_3] "storage_alignment" = 128 {
                let matmul_cublas_3 = @tir.TVMBackendAllocWorkspace(2, dev_id_8, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas_3, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape_5[0] = 2048i64
                      stack_shape_5[1] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 0, 1, placeholder_18, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 2, @tir.address_of((int64*)stack_shape_5[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 10, 2, dtype=int32)
                      stack_shape_5[2] = 768i64
                      stack_shape_5[3] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 1, 1, placeholder_19, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 2, @tir.address_of((int64*)stack_shape_5[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 10, 2, dtype=int32)
                      stack_shape_5[4] = 2048i64
                      stack_shape_5[5] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 2, 1, matmul_cublas_3, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 2, @tir.address_of((int64*)stack_shape_5[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value_8, 0, 12, @tir.tvm_struct_get(stack_array_5, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[0] = 7
                      @tir.tvm_struct_set(stack_value_8, 1, 12, @tir.tvm_struct_get(stack_array_5, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[1] = 7
                      @tir.tvm_struct_set(stack_value_8, 2, 12, @tir.tvm_struct_get(stack_array_5, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[2] = 7
                      @tir.tvm_struct_set(stack_value_8, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode_8[3] = 0
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_8, stack_tcode_8, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value_8, 0, 12, T_add_3, dtype=int32)
                      stack_tcode_8[0] = 3
                      @tir.tvm_struct_set(stack_value_8, 1, 12, matmul_cublas_3, dtype=int32)
                      stack_tcode_8[1] = 3
                      @tir.tvm_struct_set(stack_value_8, 2, 12, placeholder_20, dtype=int32)
                      stack_tcode_8[2] = 3
                      @tir.tvm_struct_set(stack_value_8, 3, 12, placeholder_21, dtype=int32)
                      stack_tcode_8[3] = 3
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_struct_set(stack_value_8, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode_8[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_kernel0", stack_value_8, stack_tcode_8, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id_8, matmul_cublas_3, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape", "calling_conv": 1} {
  let stack_tcode_9: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_9: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_9 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let placeholder_22: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let T_reshape: Pointer(float32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [T_reshape] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_9[1])) && (768 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (64 == cast(int32, (int64*)arg1.strides_9[1]))) && (8192 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_9, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_9[0] = 0
          @tir.tvm_struct_set(stack_value_9, 1, 12, cast(int64, dev_id_9), dtype=int32)
          stack_tcode_9[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_9, stack_tcode_9, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_" {
          @tir.tvm_struct_set(stack_value_9, 0, 12, T_reshape, dtype=int32)
          stack_tcode_9[0] = 3
          @tir.tvm_struct_set(stack_value_9, 1, 12, placeholder_22, dtype=int32)
          stack_tcode_9[1] = 3
          @tir.tvm_struct_set(stack_value_9, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_9[2] = 0
          @tir.tvm_struct_set(stack_value_9, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_9[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_kernel0", stack_value_9, stack_tcode_9, 0, 4, dtype=int32)
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add_1", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let arg4: handle = @tir.tvm_struct_get(args, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids[4]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  let T_add: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (3072 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (3072 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode[0] = 0
                @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
                stack_tcode[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas] "storage_alignment" = 128 {
                let matmul_cublas = @tir.TVMBackendAllocWorkspace(2, dev_id, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape[0] = 2048i64
                      stack_shape[1] = 3072i64
                      @tir.tvm_struct_set(stack_array, 0, 1, placeholder, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 2, @tir.address_of((int64*)stack_shape[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 10, 2, dtype=int32)
                      stack_shape[2] = 768i64
                      stack_shape[3] = 3072i64
                      @tir.tvm_struct_set(stack_array, 1, 1, placeholder_1, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 2, @tir.address_of((int64*)stack_shape[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 10, 2, dtype=int32)
                      stack_shape[4] = 2048i64
                      stack_shape[5] = 768i64
                      @tir.tvm_struct_set(stack_array, 2, 1, matmul_cublas, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 2, @tir.address_of((int64*)stack_shape[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value, 0, 12, @tir.tvm_struct_get(stack_array, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode[0] = 7
                      @tir.tvm_struct_set(stack_value, 1, 12, @tir.tvm_struct_get(stack_array, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode[1] = 7
                      @tir.tvm_struct_set(stack_value, 2, 12, @tir.tvm_struct_get(stack_array, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode[2] = 7
                      @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode[3] = 0
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value, stack_tcode, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value, 0, 12, T_add, dtype=int32)
                      stack_tcode[0] = 3
                      @tir.tvm_struct_set(stack_value, 1, 12, matmul_cublas, dtype=int32)
                      stack_tcode[1] = 3
                      @tir.tvm_struct_set(stack_value, 2, 12, placeholder_2, dtype=int32)
                      stack_tcode[2] = 3
                      @tir.tvm_struct_set(stack_value, 3, 12, placeholder_3, dtype=int32)
                      stack_tcode[3] = 3
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_1_kernel0", stack_value, stack_tcode, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id, matmul_cublas, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add", "calling_conv": 1} {
  let stack_tcode_1: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_1: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_1: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_1: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (768 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_1, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_1[0] = 0
              @tir.tvm_struct_set(stack_value_1, 1, 12, cast(int64, dev_id_1), dtype=int32)
              stack_tcode_1[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_1, stack_tcode_1, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_1] "storage_alignment" = 128 {
              let matmul_cublas_1 = @tir.TVMBackendAllocWorkspace(2, dev_id_1, 6291456u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_1, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_1[0] = 2048i64
                    stack_shape_1[1] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 0, 1, placeholder_4, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 2, @tir.address_of((int64*)stack_shape_1[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 10, 2, dtype=int32)
                    stack_shape_1[2] = 768i64
                    stack_shape_1[3] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 1, 1, placeholder_5, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 2, @tir.address_of((int64*)stack_shape_1[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 10, 2, dtype=int32)
                    stack_shape_1[4] = 2048i64
                    stack_shape_1[5] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 2, 1, matmul_cublas_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 2, @tir.address_of((int64*)stack_shape_1[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_1, 0, 12, @tir.tvm_struct_get(stack_array_1, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[0] = 7
                    @tir.tvm_struct_set(stack_value_1, 1, 12, @tir.tvm_struct_get(stack_array_1, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[1] = 7
                    @tir.tvm_struct_set(stack_value_1, 2, 12, @tir.tvm_struct_get(stack_array_1, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[2] = 7
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_1, 0, 12, T_add_1, dtype=int32)
                    stack_tcode_1[0] = 3
                    @tir.tvm_struct_set(stack_value_1, 1, 12, matmul_cublas_1, dtype=int32)
                    stack_tcode_1[1] = 3
                    @tir.tvm_struct_set(stack_value_1, 2, 12, placeholder_6, dtype=int32)
                    stack_tcode_1[2] = 3
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, 1536), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_kernel0", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_1, matmul_cublas_1, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "calling_conv": 1} {
  let stack_tcode_2: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_2: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_2: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_2: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_2 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (768 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (768 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (3072 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_2, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_2[0] = 0
              @tir.tvm_struct_set(stack_value_2, 1, 12, cast(int64, dev_id_2), dtype=int32)
              stack_tcode_2[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_2, stack_tcode_2, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_2] "storage_alignment" = 128 {
              let matmul_cublas_2 = @tir.TVMBackendAllocWorkspace(2, dev_id_2, 25165824u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_2, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_2[0] = 2048i64
                    stack_shape_2[1] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 0, 1, placeholder_7, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 2, @tir.address_of((int64*)stack_shape_2[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 10, 2, dtype=int32)
                    stack_shape_2[2] = 3072i64
                    stack_shape_2[3] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 1, 1, placeholder_8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 2, @tir.address_of((int64*)stack_shape_2[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 10, 2, dtype=int32)
                    stack_shape_2[4] = 2048i64
                    stack_shape_2[5] = 3072i64
                    @tir.tvm_struct_set(stack_array_2, 2, 1, matmul_cublas_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 2, @tir.address_of((int64*)stack_shape_2[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_2, 0, 12, @tir.tvm_struct_get(stack_array_2, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[0] = 7
                    @tir.tvm_struct_set(stack_value_2, 1, 12, @tir.tvm_struct_get(stack_array_2, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[1] = 7
                    @tir.tvm_struct_set(stack_value_2, 2, 12, @tir.tvm_struct_get(stack_array_2, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[2] = 7
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_2, 0, 12, T_multiply, dtype=int32)
                    stack_tcode_2[0] = 3
                    @tir.tvm_struct_set(stack_value_2, 1, 12, matmul_cublas_2, dtype=int32)
                    stack_tcode_2[1] = 3
                    @tir.tvm_struct_set(stack_value_2, 2, 12, placeholder_9, dtype=int32)
                    stack_tcode_2[2] = 3
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, 6144), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_2, matmul_cublas_2, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape_transpose", "calling_conv": 1} {
  let stack_tcode_3: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_3: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_3, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_3[0] = 0
          @tir.tvm_struct_set(stack_value_3, 1, 12, cast(int64, dev_id_3), dtype=int32)
          stack_tcode_3[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_3, stack_tcode_3, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_" {
          @tir.tvm_struct_set(stack_value_3, 0, 12, T_transpose, dtype=int32)
          stack_tcode_3[0] = 3
          @tir.tvm_struct_set(stack_value_3, 1, 12, placeholder_10, dtype=int32)
          stack_tcode_3[1] = 3
          @tir.tvm_struct_set(stack_value_3, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_3[2] = 0
          @tir.tvm_struct_set(stack_value_3, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_3[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_transpose_kernel0", stack_value_3, stack_tcode_3, 0, 4, dtype=int32)
        }
      }
    }
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode_4: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_4: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_4, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_4[0] = 0
          @tir.tvm_struct_set(stack_value_4, 1, 12, cast(int64, dev_id_4), dtype=int32)
          stack_tcode_4[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_4, stack_tcode_4, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_maxelem] "storage_alignment" = 128 {
          let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 98304u64, 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
            attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
            attr [T_softmax_exp] "storage_alignment" = 128 {
              let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 12582912u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(T_softmax_exp, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_norm, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_exp, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_maxelem, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul_1", "calling_conv": 1} {
  let stack_tcode_5: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_5: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_3: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_3: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_13: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_13] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_5, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_5[0] = 0
            @tir.tvm_struct_set(stack_value_5, 1, 12, cast(int64, dev_id_5), dtype=int32)
            stack_tcode_5[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_5, stack_tcode_5, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_3[0] = 192i64
            stack_shape_3[1] = 128i64
            stack_shape_3[2] = 128i64
            @tir.tvm_struct_set(stack_array_3, 0, 1, placeholder_12, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 2, @tir.address_of((int64*)stack_shape_3[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 10, 2, dtype=int32)
            stack_shape_3[3] = 192i64
            stack_shape_3[4] = 64i64
            stack_shape_3[5] = 128i64
            @tir.tvm_struct_set(stack_array_3, 1, 1, placeholder_13, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 2, @tir.address_of((int64*)stack_shape_3[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 10, 2, dtype=int32)
            stack_shape_3[6] = 192i64
            stack_shape_3[7] = 128i64
            stack_shape_3[8] = 64i64
            @tir.tvm_struct_set(stack_array_3, 2, 1, batch_matmul_cublas, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 2, @tir.address_of((int64*)stack_shape_3[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_5, 0, 12, @tir.tvm_struct_get(stack_array_3, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_5[0] = 7
            @tir.tvm_struct_set(stack_value_5, 1, 12, @tir.tvm_struct_get(stack_array_3, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_5[1] = 7
            @tir.tvm_struct_set(stack_value_5, 2, 12, @tir.tvm_struct_get(stack_array_3, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_5[2] = 7
            @tir.tvm_struct_set(stack_value_5, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_5[3] = 0
            @tir.tvm_struct_set(stack_value_5, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_5[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_5, stack_tcode_5, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "calling_conv": 1} {
  let stack_tcode_6: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_6: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_6 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let placeholder_14: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_14] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_15: Pointer(int32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_15] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_6[2])) && (128 == cast(int32, (int64*)arg0.strides_6[1]))) && (16384 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_6[2])) && (128 == cast(int32, (int64*)arg1.strides_6[1]))) && (16384 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_4[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_4[3])) && (128 == cast(int32, (int64*)arg2.strides_4[2]))) && (16384 == cast(int32, (int64*)arg2.strides_4[1]))) && (196608 == cast(int32, (int64*)arg2.strides_4[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_6, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_6[0] = 0
            @tir.tvm_struct_set(stack_value_6, 1, 12, cast(int64, dev_id_6), dtype=int32)
            stack_tcode_6[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_6, stack_tcode_6, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_" {
            @tir.tvm_struct_set(stack_value_6, 0, 12, T_add_2, dtype=int32)
            stack_tcode_6[0] = 3
            @tir.tvm_struct_set(stack_value_6, 1, 12, placeholder_14, dtype=int32)
            stack_tcode_6[1] = 3
            @tir.tvm_struct_set(stack_value_6, 2, 12, placeholder_15, dtype=int32)
            stack_tcode_6[2] = 3
            @tir.tvm_struct_set(stack_value_6, 3, 12, cast(int64, 256), dtype=int32)
            stack_tcode_6[3] = 0
            @tir.tvm_struct_set(stack_value_6, 4, 12, cast(int64, 1024), dtype=int32)
            stack_tcode_6[4] = 0
            @tir.tvm_call_packed_lowered("fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", stack_value_6, stack_tcode_6, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul", "calling_conv": 1} {
  let stack_tcode_7: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_7: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_4: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_4: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_17: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_17] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_7, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_7[0] = 0
            @tir.tvm_struct_set(stack_value_7, 1, 12, cast(int64, dev_id_7), dtype=int32)
            stack_tcode_7[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_7, stack_tcode_7, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_4[0] = 192i64
            stack_shape_4[1] = 128i64
            stack_shape_4[2] = 64i64
            @tir.tvm_struct_set(stack_array_4, 0, 1, placeholder_16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 2, @tir.address_of((int64*)stack_shape_4[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 10, 2, dtype=int32)
            stack_shape_4[3] = 192i64
            stack_shape_4[4] = 128i64
            stack_shape_4[5] = 64i64
            @tir.tvm_struct_set(stack_array_4, 1, 1, placeholder_17, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 2, @tir.address_of((int64*)stack_shape_4[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 10, 2, dtype=int32)
            stack_shape_4[6] = 192i64
            stack_shape_4[7] = 128i64
            stack_shape_4[8] = 128i64
            @tir.tvm_struct_set(stack_array_4, 2, 1, batch_matmul_cublas_1, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 2, @tir.address_of((int64*)stack_shape_4[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_7, 0, 12, @tir.tvm_struct_get(stack_array_4, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_7[0] = 7
            @tir.tvm_struct_set(stack_value_7, 1, 12, @tir.tvm_struct_get(stack_array_4, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_7[1] = 7
            @tir.tvm_struct_set(stack_value_7, 2, 12, @tir.tvm_struct_get(stack_array_4, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_7[2] = 7
            @tir.tvm_struct_set(stack_value_7, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_7[3] = 0
            @tir.tvm_struct_set(stack_value_7, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_7[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_7, stack_tcode_7, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add", "calling_conv": 1} {
  let stack_tcode_8: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value_8: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array_5: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_5: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_8 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_8, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_8[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_8, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_8[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_8, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_8[4]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let placeholder_19: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [placeholder_19] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_3: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_3] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_8[1])) && (768 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_6[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_8 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_8 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_8 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value_8, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode_8[0] = 0
                @tir.tvm_struct_set(stack_value_8, 1, 12, cast(int64, dev_id_8), dtype=int32)
                stack_tcode_8[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_8, stack_tcode_8, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas_3] "storage_alignment" = 128 {
                let matmul_cublas_3 = @tir.TVMBackendAllocWorkspace(2, dev_id_8, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas_3, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape_5[0] = 2048i64
                      stack_shape_5[1] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 0, 1, placeholder_18, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 2, @tir.address_of((int64*)stack_shape_5[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 10, 2, dtype=int32)
                      stack_shape_5[2] = 768i64
                      stack_shape_5[3] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 1, 1, placeholder_19, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 2, @tir.address_of((int64*)stack_shape_5[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 10, 2, dtype=int32)
                      stack_shape_5[4] = 2048i64
                      stack_shape_5[5] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 2, 1, matmul_cublas_3, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 2, @tir.address_of((int64*)stack_shape_5[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value_8, 0, 12, @tir.tvm_struct_get(stack_array_5, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[0] = 7
                      @tir.tvm_struct_set(stack_value_8, 1, 12, @tir.tvm_struct_get(stack_array_5, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[1] = 7
                      @tir.tvm_struct_set(stack_value_8, 2, 12, @tir.tvm_struct_get(stack_array_5, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[2] = 7
                      @tir.tvm_struct_set(stack_value_8, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode_8[3] = 0
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_8, stack_tcode_8, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value_8, 0, 12, T_add_3, dtype=int32)
                      stack_tcode_8[0] = 3
                      @tir.tvm_struct_set(stack_value_8, 1, 12, matmul_cublas_3, dtype=int32)
                      stack_tcode_8[1] = 3
                      @tir.tvm_struct_set(stack_value_8, 2, 12, placeholder_20, dtype=int32)
                      stack_tcode_8[2] = 3
                      @tir.tvm_struct_set(stack_value_8, 3, 12, placeholder_21, dtype=int32)
                      stack_tcode_8[3] = 3
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_struct_set(stack_value_8, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode_8[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_kernel0", stack_value_8, stack_tcode_8, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id_8, matmul_cublas_3, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape", "calling_conv": 1} {
  let stack_tcode_9: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_9: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_9 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let placeholder_22: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let T_reshape: Pointer(float32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [T_reshape] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_9[1])) && (768 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (64 == cast(int32, (int64*)arg1.strides_9[1]))) && (8192 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_9, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_9[0] = 0
          @tir.tvm_struct_set(stack_value_9, 1, 12, cast(int64, dev_id_9), dtype=int32)
          stack_tcode_9[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_9, stack_tcode_9, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_" {
          @tir.tvm_struct_set(stack_value_9, 0, 12, T_reshape, dtype=int32)
          stack_tcode_9[0] = 3
          @tir.tvm_struct_set(stack_value_9, 1, 12, placeholder_22, dtype=int32)
          stack_tcode_9[1] = 3
          @tir.tvm_struct_set(stack_value_9, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_9[2] = 0
          @tir.tvm_struct_set(stack_value_9, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_9[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_kernel0", stack_value_9, stack_tcode_9, 0, 4, dtype=int32)
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add_1", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let arg4: handle = @tir.tvm_struct_get(args, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids[4]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  let T_add: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (3072 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (3072 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode[0] = 0
                @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
                stack_tcode[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas] "storage_alignment" = 128 {
                let matmul_cublas = @tir.TVMBackendAllocWorkspace(2, dev_id, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape[0] = 2048i64
                      stack_shape[1] = 3072i64
                      @tir.tvm_struct_set(stack_array, 0, 1, placeholder, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 2, @tir.address_of((int64*)stack_shape[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 10, 2, dtype=int32)
                      stack_shape[2] = 768i64
                      stack_shape[3] = 3072i64
                      @tir.tvm_struct_set(stack_array, 1, 1, placeholder_1, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 2, @tir.address_of((int64*)stack_shape[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 10, 2, dtype=int32)
                      stack_shape[4] = 2048i64
                      stack_shape[5] = 768i64
                      @tir.tvm_struct_set(stack_array, 2, 1, matmul_cublas, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 2, @tir.address_of((int64*)stack_shape[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value, 0, 12, @tir.tvm_struct_get(stack_array, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode[0] = 7
                      @tir.tvm_struct_set(stack_value, 1, 12, @tir.tvm_struct_get(stack_array, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode[1] = 7
                      @tir.tvm_struct_set(stack_value, 2, 12, @tir.tvm_struct_get(stack_array, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode[2] = 7
                      @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode[3] = 0
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value, stack_tcode, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value, 0, 12, T_add, dtype=int32)
                      stack_tcode[0] = 3
                      @tir.tvm_struct_set(stack_value, 1, 12, matmul_cublas, dtype=int32)
                      stack_tcode[1] = 3
                      @tir.tvm_struct_set(stack_value, 2, 12, placeholder_2, dtype=int32)
                      stack_tcode[2] = 3
                      @tir.tvm_struct_set(stack_value, 3, 12, placeholder_3, dtype=int32)
                      stack_tcode[3] = 3
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_1_kernel0", stack_value, stack_tcode, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id, matmul_cublas, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add", "calling_conv": 1} {
  let stack_tcode_1: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_1: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_1: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_1: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (768 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_1, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_1[0] = 0
              @tir.tvm_struct_set(stack_value_1, 1, 12, cast(int64, dev_id_1), dtype=int32)
              stack_tcode_1[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_1, stack_tcode_1, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_1] "storage_alignment" = 128 {
              let matmul_cublas_1 = @tir.TVMBackendAllocWorkspace(2, dev_id_1, 6291456u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_1, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_1[0] = 2048i64
                    stack_shape_1[1] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 0, 1, placeholder_4, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 2, @tir.address_of((int64*)stack_shape_1[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 10, 2, dtype=int32)
                    stack_shape_1[2] = 768i64
                    stack_shape_1[3] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 1, 1, placeholder_5, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 2, @tir.address_of((int64*)stack_shape_1[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 10, 2, dtype=int32)
                    stack_shape_1[4] = 2048i64
                    stack_shape_1[5] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 2, 1, matmul_cublas_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 2, @tir.address_of((int64*)stack_shape_1[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_1, 0, 12, @tir.tvm_struct_get(stack_array_1, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[0] = 7
                    @tir.tvm_struct_set(stack_value_1, 1, 12, @tir.tvm_struct_get(stack_array_1, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[1] = 7
                    @tir.tvm_struct_set(stack_value_1, 2, 12, @tir.tvm_struct_get(stack_array_1, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[2] = 7
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_1, 0, 12, T_add_1, dtype=int32)
                    stack_tcode_1[0] = 3
                    @tir.tvm_struct_set(stack_value_1, 1, 12, matmul_cublas_1, dtype=int32)
                    stack_tcode_1[1] = 3
                    @tir.tvm_struct_set(stack_value_1, 2, 12, placeholder_6, dtype=int32)
                    stack_tcode_1[2] = 3
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, 1536), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_kernel0", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_1, matmul_cublas_1, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "calling_conv": 1} {
  let stack_tcode_2: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_2: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_2: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_2: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_2 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (768 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (768 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (3072 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_2, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_2[0] = 0
              @tir.tvm_struct_set(stack_value_2, 1, 12, cast(int64, dev_id_2), dtype=int32)
              stack_tcode_2[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_2, stack_tcode_2, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_2] "storage_alignment" = 128 {
              let matmul_cublas_2 = @tir.TVMBackendAllocWorkspace(2, dev_id_2, 25165824u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_2, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_2[0] = 2048i64
                    stack_shape_2[1] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 0, 1, placeholder_7, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 2, @tir.address_of((int64*)stack_shape_2[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 10, 2, dtype=int32)
                    stack_shape_2[2] = 3072i64
                    stack_shape_2[3] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 1, 1, placeholder_8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 2, @tir.address_of((int64*)stack_shape_2[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 10, 2, dtype=int32)
                    stack_shape_2[4] = 2048i64
                    stack_shape_2[5] = 3072i64
                    @tir.tvm_struct_set(stack_array_2, 2, 1, matmul_cublas_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 2, @tir.address_of((int64*)stack_shape_2[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_2, 0, 12, @tir.tvm_struct_get(stack_array_2, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[0] = 7
                    @tir.tvm_struct_set(stack_value_2, 1, 12, @tir.tvm_struct_get(stack_array_2, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[1] = 7
                    @tir.tvm_struct_set(stack_value_2, 2, 12, @tir.tvm_struct_get(stack_array_2, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[2] = 7
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_2, 0, 12, T_multiply, dtype=int32)
                    stack_tcode_2[0] = 3
                    @tir.tvm_struct_set(stack_value_2, 1, 12, matmul_cublas_2, dtype=int32)
                    stack_tcode_2[1] = 3
                    @tir.tvm_struct_set(stack_value_2, 2, 12, placeholder_9, dtype=int32)
                    stack_tcode_2[2] = 3
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, 6144), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_2, matmul_cublas_2, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape_transpose", "calling_conv": 1} {
  let stack_tcode_3: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_3: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_3, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_3[0] = 0
          @tir.tvm_struct_set(stack_value_3, 1, 12, cast(int64, dev_id_3), dtype=int32)
          stack_tcode_3[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_3, stack_tcode_3, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_" {
          @tir.tvm_struct_set(stack_value_3, 0, 12, T_transpose, dtype=int32)
          stack_tcode_3[0] = 3
          @tir.tvm_struct_set(stack_value_3, 1, 12, placeholder_10, dtype=int32)
          stack_tcode_3[1] = 3
          @tir.tvm_struct_set(stack_value_3, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_3[2] = 0
          @tir.tvm_struct_set(stack_value_3, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_3[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_transpose_kernel0", stack_value_3, stack_tcode_3, 0, 4, dtype=int32)
        }
      }
    }
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode_4: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_4: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_4, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_4[0] = 0
          @tir.tvm_struct_set(stack_value_4, 1, 12, cast(int64, dev_id_4), dtype=int32)
          stack_tcode_4[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_4, stack_tcode_4, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_maxelem] "storage_alignment" = 128 {
          let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 98304u64, 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
            attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
            attr [T_softmax_exp] "storage_alignment" = 128 {
              let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 12582912u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(T_softmax_exp, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_norm, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_exp, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_maxelem, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul_1", "calling_conv": 1} {
  let stack_tcode_5: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_5: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_3: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_3: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_13: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_13] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_5, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_5[0] = 0
            @tir.tvm_struct_set(stack_value_5, 1, 12, cast(int64, dev_id_5), dtype=int32)
            stack_tcode_5[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_5, stack_tcode_5, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_3[0] = 192i64
            stack_shape_3[1] = 128i64
            stack_shape_3[2] = 128i64
            @tir.tvm_struct_set(stack_array_3, 0, 1, placeholder_12, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 2, @tir.address_of((int64*)stack_shape_3[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 10, 2, dtype=int32)
            stack_shape_3[3] = 192i64
            stack_shape_3[4] = 64i64
            stack_shape_3[5] = 128i64
            @tir.tvm_struct_set(stack_array_3, 1, 1, placeholder_13, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 2, @tir.address_of((int64*)stack_shape_3[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 10, 2, dtype=int32)
            stack_shape_3[6] = 192i64
            stack_shape_3[7] = 128i64
            stack_shape_3[8] = 64i64
            @tir.tvm_struct_set(stack_array_3, 2, 1, batch_matmul_cublas, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 2, @tir.address_of((int64*)stack_shape_3[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_5, 0, 12, @tir.tvm_struct_get(stack_array_3, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_5[0] = 7
            @tir.tvm_struct_set(stack_value_5, 1, 12, @tir.tvm_struct_get(stack_array_3, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_5[1] = 7
            @tir.tvm_struct_set(stack_value_5, 2, 12, @tir.tvm_struct_get(stack_array_3, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_5[2] = 7
            @tir.tvm_struct_set(stack_value_5, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_5[3] = 0
            @tir.tvm_struct_set(stack_value_5, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_5[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_5, stack_tcode_5, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "calling_conv": 1} {
  let stack_tcode_6: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_6: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_6 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let placeholder_14: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_14] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_15: Pointer(int32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_15] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_6[2])) && (128 == cast(int32, (int64*)arg0.strides_6[1]))) && (16384 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_6[2])) && (128 == cast(int32, (int64*)arg1.strides_6[1]))) && (16384 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_4[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_4[3])) && (128 == cast(int32, (int64*)arg2.strides_4[2]))) && (16384 == cast(int32, (int64*)arg2.strides_4[1]))) && (196608 == cast(int32, (int64*)arg2.strides_4[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_6, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_6[0] = 0
            @tir.tvm_struct_set(stack_value_6, 1, 12, cast(int64, dev_id_6), dtype=int32)
            stack_tcode_6[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_6, stack_tcode_6, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_" {
            @tir.tvm_struct_set(stack_value_6, 0, 12, T_add_2, dtype=int32)
            stack_tcode_6[0] = 3
            @tir.tvm_struct_set(stack_value_6, 1, 12, placeholder_14, dtype=int32)
            stack_tcode_6[1] = 3
            @tir.tvm_struct_set(stack_value_6, 2, 12, placeholder_15, dtype=int32)
            stack_tcode_6[2] = 3
            @tir.tvm_struct_set(stack_value_6, 3, 12, cast(int64, 256), dtype=int32)
            stack_tcode_6[3] = 0
            @tir.tvm_struct_set(stack_value_6, 4, 12, cast(int64, 1024), dtype=int32)
            stack_tcode_6[4] = 0
            @tir.tvm_call_packed_lowered("fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", stack_value_6, stack_tcode_6, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul", "calling_conv": 1} {
  let stack_tcode_7: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_7: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_4: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_4: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_17: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_17] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_7, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_7[0] = 0
            @tir.tvm_struct_set(stack_value_7, 1, 12, cast(int64, dev_id_7), dtype=int32)
            stack_tcode_7[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_7, stack_tcode_7, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_4[0] = 192i64
            stack_shape_4[1] = 128i64
            stack_shape_4[2] = 64i64
            @tir.tvm_struct_set(stack_array_4, 0, 1, placeholder_16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 2, @tir.address_of((int64*)stack_shape_4[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 10, 2, dtype=int32)
            stack_shape_4[3] = 192i64
            stack_shape_4[4] = 128i64
            stack_shape_4[5] = 64i64
            @tir.tvm_struct_set(stack_array_4, 1, 1, placeholder_17, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 2, @tir.address_of((int64*)stack_shape_4[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 10, 2, dtype=int32)
            stack_shape_4[6] = 192i64
            stack_shape_4[7] = 128i64
            stack_shape_4[8] = 128i64
            @tir.tvm_struct_set(stack_array_4, 2, 1, batch_matmul_cublas_1, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 2, @tir.address_of((int64*)stack_shape_4[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_7, 0, 12, @tir.tvm_struct_get(stack_array_4, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_7[0] = 7
            @tir.tvm_struct_set(stack_value_7, 1, 12, @tir.tvm_struct_get(stack_array_4, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_7[1] = 7
            @tir.tvm_struct_set(stack_value_7, 2, 12, @tir.tvm_struct_get(stack_array_4, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_7[2] = 7
            @tir.tvm_struct_set(stack_value_7, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_7[3] = 0
            @tir.tvm_struct_set(stack_value_7, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_7[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_7, stack_tcode_7, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add", "calling_conv": 1} {
  let stack_tcode_8: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value_8: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array_5: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_5: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_8 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_8, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_8[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_8, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_8[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_8, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_8[4]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let placeholder_19: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [placeholder_19] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_3: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_3] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_8[1])) && (768 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_6[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_8 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_8 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_8 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value_8, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode_8[0] = 0
                @tir.tvm_struct_set(stack_value_8, 1, 12, cast(int64, dev_id_8), dtype=int32)
                stack_tcode_8[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_8, stack_tcode_8, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas_3] "storage_alignment" = 128 {
                let matmul_cublas_3 = @tir.TVMBackendAllocWorkspace(2, dev_id_8, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas_3, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape_5[0] = 2048i64
                      stack_shape_5[1] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 0, 1, placeholder_18, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 2, @tir.address_of((int64*)stack_shape_5[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 10, 2, dtype=int32)
                      stack_shape_5[2] = 768i64
                      stack_shape_5[3] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 1, 1, placeholder_19, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 2, @tir.address_of((int64*)stack_shape_5[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 10, 2, dtype=int32)
                      stack_shape_5[4] = 2048i64
                      stack_shape_5[5] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 2, 1, matmul_cublas_3, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 2, @tir.address_of((int64*)stack_shape_5[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value_8, 0, 12, @tir.tvm_struct_get(stack_array_5, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[0] = 7
                      @tir.tvm_struct_set(stack_value_8, 1, 12, @tir.tvm_struct_get(stack_array_5, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[1] = 7
                      @tir.tvm_struct_set(stack_value_8, 2, 12, @tir.tvm_struct_get(stack_array_5, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[2] = 7
                      @tir.tvm_struct_set(stack_value_8, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode_8[3] = 0
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_8, stack_tcode_8, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value_8, 0, 12, T_add_3, dtype=int32)
                      stack_tcode_8[0] = 3
                      @tir.tvm_struct_set(stack_value_8, 1, 12, matmul_cublas_3, dtype=int32)
                      stack_tcode_8[1] = 3
                      @tir.tvm_struct_set(stack_value_8, 2, 12, placeholder_20, dtype=int32)
                      stack_tcode_8[2] = 3
                      @tir.tvm_struct_set(stack_value_8, 3, 12, placeholder_21, dtype=int32)
                      stack_tcode_8[3] = 3
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_struct_set(stack_value_8, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode_8[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_kernel0", stack_value_8, stack_tcode_8, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id_8, matmul_cublas_3, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape", "calling_conv": 1} {
  let stack_tcode_9: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_9: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_9 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let placeholder_22: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let T_reshape: Pointer(float32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [T_reshape] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_9[1])) && (768 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (64 == cast(int32, (int64*)arg1.strides_9[1]))) && (8192 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_9, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_9[0] = 0
          @tir.tvm_struct_set(stack_value_9, 1, 12, cast(int64, dev_id_9), dtype=int32)
          stack_tcode_9[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_9, stack_tcode_9, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_" {
          @tir.tvm_struct_set(stack_value_9, 0, 12, T_reshape, dtype=int32)
          stack_tcode_9[0] = 3
          @tir.tvm_struct_set(stack_value_9, 1, 12, placeholder_22, dtype=int32)
          stack_tcode_9[1] = 3
          @tir.tvm_struct_set(stack_value_9, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_9[2] = 0
          @tir.tvm_struct_set(stack_value_9, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_9[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_kernel0", stack_value_9, stack_tcode_9, 0, 4, dtype=int32)
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add_1", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let arg4: handle = @tir.tvm_struct_get(args, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids[4]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  let T_add: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (3072 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (3072 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode[0] = 0
                @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
                stack_tcode[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas] "storage_alignment" = 128 {
                let matmul_cublas = @tir.TVMBackendAllocWorkspace(2, dev_id, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape[0] = 2048i64
                      stack_shape[1] = 3072i64
                      @tir.tvm_struct_set(stack_array, 0, 1, placeholder, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 2, @tir.address_of((int64*)stack_shape[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 10, 2, dtype=int32)
                      stack_shape[2] = 768i64
                      stack_shape[3] = 3072i64
                      @tir.tvm_struct_set(stack_array, 1, 1, placeholder_1, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 2, @tir.address_of((int64*)stack_shape[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 10, 2, dtype=int32)
                      stack_shape[4] = 2048i64
                      stack_shape[5] = 768i64
                      @tir.tvm_struct_set(stack_array, 2, 1, matmul_cublas, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 2, @tir.address_of((int64*)stack_shape[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value, 0, 12, @tir.tvm_struct_get(stack_array, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode[0] = 7
                      @tir.tvm_struct_set(stack_value, 1, 12, @tir.tvm_struct_get(stack_array, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode[1] = 7
                      @tir.tvm_struct_set(stack_value, 2, 12, @tir.tvm_struct_get(stack_array, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode[2] = 7
                      @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode[3] = 0
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value, stack_tcode, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value, 0, 12, T_add, dtype=int32)
                      stack_tcode[0] = 3
                      @tir.tvm_struct_set(stack_value, 1, 12, matmul_cublas, dtype=int32)
                      stack_tcode[1] = 3
                      @tir.tvm_struct_set(stack_value, 2, 12, placeholder_2, dtype=int32)
                      stack_tcode[2] = 3
                      @tir.tvm_struct_set(stack_value, 3, 12, placeholder_3, dtype=int32)
                      stack_tcode[3] = 3
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_1_kernel0", stack_value, stack_tcode, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id, matmul_cublas, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add", "calling_conv": 1} {
  let stack_tcode_1: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_1: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_1: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_1: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (768 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_1, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_1[0] = 0
              @tir.tvm_struct_set(stack_value_1, 1, 12, cast(int64, dev_id_1), dtype=int32)
              stack_tcode_1[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_1, stack_tcode_1, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_1] "storage_alignment" = 128 {
              let matmul_cublas_1 = @tir.TVMBackendAllocWorkspace(2, dev_id_1, 6291456u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_1, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_1[0] = 2048i64
                    stack_shape_1[1] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 0, 1, placeholder_4, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 2, @tir.address_of((int64*)stack_shape_1[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 10, 2, dtype=int32)
                    stack_shape_1[2] = 768i64
                    stack_shape_1[3] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 1, 1, placeholder_5, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 2, @tir.address_of((int64*)stack_shape_1[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 10, 2, dtype=int32)
                    stack_shape_1[4] = 2048i64
                    stack_shape_1[5] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 2, 1, matmul_cublas_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 2, @tir.address_of((int64*)stack_shape_1[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_1, 0, 12, @tir.tvm_struct_get(stack_array_1, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[0] = 7
                    @tir.tvm_struct_set(stack_value_1, 1, 12, @tir.tvm_struct_get(stack_array_1, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[1] = 7
                    @tir.tvm_struct_set(stack_value_1, 2, 12, @tir.tvm_struct_get(stack_array_1, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[2] = 7
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_1, 0, 12, T_add_1, dtype=int32)
                    stack_tcode_1[0] = 3
                    @tir.tvm_struct_set(stack_value_1, 1, 12, matmul_cublas_1, dtype=int32)
                    stack_tcode_1[1] = 3
                    @tir.tvm_struct_set(stack_value_1, 2, 12, placeholder_6, dtype=int32)
                    stack_tcode_1[2] = 3
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, 1536), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_kernel0", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_1, matmul_cublas_1, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "calling_conv": 1} {
  let stack_tcode_2: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_2: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_2: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_2: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_2 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (768 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (768 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (3072 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_2, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_2[0] = 0
              @tir.tvm_struct_set(stack_value_2, 1, 12, cast(int64, dev_id_2), dtype=int32)
              stack_tcode_2[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_2, stack_tcode_2, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_2] "storage_alignment" = 128 {
              let matmul_cublas_2 = @tir.TVMBackendAllocWorkspace(2, dev_id_2, 25165824u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_2, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_2[0] = 2048i64
                    stack_shape_2[1] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 0, 1, placeholder_7, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 2, @tir.address_of((int64*)stack_shape_2[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 10, 2, dtype=int32)
                    stack_shape_2[2] = 3072i64
                    stack_shape_2[3] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 1, 1, placeholder_8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 2, @tir.address_of((int64*)stack_shape_2[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 10, 2, dtype=int32)
                    stack_shape_2[4] = 2048i64
                    stack_shape_2[5] = 3072i64
                    @tir.tvm_struct_set(stack_array_2, 2, 1, matmul_cublas_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 2, @tir.address_of((int64*)stack_shape_2[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_2, 0, 12, @tir.tvm_struct_get(stack_array_2, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[0] = 7
                    @tir.tvm_struct_set(stack_value_2, 1, 12, @tir.tvm_struct_get(stack_array_2, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[1] = 7
                    @tir.tvm_struct_set(stack_value_2, 2, 12, @tir.tvm_struct_get(stack_array_2, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[2] = 7
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_2, 0, 12, T_multiply, dtype=int32)
                    stack_tcode_2[0] = 3
                    @tir.tvm_struct_set(stack_value_2, 1, 12, matmul_cublas_2, dtype=int32)
                    stack_tcode_2[1] = 3
                    @tir.tvm_struct_set(stack_value_2, 2, 12, placeholder_9, dtype=int32)
                    stack_tcode_2[2] = 3
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, 6144), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_2, matmul_cublas_2, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape_transpose", "calling_conv": 1} {
  let stack_tcode_3: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_3: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_3, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_3[0] = 0
          @tir.tvm_struct_set(stack_value_3, 1, 12, cast(int64, dev_id_3), dtype=int32)
          stack_tcode_3[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_3, stack_tcode_3, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_" {
          @tir.tvm_struct_set(stack_value_3, 0, 12, T_transpose, dtype=int32)
          stack_tcode_3[0] = 3
          @tir.tvm_struct_set(stack_value_3, 1, 12, placeholder_10, dtype=int32)
          stack_tcode_3[1] = 3
          @tir.tvm_struct_set(stack_value_3, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_3[2] = 0
          @tir.tvm_struct_set(stack_value_3, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_3[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_transpose_kernel0", stack_value_3, stack_tcode_3, 0, 4, dtype=int32)
        }
      }
    }
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode_4: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_4: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_4, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_4[0] = 0
          @tir.tvm_struct_set(stack_value_4, 1, 12, cast(int64, dev_id_4), dtype=int32)
          stack_tcode_4[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_4, stack_tcode_4, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_maxelem] "storage_alignment" = 128 {
          let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 98304u64, 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
            attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
            attr [T_softmax_exp] "storage_alignment" = 128 {
              let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 12582912u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(T_softmax_exp, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_norm, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_exp, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_maxelem, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul_1", "calling_conv": 1} {
  let stack_tcode_5: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_5: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_3: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_3: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_13: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_13] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_5, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_5[0] = 0
            @tir.tvm_struct_set(stack_value_5, 1, 12, cast(int64, dev_id_5), dtype=int32)
            stack_tcode_5[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_5, stack_tcode_5, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_3[0] = 192i64
            stack_shape_3[1] = 128i64
            stack_shape_3[2] = 128i64
            @tir.tvm_struct_set(stack_array_3, 0, 1, placeholder_12, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 2, @tir.address_of((int64*)stack_shape_3[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 10, 2, dtype=int32)
            stack_shape_3[3] = 192i64
            stack_shape_3[4] = 64i64
            stack_shape_3[5] = 128i64
            @tir.tvm_struct_set(stack_array_3, 1, 1, placeholder_13, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 2, @tir.address_of((int64*)stack_shape_3[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 10, 2, dtype=int32)
            stack_shape_3[6] = 192i64
            stack_shape_3[7] = 128i64
            stack_shape_3[8] = 64i64
            @tir.tvm_struct_set(stack_array_3, 2, 1, batch_matmul_cublas, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 2, @tir.address_of((int64*)stack_shape_3[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_5, 0, 12, @tir.tvm_struct_get(stack_array_3, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_5[0] = 7
            @tir.tvm_struct_set(stack_value_5, 1, 12, @tir.tvm_struct_get(stack_array_3, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_5[1] = 7
            @tir.tvm_struct_set(stack_value_5, 2, 12, @tir.tvm_struct_get(stack_array_3, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_5[2] = 7
            @tir.tvm_struct_set(stack_value_5, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_5[3] = 0
            @tir.tvm_struct_set(stack_value_5, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_5[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_5, stack_tcode_5, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "calling_conv": 1} {
  let stack_tcode_6: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_6: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_6 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let placeholder_14: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_14] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_15: Pointer(int32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_15] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_6[2])) && (128 == cast(int32, (int64*)arg0.strides_6[1]))) && (16384 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_6[2])) && (128 == cast(int32, (int64*)arg1.strides_6[1]))) && (16384 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_4[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_4[3])) && (128 == cast(int32, (int64*)arg2.strides_4[2]))) && (16384 == cast(int32, (int64*)arg2.strides_4[1]))) && (196608 == cast(int32, (int64*)arg2.strides_4[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_6, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_6[0] = 0
            @tir.tvm_struct_set(stack_value_6, 1, 12, cast(int64, dev_id_6), dtype=int32)
            stack_tcode_6[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_6, stack_tcode_6, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_" {
            @tir.tvm_struct_set(stack_value_6, 0, 12, T_add_2, dtype=int32)
            stack_tcode_6[0] = 3
            @tir.tvm_struct_set(stack_value_6, 1, 12, placeholder_14, dtype=int32)
            stack_tcode_6[1] = 3
            @tir.tvm_struct_set(stack_value_6, 2, 12, placeholder_15, dtype=int32)
            stack_tcode_6[2] = 3
            @tir.tvm_struct_set(stack_value_6, 3, 12, cast(int64, 256), dtype=int32)
            stack_tcode_6[3] = 0
            @tir.tvm_struct_set(stack_value_6, 4, 12, cast(int64, 1024), dtype=int32)
            stack_tcode_6[4] = 0
            @tir.tvm_call_packed_lowered("fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", stack_value_6, stack_tcode_6, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul", "calling_conv": 1} {
  let stack_tcode_7: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_7: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_4: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_4: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_17: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_17] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_7, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_7[0] = 0
            @tir.tvm_struct_set(stack_value_7, 1, 12, cast(int64, dev_id_7), dtype=int32)
            stack_tcode_7[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_7, stack_tcode_7, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_4[0] = 192i64
            stack_shape_4[1] = 128i64
            stack_shape_4[2] = 64i64
            @tir.tvm_struct_set(stack_array_4, 0, 1, placeholder_16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 2, @tir.address_of((int64*)stack_shape_4[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 10, 2, dtype=int32)
            stack_shape_4[3] = 192i64
            stack_shape_4[4] = 128i64
            stack_shape_4[5] = 64i64
            @tir.tvm_struct_set(stack_array_4, 1, 1, placeholder_17, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 2, @tir.address_of((int64*)stack_shape_4[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 10, 2, dtype=int32)
            stack_shape_4[6] = 192i64
            stack_shape_4[7] = 128i64
            stack_shape_4[8] = 128i64
            @tir.tvm_struct_set(stack_array_4, 2, 1, batch_matmul_cublas_1, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 2, @tir.address_of((int64*)stack_shape_4[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_7, 0, 12, @tir.tvm_struct_get(stack_array_4, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_7[0] = 7
            @tir.tvm_struct_set(stack_value_7, 1, 12, @tir.tvm_struct_get(stack_array_4, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_7[1] = 7
            @tir.tvm_struct_set(stack_value_7, 2, 12, @tir.tvm_struct_get(stack_array_4, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_7[2] = 7
            @tir.tvm_struct_set(stack_value_7, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_7[3] = 0
            @tir.tvm_struct_set(stack_value_7, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_7[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_7, stack_tcode_7, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add", "calling_conv": 1} {
  let stack_tcode_8: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value_8: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array_5: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_5: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_8 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_8, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_8[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_8, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_8[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_8, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_8[4]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let placeholder_19: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [placeholder_19] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_3: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_3] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_8[1])) && (768 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_6[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_8 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_8 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_8 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value_8, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode_8[0] = 0
                @tir.tvm_struct_set(stack_value_8, 1, 12, cast(int64, dev_id_8), dtype=int32)
                stack_tcode_8[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_8, stack_tcode_8, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas_3] "storage_alignment" = 128 {
                let matmul_cublas_3 = @tir.TVMBackendAllocWorkspace(2, dev_id_8, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas_3, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape_5[0] = 2048i64
                      stack_shape_5[1] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 0, 1, placeholder_18, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 2, @tir.address_of((int64*)stack_shape_5[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 10, 2, dtype=int32)
                      stack_shape_5[2] = 768i64
                      stack_shape_5[3] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 1, 1, placeholder_19, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 2, @tir.address_of((int64*)stack_shape_5[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 10, 2, dtype=int32)
                      stack_shape_5[4] = 2048i64
                      stack_shape_5[5] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 2, 1, matmul_cublas_3, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 2, @tir.address_of((int64*)stack_shape_5[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value_8, 0, 12, @tir.tvm_struct_get(stack_array_5, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[0] = 7
                      @tir.tvm_struct_set(stack_value_8, 1, 12, @tir.tvm_struct_get(stack_array_5, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[1] = 7
                      @tir.tvm_struct_set(stack_value_8, 2, 12, @tir.tvm_struct_get(stack_array_5, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[2] = 7
                      @tir.tvm_struct_set(stack_value_8, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode_8[3] = 0
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_8, stack_tcode_8, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value_8, 0, 12, T_add_3, dtype=int32)
                      stack_tcode_8[0] = 3
                      @tir.tvm_struct_set(stack_value_8, 1, 12, matmul_cublas_3, dtype=int32)
                      stack_tcode_8[1] = 3
                      @tir.tvm_struct_set(stack_value_8, 2, 12, placeholder_20, dtype=int32)
                      stack_tcode_8[2] = 3
                      @tir.tvm_struct_set(stack_value_8, 3, 12, placeholder_21, dtype=int32)
                      stack_tcode_8[3] = 3
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_struct_set(stack_value_8, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode_8[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_kernel0", stack_value_8, stack_tcode_8, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id_8, matmul_cublas_3, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape", "calling_conv": 1} {
  let stack_tcode_9: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_9: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_9 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let placeholder_22: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let T_reshape: Pointer(float32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [T_reshape] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_9[1])) && (768 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (64 == cast(int32, (int64*)arg1.strides_9[1]))) && (8192 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_9, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_9[0] = 0
          @tir.tvm_struct_set(stack_value_9, 1, 12, cast(int64, dev_id_9), dtype=int32)
          stack_tcode_9[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_9, stack_tcode_9, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_" {
          @tir.tvm_struct_set(stack_value_9, 0, 12, T_reshape, dtype=int32)
          stack_tcode_9[0] = 3
          @tir.tvm_struct_set(stack_value_9, 1, 12, placeholder_22, dtype=int32)
          stack_tcode_9[1] = 3
          @tir.tvm_struct_set(stack_value_9, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_9[2] = 0
          @tir.tvm_struct_set(stack_value_9, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_9[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_kernel0", stack_value_9, stack_tcode_9, 0, 4, dtype=int32)
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add_1", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args == 5), "fused_nn_dense_nn_bias_add_add_1: num_args should be 5")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let arg3: handle = @tir.tvm_struct_get(args, 3, 12, dtype=handle)
  let arg3.code: int32 = (int32*)arg_type_ids[3]
  let arg4: handle = @tir.tvm_struct_get(args, 4, 12, dtype=handle)
  let arg4.code: int32 = (int32*)arg_type_ids[4]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  let placeholder_3: Pointer(float32) = @tir.tvm_struct_get(arg3, 0, 1, dtype=handle)
  attr [placeholder_3] "storage_alignment" = 128;
  let arg3.shape: handle = @tir.tvm_struct_get(arg3, 0, 2, dtype=handle)
  let arg3.strides: handle = @tir.tvm_struct_get(arg3, 0, 3, dtype=handle)
  let T_add: Pointer(float32) = @tir.tvm_struct_get(arg4, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg4.shape: handle = @tir.tvm_struct_get(arg4, 0, 2, dtype=handle)
  let arg4.strides: handle = @tir.tvm_struct_get(arg4, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[2] to be pointer")
  assert(((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[3] to be pointer")
  assert(((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), "fused_nn_dense_nn_bias_add_add_1: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((3072 == cast(int32, (int64*)arg0.shape[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (3072 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides[1])) && (3072 == cast(int32, (int64*)arg0.strides[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((3072 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (3072 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides[1])) && (3072 == cast(int32, (int64*)arg1.strides[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides[1])) && (768 == cast(int32, (int64*)arg3.strides[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id == @tir.tvm_struct_get(arg3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides[1])) && (768 == cast(int32, (int64*)arg4.strides[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id == @tir.tvm_struct_get(arg4, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode[0] = 0
                @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
                stack_tcode[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_1_compute_";
              attr [matmul_cublas: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas] "storage_alignment" = 128 {
                let matmul_cublas = @tir.TVMBackendAllocWorkspace(2, dev_id, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape[0] = 2048i64
                      stack_shape[1] = 3072i64
                      @tir.tvm_struct_set(stack_array, 0, 1, placeholder, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 2, @tir.address_of((int64*)stack_shape[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 0, 10, 2, dtype=int32)
                      stack_shape[2] = 768i64
                      stack_shape[3] = 3072i64
                      @tir.tvm_struct_set(stack_array, 1, 1, placeholder_1, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 2, @tir.address_of((int64*)stack_shape[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 1, 10, 2, dtype=int32)
                      stack_shape[4] = 2048i64
                      stack_shape[5] = 768i64
                      @tir.tvm_struct_set(stack_array, 2, 1, matmul_cublas, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 2, @tir.address_of((int64*)stack_shape[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 9, dev_id, dtype=int32)
                      @tir.tvm_struct_set(stack_array, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value, 0, 12, @tir.tvm_struct_get(stack_array, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode[0] = 7
                      @tir.tvm_struct_set(stack_value, 1, 12, @tir.tvm_struct_get(stack_array, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode[1] = 7
                      @tir.tvm_struct_set(stack_value, 2, 12, @tir.tvm_struct_get(stack_array, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode[2] = 7
                      @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode[3] = 0
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value, stack_tcode, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value, 0, 12, T_add, dtype=int32)
                      stack_tcode[0] = 3
                      @tir.tvm_struct_set(stack_value, 1, 12, matmul_cublas, dtype=int32)
                      stack_tcode[1] = 3
                      @tir.tvm_struct_set(stack_value, 2, 12, placeholder_2, dtype=int32)
                      stack_tcode[2] = 3
                      @tir.tvm_struct_set(stack_value, 3, 12, placeholder_3, dtype=int32)
                      stack_tcode[3] = 3
                      @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode[4] = 0
                      @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_1_kernel0", stack_value, stack_tcode, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id, matmul_cublas, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_1: handle, arg_type_ids_1: handle, num_args_1: int32, out_ret_value_1: handle, out_ret_tcode_1: handle, resource_handle_1: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add", "calling_conv": 1} {
  let stack_tcode_1: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_1: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_1: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_1: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_1 == 4), "fused_nn_dense_nn_bias_add: num_args should be 4")
  let arg0_1: handle = @tir.tvm_struct_get(args_1, 0, 12, dtype=handle)
  let arg0.code_1: int32 = (int32*)arg_type_ids_1[0]
  let arg1_1: handle = @tir.tvm_struct_get(args_1, 1, 12, dtype=handle)
  let arg1.code_1: int32 = (int32*)arg_type_ids_1[1]
  let arg2_1: handle = @tir.tvm_struct_get(args_1, 2, 12, dtype=handle)
  let arg2.code_1: int32 = (int32*)arg_type_ids_1[2]
  let arg3_1: handle = @tir.tvm_struct_get(args_1, 3, 12, dtype=handle)
  let arg3.code_1: int32 = (int32*)arg_type_ids_1[3]
  let placeholder_4: Pointer(float32) = @tir.tvm_struct_get(arg0_1, 0, 1, dtype=handle)
  attr [placeholder_4] "storage_alignment" = 128;
  let arg0.shape_1: handle = @tir.tvm_struct_get(arg0_1, 0, 2, dtype=handle)
  let arg0.strides_1: handle = @tir.tvm_struct_get(arg0_1, 0, 3, dtype=handle)
  let dev_id_1: int32 = @tir.tvm_struct_get(arg0_1, 0, 9, dtype=int32)
  let placeholder_5: Pointer(float32) = @tir.tvm_struct_get(arg1_1, 0, 1, dtype=handle)
  attr [placeholder_5] "storage_alignment" = 128;
  let arg1.shape_1: handle = @tir.tvm_struct_get(arg1_1, 0, 2, dtype=handle)
  let arg1.strides_1: handle = @tir.tvm_struct_get(arg1_1, 0, 3, dtype=handle)
  let placeholder_6: Pointer(float32) = @tir.tvm_struct_get(arg2_1, 0, 1, dtype=handle)
  attr [placeholder_6] "storage_alignment" = 128;
  let arg2.shape_1: handle = @tir.tvm_struct_get(arg2_1, 0, 2, dtype=handle)
  let arg2.strides_1: handle = @tir.tvm_struct_get(arg2_1, 0, 3, dtype=handle)
  let T_add_1: Pointer(float32) = @tir.tvm_struct_get(arg3_1, 0, 1, dtype=handle)
  attr [T_add_1] "storage_alignment" = 128;
  let arg3.shape_1: handle = @tir.tvm_struct_get(arg3_1, 0, 2, dtype=handle)
  let arg3.strides_1: handle = @tir.tvm_struct_get(arg3_1, 0, 3, dtype=handle)
  assert(((((arg0.code_1 == 3) || (arg0.code_1 == 13)) || (arg0.code_1 == 7)) || (arg0.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_1 == 3) || (arg1.code_1 == 13)) || (arg1.code_1 == 7)) || (arg1.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_1 == 3) || (arg2.code_1 == 13)) || (arg2.code_1 == 7)) || (arg2.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_1 == 3) || (arg3.code_1 == 13)) || (arg3.code_1 == 7)) || (arg3.code_1 == 4)), "fused_nn_dense_nn_bias_add: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_1, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_1, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_1[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_1[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_1, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_1[1])) && (768 == cast(int32, (int64*)arg0.strides_1[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_1, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_1, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_1[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_1[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_1, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_1[1])) && (768 == cast(int32, (int64*)arg1.strides_1[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_1 == @tir.tvm_struct_get(arg1_1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_1, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_1, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_1[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_1, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_1[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_1, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_1, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_1 == @tir.tvm_struct_get(arg2_1, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_1, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_1, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_1[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_1[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_1, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_1[1])) && (768 == cast(int32, (int64*)arg3.strides_1[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_1, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_1, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_1 == @tir.tvm_struct_get(arg3_1, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_1, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_1[0] = 0
              @tir.tvm_struct_set(stack_value_1, 1, 12, cast(int64, dev_id_1), dtype=int32)
              stack_tcode_1[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_1, stack_tcode_1, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_compute_";
            attr [matmul_cublas_1: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_1] "storage_alignment" = 128 {
              let matmul_cublas_1 = @tir.TVMBackendAllocWorkspace(2, dev_id_1, 6291456u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_1, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_1[0] = 2048i64
                    stack_shape_1[1] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 0, 1, placeholder_4, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 2, @tir.address_of((int64*)stack_shape_1[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 0, 10, 2, dtype=int32)
                    stack_shape_1[2] = 768i64
                    stack_shape_1[3] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 1, 1, placeholder_5, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 2, @tir.address_of((int64*)stack_shape_1[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 1, 10, 2, dtype=int32)
                    stack_shape_1[4] = 2048i64
                    stack_shape_1[5] = 768i64
                    @tir.tvm_struct_set(stack_array_1, 2, 1, matmul_cublas_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 2, @tir.address_of((int64*)stack_shape_1[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 9, dev_id_1, dtype=int32)
                    @tir.tvm_struct_set(stack_array_1, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_1, 0, 12, @tir.tvm_struct_get(stack_array_1, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[0] = 7
                    @tir.tvm_struct_set(stack_value_1, 1, 12, @tir.tvm_struct_get(stack_array_1, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[1] = 7
                    @tir.tvm_struct_set(stack_value_1, 2, 12, @tir.tvm_struct_get(stack_array_1, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_1[2] = 7
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_1, 0, 12, T_add_1, dtype=int32)
                    stack_tcode_1[0] = 3
                    @tir.tvm_struct_set(stack_value_1, 1, 12, matmul_cublas_1, dtype=int32)
                    stack_tcode_1[1] = 3
                    @tir.tvm_struct_set(stack_value_1, 2, 12, placeholder_6, dtype=int32)
                    stack_tcode_1[2] = 3
                    @tir.tvm_struct_set(stack_value_1, 3, 12, cast(int64, 1536), dtype=int32)
                    stack_tcode_1[3] = 0
                    @tir.tvm_struct_set(stack_value_1, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_1[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_kernel0", stack_value_1, stack_tcode_1, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_1, matmul_cublas_1, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_2: handle, arg_type_ids_2: handle, num_args_2: int32, out_ret_value_2: handle, out_ret_tcode_2: handle, resource_handle_2: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_", "calling_conv": 1} {
  let stack_tcode_2: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_2: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_2: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_2: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_2 == 4), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: num_args should be 4")
  let arg0_2: handle = @tir.tvm_struct_get(args_2, 0, 12, dtype=handle)
  let arg0.code_2: int32 = (int32*)arg_type_ids_2[0]
  let arg1_2: handle = @tir.tvm_struct_get(args_2, 1, 12, dtype=handle)
  let arg1.code_2: int32 = (int32*)arg_type_ids_2[1]
  let arg2_2: handle = @tir.tvm_struct_get(args_2, 2, 12, dtype=handle)
  let arg2.code_2: int32 = (int32*)arg_type_ids_2[2]
  let arg3_2: handle = @tir.tvm_struct_get(args_2, 3, 12, dtype=handle)
  let arg3.code_2: int32 = (int32*)arg_type_ids_2[3]
  let placeholder_7: Pointer(float32) = @tir.tvm_struct_get(arg0_2, 0, 1, dtype=handle)
  attr [placeholder_7] "storage_alignment" = 128;
  let arg0.shape_2: handle = @tir.tvm_struct_get(arg0_2, 0, 2, dtype=handle)
  let arg0.strides_2: handle = @tir.tvm_struct_get(arg0_2, 0, 3, dtype=handle)
  let dev_id_2: int32 = @tir.tvm_struct_get(arg0_2, 0, 9, dtype=int32)
  let placeholder_8: Pointer(float32) = @tir.tvm_struct_get(arg1_2, 0, 1, dtype=handle)
  attr [placeholder_8] "storage_alignment" = 128;
  let arg1.shape_2: handle = @tir.tvm_struct_get(arg1_2, 0, 2, dtype=handle)
  let arg1.strides_2: handle = @tir.tvm_struct_get(arg1_2, 0, 3, dtype=handle)
  let placeholder_9: Pointer(float32) = @tir.tvm_struct_get(arg2_2, 0, 1, dtype=handle)
  attr [placeholder_9] "storage_alignment" = 128;
  let arg2.shape_2: handle = @tir.tvm_struct_get(arg2_2, 0, 2, dtype=handle)
  let arg2.strides_2: handle = @tir.tvm_struct_get(arg2_2, 0, 3, dtype=handle)
  let T_multiply: Pointer(float32) = @tir.tvm_struct_get(arg3_2, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg3.shape_2: handle = @tir.tvm_struct_get(arg3_2, 0, 2, dtype=handle)
  let arg3.strides_2: handle = @tir.tvm_struct_get(arg3_2, 0, 3, dtype=handle)
  assert(((((arg0.code_2 == 3) || (arg0.code_2 == 13)) || (arg0.code_2 == 7)) || (arg0.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[0] to be pointer")
  assert(((((arg1.code_2 == 3) || (arg1.code_2 == 13)) || (arg1.code_2 == 7)) || (arg1.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[1] to be pointer")
  assert(((((arg2.code_2 == 3) || (arg2.code_2 == 13)) || (arg2.code_2 == 7)) || (arg2.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[2] to be pointer")
  assert(((((arg3.code_2 == 3) || (arg3.code_2 == 13)) || (arg3.code_2 == 7)) || (arg3.code_2 == 4)), "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035_: Expect arg[3] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_2, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_2, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_2[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_2[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_2, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_2[1])) && (768 == cast(int32, (int64*)arg0.strides_2[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_2, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_2, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_2, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_2, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((3072 == cast(int32, (int64*)arg1.shape_2[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (3072 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_2[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_2, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_2[1])) && (768 == cast(int32, (int64*)arg1.strides_2[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_2, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_2, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_2 == @tir.tvm_struct_get(arg1_2, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((3072 == cast(int32, (int64*)arg2.shape_2[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (3072 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_2, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_2[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_2 == @tir.tvm_struct_get(arg2_2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_2, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_2, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_2, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_2, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_2[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((3072 == cast(int32, (int64*)arg3.shape_2[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (3072 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_2, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_2[1])) && (3072 == cast(int32, (int64*)arg3.strides_2[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_2, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_2, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_2 == @tir.tvm_struct_get(arg3_2, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
           {
             {
              @tir.tvm_struct_set(stack_value_2, 0, 12, cast(int64, 2), dtype=int32)
              stack_tcode_2[0] = 0
              @tir.tvm_struct_set(stack_value_2, 1, 12, cast(int64, dev_id_2), dtype=int32)
              stack_tcode_2[1] = 0
              @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_2, stack_tcode_2, 0, 2, dtype=int32)
            }
            attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__compute_";
            attr [matmul_cublas_2: Pointer(float32)] "storage_scope" = "global";
            attr [matmul_cublas_2] "storage_alignment" = 128 {
              let matmul_cublas_2 = @tir.TVMBackendAllocWorkspace(2, dev_id_2, 25165824u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(matmul_cublas_2, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                  attr [0] "extern_scope" = 0 {
                    stack_shape_2[0] = 2048i64
                    stack_shape_2[1] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 0, 1, placeholder_7, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 2, @tir.address_of((int64*)stack_shape_2[0], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 0, 10, 2, dtype=int32)
                    stack_shape_2[2] = 3072i64
                    stack_shape_2[3] = 768i64
                    @tir.tvm_struct_set(stack_array_2, 1, 1, placeholder_8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 2, @tir.address_of((int64*)stack_shape_2[2], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 1, 10, 2, dtype=int32)
                    stack_shape_2[4] = 2048i64
                    stack_shape_2[5] = 3072i64
                    @tir.tvm_struct_set(stack_array_2, 2, 1, matmul_cublas_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 2, @tir.address_of((int64*)stack_shape_2[4], dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 4, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 5, 2u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 6, 32u8, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 7, 1u16, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 8, 0u64, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 9, dev_id_2, dtype=int32)
                    @tir.tvm_struct_set(stack_array_2, 2, 10, 2, dtype=int32)
                    @tir.tvm_struct_set(stack_value_2, 0, 12, @tir.tvm_struct_get(stack_array_2, 0, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[0] = 7
                    @tir.tvm_struct_set(stack_value_2, 1, 12, @tir.tvm_struct_get(stack_array_2, 1, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[1] = 7
                    @tir.tvm_struct_set(stack_value_2, 2, 12, @tir.tvm_struct_get(stack_array_2, 2, 0, dtype=handle), dtype=int32)
                    stack_tcode_2[2] = 7
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, False), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, True), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_2, 0, 12, T_multiply, dtype=int32)
                    stack_tcode_2[0] = 3
                    @tir.tvm_struct_set(stack_value_2, 1, 12, matmul_cublas_2, dtype=int32)
                    stack_tcode_2[1] = 3
                    @tir.tvm_struct_set(stack_value_2, 2, 12, placeholder_9, dtype=int32)
                    stack_tcode_2[2] = 3
                    @tir.tvm_struct_set(stack_value_2, 3, 12, cast(int64, 6144), dtype=int32)
                    stack_tcode_2[3] = 0
                    @tir.tvm_struct_set(stack_value_2, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_2[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", stack_value_2, stack_tcode_2, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_2, matmul_cublas_2, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_3: handle, arg_type_ids_3: handle, num_args_3: int32, out_ret_value_3: handle, out_ret_tcode_3: handle, resource_handle_3: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape_transpose", "calling_conv": 1} {
  let stack_tcode_3: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_3: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_3 == 2), "fused_reshape_transpose_reshape_transpose: num_args should be 2")
  let arg0_3: handle = @tir.tvm_struct_get(args_3, 0, 12, dtype=handle)
  let arg0.code_3: int32 = (int32*)arg_type_ids_3[0]
  let arg1_3: handle = @tir.tvm_struct_get(args_3, 1, 12, dtype=handle)
  let arg1.code_3: int32 = (int32*)arg_type_ids_3[1]
  let placeholder_10: Pointer(float32) = @tir.tvm_struct_get(arg0_3, 0, 1, dtype=handle)
  attr [placeholder_10] "storage_alignment" = 128;
  let arg0.shape_3: handle = @tir.tvm_struct_get(arg0_3, 0, 2, dtype=handle)
  let arg0.strides_3: handle = @tir.tvm_struct_get(arg0_3, 0, 3, dtype=handle)
  let dev_id_3: int32 = @tir.tvm_struct_get(arg0_3, 0, 9, dtype=int32)
  let T_transpose: Pointer(float32) = @tir.tvm_struct_get(arg1_3, 0, 1, dtype=handle)
  attr [T_transpose] "storage_alignment" = 128;
  let arg1.shape_3: handle = @tir.tvm_struct_get(arg1_3, 0, 2, dtype=handle)
  let arg1.strides_3: handle = @tir.tvm_struct_get(arg1_3, 0, 3, dtype=handle)
  assert(((((arg0.code_3 == 3) || (arg0.code_3 == 13)) || (arg0.code_3 == 7)) || (arg0.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[0] to be pointer")
  assert(((((arg1.code_3 == 3) || (arg1.code_3 == 13)) || (arg1.code_3 == 7)) || (arg1.code_3 == 4)), "fused_reshape_transpose_reshape_transpose: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_3, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_3, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_3[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_3[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_3, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_3[1])) && (768 == cast(int32, (int64*)arg0.strides_3[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_3, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_3, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_3, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_3, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_3[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_3[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_3[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_3, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_3[2])) && (128 == cast(int32, (int64*)arg1.strides_3[1]))) && (8192 == cast(int32, (int64*)arg1.strides_3[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_3, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_3, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_3 == @tir.tvm_struct_get(arg1_3, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_3, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_3[0] = 0
          @tir.tvm_struct_set(stack_value_3, 1, 12, cast(int64, dev_id_3), dtype=int32)
          stack_tcode_3[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_3, stack_tcode_3, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_transpose_compute_" {
          @tir.tvm_struct_set(stack_value_3, 0, 12, T_transpose, dtype=int32)
          stack_tcode_3[0] = 3
          @tir.tvm_struct_set(stack_value_3, 1, 12, placeholder_10, dtype=int32)
          stack_tcode_3[1] = 3
          @tir.tvm_struct_set(stack_value_3, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_3[2] = 0
          @tir.tvm_struct_set(stack_value_3, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_3[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_transpose_kernel0", stack_value_3, stack_tcode_3, 0, 4, dtype=int32)
        }
      }
    }
  }
}

primfn(args_4: handle, arg_type_ids_4: handle, num_args_4: int32, out_ret_value_4: handle, out_ret_tcode_4: handle, resource_handle_4: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode_4: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_4: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_4 == 2), "fused_nn_softmax: num_args should be 2")
  let arg0_4: handle = @tir.tvm_struct_get(args_4, 0, 12, dtype=handle)
  let arg0.code_4: int32 = (int32*)arg_type_ids_4[0]
  let arg1_4: handle = @tir.tvm_struct_get(args_4, 1, 12, dtype=handle)
  let arg1.code_4: int32 = (int32*)arg_type_ids_4[1]
  let placeholder_11: Pointer(float32) = @tir.tvm_struct_get(arg0_4, 0, 1, dtype=handle)
  attr [placeholder_11] "storage_alignment" = 128;
  let arg0.shape_4: handle = @tir.tvm_struct_get(arg0_4, 0, 2, dtype=handle)
  let arg0.strides_4: handle = @tir.tvm_struct_get(arg0_4, 0, 3, dtype=handle)
  let dev_id_4: int32 = @tir.tvm_struct_get(arg0_4, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1_4, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape_4: handle = @tir.tvm_struct_get(arg1_4, 0, 2, dtype=handle)
  let arg1.strides_4: handle = @tir.tvm_struct_get(arg1_4, 0, 3, dtype=handle)
  assert(((((arg0.code_4 == 3) || (arg0.code_4 == 13)) || (arg0.code_4 == 7)) || (arg0.code_4 == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code_4 == 3) || (arg1.code_4 == 13)) || (arg1.code_4 == 7)) || (arg1.code_4 == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0_4, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_4, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((16 == cast(int32, (int64*)arg0.shape_4[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (16 == int32(arg0.shape[0]))")
  assert((12 == cast(int32, (int64*)arg0.shape_4[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (12 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
  assert((128 == cast(int32, (int64*)arg0.shape_4[3])), "Argument arg0.shape[3] has an unsatisfied constraint: (128 == int32(arg0.shape[3]))")
   {
    if !@tir.isnullptr(arg0.strides_4, dtype=bool) {
      assert(((((1 == cast(int32, (int64*)arg0.strides_4[3])) && (128 == cast(int32, (int64*)arg0.strides_4[2]))) && (16384 == cast(int32, (int64*)arg0.strides_4[1]))) && (196608 == cast(int32, (int64*)arg0.strides_4[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_4, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_4, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((4 == @tir.tvm_struct_get(arg1_4, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
    assert((((@tir.tvm_struct_get(arg1_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_4, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((16 == cast(int32, (int64*)arg1.shape_4[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((12 == cast(int32, (int64*)arg1.shape_4[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (12 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
    assert((128 == cast(int32, (int64*)arg1.shape_4[3])), "Argument arg1.shape[3] has an unsatisfied constraint: (128 == int32(arg1.shape[3]))")
     {
      if !@tir.isnullptr(arg1.strides_4, dtype=bool) {
        assert(((((1 == cast(int32, (int64*)arg1.strides_4[3])) && (128 == cast(int32, (int64*)arg1.strides_4[2]))) && (16384 == cast(int32, (int64*)arg1.strides_4[1]))) && (196608 == cast(int32, (int64*)arg1.strides_4[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_4, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_4, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_4 == @tir.tvm_struct_get(arg1_4, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_4, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_4[0] = 0
          @tir.tvm_struct_set(stack_value_4, 1, 12, cast(int64, dev_id_4), dtype=int32)
          stack_tcode_4[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_4, stack_tcode_4, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_nn_softmax_compute_";
        attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_maxelem] "storage_alignment" = 128 {
          let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 98304u64, 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
            attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
            attr [T_softmax_exp] "storage_alignment" = 128 {
              let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id_4, 12582912u64, 2, 32, dtype=handle)
               {
                if @tir.isnullptr(T_softmax_exp, dtype=bool) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
                 {
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, placeholder_11, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, cast(int64, 24), dtype=int32)
                    stack_tcode_4[2] = 0
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value_4, stack_tcode_4, 0, 4, dtype=int32)
                  }
                   {
                    @tir.tvm_struct_set(stack_value_4, 0, 12, T_softmax_norm, dtype=int32)
                    stack_tcode_4[0] = 3
                    @tir.tvm_struct_set(stack_value_4, 1, 12, T_softmax_exp, dtype=int32)
                    stack_tcode_4[1] = 3
                    @tir.tvm_struct_set(stack_value_4, 2, 12, T_softmax_maxelem, dtype=int32)
                    stack_tcode_4[2] = 3
                    @tir.tvm_struct_set(stack_value_4, 3, 12, cast(int64, 256), dtype=int32)
                    stack_tcode_4[3] = 0
                    @tir.tvm_struct_set(stack_value_4, 4, 12, cast(int64, 1024), dtype=int32)
                    stack_tcode_4[4] = 0
                    @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value_4, stack_tcode_4, 0, 5, dtype=int32)
                  }
                }
              }
              if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_exp, dtype=int32) != 0) {
                @tir.tvm_throw_last_error(, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id_4, T_softmax_maxelem, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_5: handle, arg_type_ids_5: handle, num_args_5: int32, out_ret_value_5: handle, out_ret_tcode_5: handle, resource_handle_5: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul_1", "calling_conv": 1} {
  let stack_tcode_5: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_5: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_3: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_3: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_5 == 3), "fused_nn_batch_matmul_1: num_args should be 3")
  let arg0_5: handle = @tir.tvm_struct_get(args_5, 0, 12, dtype=handle)
  let arg0.code_5: int32 = (int32*)arg_type_ids_5[0]
  let arg1_5: handle = @tir.tvm_struct_get(args_5, 1, 12, dtype=handle)
  let arg1.code_5: int32 = (int32*)arg_type_ids_5[1]
  let arg2_3: handle = @tir.tvm_struct_get(args_5, 2, 12, dtype=handle)
  let arg2.code_3: int32 = (int32*)arg_type_ids_5[2]
  let placeholder_12: Pointer(float32) = @tir.tvm_struct_get(arg0_5, 0, 1, dtype=handle)
  attr [placeholder_12] "storage_alignment" = 128;
  let arg0.shape_5: handle = @tir.tvm_struct_get(arg0_5, 0, 2, dtype=handle)
  let arg0.strides_5: handle = @tir.tvm_struct_get(arg0_5, 0, 3, dtype=handle)
  let dev_id_5: int32 = @tir.tvm_struct_get(arg0_5, 0, 9, dtype=int32)
  let placeholder_13: Pointer(float32) = @tir.tvm_struct_get(arg1_5, 0, 1, dtype=handle)
  attr [placeholder_13] "storage_alignment" = 128;
  let arg1.shape_5: handle = @tir.tvm_struct_get(arg1_5, 0, 2, dtype=handle)
  let arg1.strides_5: handle = @tir.tvm_struct_get(arg1_5, 0, 3, dtype=handle)
  let batch_matmul_cublas: Pointer(float32) = @tir.tvm_struct_get(arg2_3, 0, 1, dtype=handle)
  attr [batch_matmul_cublas] "storage_alignment" = 128;
  let arg2.shape_3: handle = @tir.tvm_struct_get(arg2_3, 0, 2, dtype=handle)
  let arg2.strides_3: handle = @tir.tvm_struct_get(arg2_3, 0, 3, dtype=handle)
  assert(((((arg0.code_5 == 3) || (arg0.code_5 == 13)) || (arg0.code_5 == 7)) || (arg0.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[0] to be pointer")
  assert(((((arg1.code_5 == 3) || (arg1.code_5 == 13)) || (arg1.code_5 == 7)) || (arg1.code_5 == 4)), "fused_nn_batch_matmul_1: Expect arg[1] to be pointer")
  assert(((((arg2.code_3 == 3) || (arg2.code_3 == 13)) || (arg2.code_3 == 7)) || (arg2.code_3 == 4)), "fused_nn_batch_matmul_1: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_5, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_5, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_5[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_5[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_5, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_5[2])) && (128 == cast(int32, (int64*)arg0.strides_5[1]))) && (16384 == cast(int32, (int64*)arg0.strides_5[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_5, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_5, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_5, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_5, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_5[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((64 == cast(int32, (int64*)arg1.shape_5[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (64 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_5[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_5, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_5[2])) && (128 == cast(int32, (int64*)arg1.strides_5[1]))) && (8192 == cast(int32, (int64*)arg1.strides_5[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_5, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_5, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_5 == @tir.tvm_struct_get(arg1_5, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_3, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_3, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_3[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_3[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((64 == cast(int32, (int64*)arg2.shape_3[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (64 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_3, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_3[2])) && (64 == cast(int32, (int64*)arg2.strides_3[1]))) && (8192 == cast(int32, (int64*)arg2.strides_3[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_3, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_3, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_5 == @tir.tvm_struct_get(arg2_3, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_5, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_5[0] = 0
            @tir.tvm_struct_set(stack_value_5, 1, 12, cast(int64, dev_id_5), dtype=int32)
            stack_tcode_5[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_5, stack_tcode_5, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_1_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_3[0] = 192i64
            stack_shape_3[1] = 128i64
            stack_shape_3[2] = 128i64
            @tir.tvm_struct_set(stack_array_3, 0, 1, placeholder_12, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 2, @tir.address_of((int64*)stack_shape_3[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 0, 10, 2, dtype=int32)
            stack_shape_3[3] = 192i64
            stack_shape_3[4] = 64i64
            stack_shape_3[5] = 128i64
            @tir.tvm_struct_set(stack_array_3, 1, 1, placeholder_13, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 2, @tir.address_of((int64*)stack_shape_3[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 1, 10, 2, dtype=int32)
            stack_shape_3[6] = 192i64
            stack_shape_3[7] = 128i64
            stack_shape_3[8] = 64i64
            @tir.tvm_struct_set(stack_array_3, 2, 1, batch_matmul_cublas, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 2, @tir.address_of((int64*)stack_shape_3[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 9, dev_id_5, dtype=int32)
            @tir.tvm_struct_set(stack_array_3, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_5, 0, 12, @tir.tvm_struct_get(stack_array_3, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_5[0] = 7
            @tir.tvm_struct_set(stack_value_5, 1, 12, @tir.tvm_struct_get(stack_array_3, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_5[1] = 7
            @tir.tvm_struct_set(stack_value_5, 2, 12, @tir.tvm_struct_get(stack_array_3, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_5[2] = 7
            @tir.tvm_struct_set(stack_value_5, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_5[3] = 0
            @tir.tvm_struct_set(stack_value_5, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_5[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_5, stack_tcode_5, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_6: handle, arg_type_ids_6: handle, num_args_6: int32, out_ret_value_6: handle, out_ret_tcode_6: handle, resource_handle_6: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add", "calling_conv": 1} {
  let stack_tcode_6: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_6: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  assert((num_args_6 == 3), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: num_args should be 3")
  let arg0_6: handle = @tir.tvm_struct_get(args_6, 0, 12, dtype=handle)
  let arg0.code_6: int32 = (int32*)arg_type_ids_6[0]
  let arg1_6: handle = @tir.tvm_struct_get(args_6, 1, 12, dtype=handle)
  let arg1.code_6: int32 = (int32*)arg_type_ids_6[1]
  let arg2_4: handle = @tir.tvm_struct_get(args_6, 2, 12, dtype=handle)
  let arg2.code_4: int32 = (int32*)arg_type_ids_6[2]
  let placeholder_14: Pointer(float32) = @tir.tvm_struct_get(arg0_6, 0, 1, dtype=handle)
  attr [placeholder_14] "storage_alignment" = 128;
  let arg0.shape_6: handle = @tir.tvm_struct_get(arg0_6, 0, 2, dtype=handle)
  let arg0.strides_6: handle = @tir.tvm_struct_get(arg0_6, 0, 3, dtype=handle)
  let dev_id_6: int32 = @tir.tvm_struct_get(arg0_6, 0, 9, dtype=int32)
  let placeholder_15: Pointer(int32) = @tir.tvm_struct_get(arg1_6, 0, 1, dtype=handle)
  attr [placeholder_15] "storage_alignment" = 128;
  let arg1.shape_6: handle = @tir.tvm_struct_get(arg1_6, 0, 2, dtype=handle)
  let arg1.strides_6: handle = @tir.tvm_struct_get(arg1_6, 0, 3, dtype=handle)
  let T_add_2: Pointer(float32) = @tir.tvm_struct_get(arg2_4, 0, 1, dtype=handle)
  attr [T_add_2] "storage_alignment" = 128;
  let arg2.shape_4: handle = @tir.tvm_struct_get(arg2_4, 0, 2, dtype=handle)
  let arg2.strides_4: handle = @tir.tvm_struct_get(arg2_4, 0, 3, dtype=handle)
  assert(((((arg0.code_6 == 3) || (arg0.code_6 == 13)) || (arg0.code_6 == 7)) || (arg0.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_6 == 3) || (arg1.code_6 == 13)) || (arg1.code_6 == 7)) || (arg1.code_6 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_4 == 3) || (arg2.code_4 == 13)) || (arg2.code_4 == 7)) || (arg2.code_4 == 4)), "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_6, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_6, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_6[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((128 == cast(int32, (int64*)arg0.shape_6[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (128 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_6, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_6[2])) && (128 == cast(int32, (int64*)arg0.strides_6[1]))) && (16384 == cast(int32, (int64*)arg0.strides_6[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_6, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_6, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_6, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_6, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_6, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int32")
    assert((16 == cast(int32, (int64*)arg1.shape_6[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (16 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((128 == cast(int32, (int64*)arg1.shape_6[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (128 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_6, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_6[2])) && (128 == cast(int32, (int64*)arg1.strides_6[1]))) && (16384 == cast(int32, (int64*)arg1.strides_6[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_6, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_6, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_6 == @tir.tvm_struct_get(arg1_6, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((4 == @tir.tvm_struct_get(arg2_4, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 4")
      assert((((@tir.tvm_struct_get(arg2_4, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_4, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_4, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((16 == cast(int32, (int64*)arg2.shape_4[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (16 == int32(arg2.shape[0]))")
      assert((12 == cast(int32, (int64*)arg2.shape_4[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (12 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
      assert((128 == cast(int32, (int64*)arg2.shape_4[3])), "Argument arg2.shape[3] has an unsatisfied constraint: (128 == int32(arg2.shape[3]))")
       {
        if !@tir.isnullptr(arg2.strides_4, dtype=bool) {
          assert(((((1 == cast(int32, (int64*)arg2.strides_4[3])) && (128 == cast(int32, (int64*)arg2.strides_4[2]))) && (16384 == cast(int32, (int64*)arg2.strides_4[1]))) && (196608 == cast(int32, (int64*)arg2.strides_4[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_4, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_4, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_6 == @tir.tvm_struct_get(arg2_4, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_6, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_6[0] = 0
            @tir.tvm_struct_set(stack_value_6, 1, 12, cast(int64, dev_id_6), dtype=int32)
            stack_tcode_6[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_6, stack_tcode_6, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_compute_" {
            @tir.tvm_struct_set(stack_value_6, 0, 12, T_add_2, dtype=int32)
            stack_tcode_6[0] = 3
            @tir.tvm_struct_set(stack_value_6, 1, 12, placeholder_14, dtype=int32)
            stack_tcode_6[1] = 3
            @tir.tvm_struct_set(stack_value_6, 2, 12, placeholder_15, dtype=int32)
            stack_tcode_6[2] = 3
            @tir.tvm_struct_set(stack_value_6, 3, 12, cast(int64, 256), dtype=int32)
            stack_tcode_6[3] = 0
            @tir.tvm_struct_set(stack_value_6, 4, 12, cast(int64, 1024), dtype=int32)
            stack_tcode_6[4] = 0
            @tir.tvm_call_packed_lowered("fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", stack_value_6, stack_tcode_6, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_7: handle, arg_type_ids_7: handle, num_args_7: int32, out_ret_value_7: handle, out_ret_tcode_7: handle, resource_handle_7: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_batch_matmul", "calling_conv": 1} {
  let stack_tcode_7: handle = @tir.tvm_stack_alloca("arg_tcode", 6, dtype=handle)
  let stack_value_7: handle = @tir.tvm_stack_alloca("arg_value", 6, dtype=handle)
  let stack_array_4: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_4: handle = @tir.tvm_stack_alloca("shape", 9, dtype=handle)
  assert((num_args_7 == 3), "fused_nn_batch_matmul: num_args should be 3")
  let arg0_7: handle = @tir.tvm_struct_get(args_7, 0, 12, dtype=handle)
  let arg0.code_7: int32 = (int32*)arg_type_ids_7[0]
  let arg1_7: handle = @tir.tvm_struct_get(args_7, 1, 12, dtype=handle)
  let arg1.code_7: int32 = (int32*)arg_type_ids_7[1]
  let arg2_5: handle = @tir.tvm_struct_get(args_7, 2, 12, dtype=handle)
  let arg2.code_5: int32 = (int32*)arg_type_ids_7[2]
  let placeholder_16: Pointer(float32) = @tir.tvm_struct_get(arg0_7, 0, 1, dtype=handle)
  attr [placeholder_16] "storage_alignment" = 128;
  let arg0.shape_7: handle = @tir.tvm_struct_get(arg0_7, 0, 2, dtype=handle)
  let arg0.strides_7: handle = @tir.tvm_struct_get(arg0_7, 0, 3, dtype=handle)
  let dev_id_7: int32 = @tir.tvm_struct_get(arg0_7, 0, 9, dtype=int32)
  let placeholder_17: Pointer(float32) = @tir.tvm_struct_get(arg1_7, 0, 1, dtype=handle)
  attr [placeholder_17] "storage_alignment" = 128;
  let arg1.shape_7: handle = @tir.tvm_struct_get(arg1_7, 0, 2, dtype=handle)
  let arg1.strides_7: handle = @tir.tvm_struct_get(arg1_7, 0, 3, dtype=handle)
  let batch_matmul_cublas_1: Pointer(float32) = @tir.tvm_struct_get(arg2_5, 0, 1, dtype=handle)
  attr [batch_matmul_cublas_1] "storage_alignment" = 128;
  let arg2.shape_5: handle = @tir.tvm_struct_get(arg2_5, 0, 2, dtype=handle)
  let arg2.strides_5: handle = @tir.tvm_struct_get(arg2_5, 0, 3, dtype=handle)
  assert(((((arg0.code_7 == 3) || (arg0.code_7 == 13)) || (arg0.code_7 == 7)) || (arg0.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[0] to be pointer")
  assert(((((arg1.code_7 == 3) || (arg1.code_7 == 13)) || (arg1.code_7 == 7)) || (arg1.code_7 == 4)), "fused_nn_batch_matmul: Expect arg[1] to be pointer")
  assert(((((arg2.code_5 == 3) || (arg2.code_5 == 13)) || (arg2.code_5 == 7)) || (arg2.code_5 == 4)), "fused_nn_batch_matmul: Expect arg[2] to be pointer")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((3 == @tir.tvm_struct_get(arg0_7, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 3")
  assert((((@tir.tvm_struct_get(arg0_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_7, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((192 == cast(int32, (int64*)arg0.shape_7[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (192 == int32(arg0.shape[0]))")
  assert((128 == cast(int32, (int64*)arg0.shape_7[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (128 == int32(arg0.shape[1]))")
  assert((64 == cast(int32, (int64*)arg0.shape_7[2])), "Argument arg0.shape[2] has an unsatisfied constraint: (64 == int32(arg0.shape[2]))")
   {
    if !@tir.isnullptr(arg0.strides_7, dtype=bool) {
      assert((((1 == cast(int32, (int64*)arg0.strides_7[2])) && (64 == cast(int32, (int64*)arg0.strides_7[1]))) && (8192 == cast(int32, (int64*)arg0.strides_7[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_7, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_7, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_7, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_7, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_7, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_7, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_7[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_7[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_7[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_7, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_7[2])) && (64 == cast(int32, (int64*)arg1.strides_7[1]))) && (8192 == cast(int32, (int64*)arg1.strides_7[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_7, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_7, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_7 == @tir.tvm_struct_get(arg1_7, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((3 == @tir.tvm_struct_get(arg2_5, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 3")
      assert((((@tir.tvm_struct_get(arg2_5, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_5, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_5, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((192 == cast(int32, (int64*)arg2.shape_5[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (192 == int32(arg2.shape[0]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[1])), "Argument arg2.shape[1] has an unsatisfied constraint: (128 == int32(arg2.shape[1]))")
      assert((128 == cast(int32, (int64*)arg2.shape_5[2])), "Argument arg2.shape[2] has an unsatisfied constraint: (128 == int32(arg2.shape[2]))")
       {
        if !@tir.isnullptr(arg2.strides_5, dtype=bool) {
          assert((((1 == cast(int32, (int64*)arg2.strides_5[2])) && (128 == cast(int32, (int64*)arg2.strides_5[1]))) && (16384 == cast(int32, (int64*)arg2.strides_5[0]))), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_5, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_5, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_7 == @tir.tvm_struct_get(arg2_5, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
         {
           {
            @tir.tvm_struct_set(stack_value_7, 0, 12, cast(int64, 2), dtype=int32)
            stack_tcode_7[0] = 0
            @tir.tvm_struct_set(stack_value_7, 1, 12, cast(int64, dev_id_7), dtype=int32)
            stack_tcode_7[1] = 0
            @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_7, stack_tcode_7, 0, 2, dtype=int32)
          }
          attr [0] "compute_scope" = "fused_nn_batch_matmul_compute_";
          attr [0] "extern_scope" = 0 {
            stack_shape_4[0] = 192i64
            stack_shape_4[1] = 128i64
            stack_shape_4[2] = 64i64
            @tir.tvm_struct_set(stack_array_4, 0, 1, placeholder_16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 2, @tir.address_of((int64*)stack_shape_4[0], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 0, 10, 2, dtype=int32)
            stack_shape_4[3] = 192i64
            stack_shape_4[4] = 128i64
            stack_shape_4[5] = 64i64
            @tir.tvm_struct_set(stack_array_4, 1, 1, placeholder_17, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 2, @tir.address_of((int64*)stack_shape_4[3], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 1, 10, 2, dtype=int32)
            stack_shape_4[6] = 192i64
            stack_shape_4[7] = 128i64
            stack_shape_4[8] = 128i64
            @tir.tvm_struct_set(stack_array_4, 2, 1, batch_matmul_cublas_1, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 2, @tir.address_of((int64*)stack_shape_4[6], dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 4, 3, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 5, 2u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 6, 32u8, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 7, 1u16, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 8, 0u64, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 9, dev_id_7, dtype=int32)
            @tir.tvm_struct_set(stack_array_4, 2, 10, 2, dtype=int32)
            @tir.tvm_struct_set(stack_value_7, 0, 12, @tir.tvm_struct_get(stack_array_4, 0, 0, dtype=handle), dtype=int32)
            stack_tcode_7[0] = 7
            @tir.tvm_struct_set(stack_value_7, 1, 12, @tir.tvm_struct_get(stack_array_4, 1, 0, dtype=handle), dtype=int32)
            stack_tcode_7[1] = 7
            @tir.tvm_struct_set(stack_value_7, 2, 12, @tir.tvm_struct_get(stack_array_4, 2, 0, dtype=handle), dtype=int32)
            stack_tcode_7[2] = 7
            @tir.tvm_struct_set(stack_value_7, 3, 12, cast(int64, False), dtype=int32)
            stack_tcode_7[3] = 0
            @tir.tvm_struct_set(stack_value_7, 4, 12, cast(int64, True), dtype=int32)
            stack_tcode_7[4] = 0
            @tir.tvm_call_packed_lowered("tvm.contrib.cublas.batch_matmul", stack_value_7, stack_tcode_7, 0, 5, dtype=int32)
          }
        }
      }
    }
  }
}

primfn(args_8: handle, arg_type_ids_8: handle, num_args_8: int32, out_ret_value_8: handle, out_ret_tcode_8: handle, resource_handle_8: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_dense_nn_bias_add_add", "calling_conv": 1} {
  let stack_tcode_8: handle = @tir.tvm_stack_alloca("arg_tcode", 7, dtype=handle)
  let stack_value_8: handle = @tir.tvm_stack_alloca("arg_value", 7, dtype=handle)
  let stack_array_5: handle = @tir.tvm_stack_alloca("array", 3, dtype=handle)
  let stack_shape_5: handle = @tir.tvm_stack_alloca("shape", 6, dtype=handle)
  assert((num_args_8 == 5), "fused_nn_dense_nn_bias_add_add: num_args should be 5")
  let arg0_8: handle = @tir.tvm_struct_get(args_8, 0, 12, dtype=handle)
  let arg0.code_8: int32 = (int32*)arg_type_ids_8[0]
  let arg1_8: handle = @tir.tvm_struct_get(args_8, 1, 12, dtype=handle)
  let arg1.code_8: int32 = (int32*)arg_type_ids_8[1]
  let arg2_6: handle = @tir.tvm_struct_get(args_8, 2, 12, dtype=handle)
  let arg2.code_6: int32 = (int32*)arg_type_ids_8[2]
  let arg3_3: handle = @tir.tvm_struct_get(args_8, 3, 12, dtype=handle)
  let arg3.code_3: int32 = (int32*)arg_type_ids_8[3]
  let arg4_1: handle = @tir.tvm_struct_get(args_8, 4, 12, dtype=handle)
  let arg4.code_1: int32 = (int32*)arg_type_ids_8[4]
  let placeholder_18: Pointer(float32) = @tir.tvm_struct_get(arg0_8, 0, 1, dtype=handle)
  attr [placeholder_18] "storage_alignment" = 128;
  let arg0.shape_8: handle = @tir.tvm_struct_get(arg0_8, 0, 2, dtype=handle)
  let arg0.strides_8: handle = @tir.tvm_struct_get(arg0_8, 0, 3, dtype=handle)
  let dev_id_8: int32 = @tir.tvm_struct_get(arg0_8, 0, 9, dtype=int32)
  let placeholder_19: Pointer(float32) = @tir.tvm_struct_get(arg1_8, 0, 1, dtype=handle)
  attr [placeholder_19] "storage_alignment" = 128;
  let arg1.shape_8: handle = @tir.tvm_struct_get(arg1_8, 0, 2, dtype=handle)
  let arg1.strides_8: handle = @tir.tvm_struct_get(arg1_8, 0, 3, dtype=handle)
  let placeholder_20: Pointer(float32) = @tir.tvm_struct_get(arg2_6, 0, 1, dtype=handle)
  attr [placeholder_20] "storage_alignment" = 128;
  let arg2.shape_6: handle = @tir.tvm_struct_get(arg2_6, 0, 2, dtype=handle)
  let arg2.strides_6: handle = @tir.tvm_struct_get(arg2_6, 0, 3, dtype=handle)
  let placeholder_21: Pointer(float32) = @tir.tvm_struct_get(arg3_3, 0, 1, dtype=handle)
  attr [placeholder_21] "storage_alignment" = 128;
  let arg3.shape_3: handle = @tir.tvm_struct_get(arg3_3, 0, 2, dtype=handle)
  let arg3.strides_3: handle = @tir.tvm_struct_get(arg3_3, 0, 3, dtype=handle)
  let T_add_3: Pointer(float32) = @tir.tvm_struct_get(arg4_1, 0, 1, dtype=handle)
  attr [T_add_3] "storage_alignment" = 128;
  let arg4.shape_1: handle = @tir.tvm_struct_get(arg4_1, 0, 2, dtype=handle)
  let arg4.strides_1: handle = @tir.tvm_struct_get(arg4_1, 0, 3, dtype=handle)
  assert(((((arg0.code_8 == 3) || (arg0.code_8 == 13)) || (arg0.code_8 == 7)) || (arg0.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[0] to be pointer")
  assert(((((arg1.code_8 == 3) || (arg1.code_8 == 13)) || (arg1.code_8 == 7)) || (arg1.code_8 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[1] to be pointer")
  assert(((((arg2.code_6 == 3) || (arg2.code_6 == 13)) || (arg2.code_6 == 7)) || (arg2.code_6 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[2] to be pointer")
  assert(((((arg3.code_3 == 3) || (arg3.code_3 == 13)) || (arg3.code_3 == 7)) || (arg3.code_3 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[3] to be pointer")
  assert(((((arg4.code_1 == 3) || (arg4.code_1 == 13)) || (arg4.code_1 == 7)) || (arg4.code_1 == 4)), "fused_nn_dense_nn_bias_add_add: Expect arg[4] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_8, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_8, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_8[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_8[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_8, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_8[1])) && (768 == cast(int32, (int64*)arg0.strides_8[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_8, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_8, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((2 == @tir.tvm_struct_get(arg1_8, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 2")
    assert((((@tir.tvm_struct_get(arg1_8, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_8, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_8, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((768 == cast(int32, (int64*)arg1.shape_8[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (768 == int32(arg1.shape[0]))")
    assert((768 == cast(int32, (int64*)arg1.shape_8[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (768 == int32(arg1.shape[1]))")
     {
      if !@tir.isnullptr(arg1.strides_8, dtype=bool) {
        assert(((1 == cast(int32, (int64*)arg1.strides_8[1])) && (768 == cast(int32, (int64*)arg1.strides_8[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_8, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_8, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_8 == @tir.tvm_struct_get(arg1_8, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((1 == @tir.tvm_struct_get(arg2_6, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 1")
      assert((((@tir.tvm_struct_get(arg2_6, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg2_6, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg2_6, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be float32")
      assert((768 == cast(int32, (int64*)arg2.shape_6[0])), "Argument arg2.shape[0] has an unsatisfied constraint: (768 == int32(arg2.shape[0]))")
       {
        if !@tir.isnullptr(arg2.strides_6, dtype=bool) {
          assert((1 == cast(int32, (int64*)arg2.strides_6[0])), "arg2.strides: expected to be compact array")
          0
        }
        assert((0u64 == @tir.tvm_struct_get(arg2_6, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
        assert((2 == @tir.tvm_struct_get(arg2_6, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg2, 0, 10))")
        assert((dev_id_8 == @tir.tvm_struct_get(arg2_6, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((2 == @tir.tvm_struct_get(arg3_3, 0, 4, dtype=int32)), "arg3.ndim is expected to equal 2")
        assert((((@tir.tvm_struct_get(arg3_3, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg3_3, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg3_3, 0, 7, dtype=uint16) == 1u16)), "arg3.dtype is expected to be float32")
        assert((2048 == cast(int32, (int64*)arg3.shape_3[0])), "Argument arg3.shape[0] has an unsatisfied constraint: (2048 == int32(arg3.shape[0]))")
        assert((768 == cast(int32, (int64*)arg3.shape_3[1])), "Argument arg3.shape[1] has an unsatisfied constraint: (768 == int32(arg3.shape[1]))")
         {
          if !@tir.isnullptr(arg3.strides_3, dtype=bool) {
            assert(((1 == cast(int32, (int64*)arg3.strides_3[1])) && (768 == cast(int32, (int64*)arg3.strides_3[0]))), "arg3.strides: expected to be compact array")
            0
          }
          assert((0u64 == @tir.tvm_struct_get(arg3_3, 0, 8, dtype=uint64)), "Argument arg3.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg3, 0, 8))")
          assert((2 == @tir.tvm_struct_get(arg3_3, 0, 10, dtype=int32)), "Argument arg3.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg3, 0, 10))")
          assert((dev_id_8 == @tir.tvm_struct_get(arg3_3, 0, 9, dtype=int32)), "Argument arg3.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg3, 0, 9))")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((2 == @tir.tvm_struct_get(arg4_1, 0, 4, dtype=int32)), "arg4.ndim is expected to equal 2")
          assert((((@tir.tvm_struct_get(arg4_1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg4_1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg4_1, 0, 7, dtype=uint16) == 1u16)), "arg4.dtype is expected to be float32")
          assert((2048 == cast(int32, (int64*)arg4.shape_1[0])), "Argument arg4.shape[0] has an unsatisfied constraint: (2048 == int32(arg4.shape[0]))")
          assert((768 == cast(int32, (int64*)arg4.shape_1[1])), "Argument arg4.shape[1] has an unsatisfied constraint: (768 == int32(arg4.shape[1]))")
           {
            if !@tir.isnullptr(arg4.strides_1, dtype=bool) {
              assert(((1 == cast(int32, (int64*)arg4.strides_1[1])) && (768 == cast(int32, (int64*)arg4.strides_1[0]))), "arg4.strides: expected to be compact array")
              0
            }
            assert((0u64 == @tir.tvm_struct_get(arg4_1, 0, 8, dtype=uint64)), "Argument arg4.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg4, 0, 8))")
            assert((2 == @tir.tvm_struct_get(arg4_1, 0, 10, dtype=int32)), "Argument arg4.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg4, 0, 10))")
            assert((dev_id_8 == @tir.tvm_struct_get(arg4_1, 0, 9, dtype=int32)), "Argument arg4.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg4, 0, 9))")
             {
               {
                @tir.tvm_struct_set(stack_value_8, 0, 12, cast(int64, 2), dtype=int32)
                stack_tcode_8[0] = 0
                @tir.tvm_struct_set(stack_value_8, 1, 12, cast(int64, dev_id_8), dtype=int32)
                stack_tcode_8[1] = 0
                @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_8, stack_tcode_8, 0, 2, dtype=int32)
              }
              attr [0] "compute_scope" = "fused_nn_dense_nn_bias_add_add_compute_";
              attr [matmul_cublas_3: Pointer(float32)] "storage_scope" = "global";
              attr [matmul_cublas_3] "storage_alignment" = 128 {
                let matmul_cublas_3 = @tir.TVMBackendAllocWorkspace(2, dev_id_8, 6291456u64, 2, 32, dtype=handle)
                 {
                  if @tir.isnullptr(matmul_cublas_3, dtype=bool) {
                    @tir.tvm_throw_last_error(, dtype=int32)
                  }
                   {
                    attr [0] "extern_scope" = 0 {
                      stack_shape_5[0] = 2048i64
                      stack_shape_5[1] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 0, 1, placeholder_18, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 2, @tir.address_of((int64*)stack_shape_5[0], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 0, 10, 2, dtype=int32)
                      stack_shape_5[2] = 768i64
                      stack_shape_5[3] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 1, 1, placeholder_19, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 2, @tir.address_of((int64*)stack_shape_5[2], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 1, 10, 2, dtype=int32)
                      stack_shape_5[4] = 2048i64
                      stack_shape_5[5] = 768i64
                      @tir.tvm_struct_set(stack_array_5, 2, 1, matmul_cublas_3, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 2, @tir.address_of((int64*)stack_shape_5[4], dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 3, @tir.reinterpret(0u64, dtype=handle), dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 4, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 5, 2u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 6, 32u8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 7, 1u16, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 8, 0u64, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 9, dev_id_8, dtype=int32)
                      @tir.tvm_struct_set(stack_array_5, 2, 10, 2, dtype=int32)
                      @tir.tvm_struct_set(stack_value_8, 0, 12, @tir.tvm_struct_get(stack_array_5, 0, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[0] = 7
                      @tir.tvm_struct_set(stack_value_8, 1, 12, @tir.tvm_struct_get(stack_array_5, 1, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[1] = 7
                      @tir.tvm_struct_set(stack_value_8, 2, 12, @tir.tvm_struct_get(stack_array_5, 2, 0, dtype=handle), dtype=int32)
                      stack_tcode_8[2] = 7
                      @tir.tvm_struct_set(stack_value_8, 3, 12, cast(int64, False), dtype=int32)
                      stack_tcode_8[3] = 0
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, True), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_call_packed_lowered("tvm.contrib.cublas.matmul", stack_value_8, stack_tcode_8, 0, 5, dtype=int32)
                    }
                     {
                      @tir.tvm_struct_set(stack_value_8, 0, 12, T_add_3, dtype=int32)
                      stack_tcode_8[0] = 3
                      @tir.tvm_struct_set(stack_value_8, 1, 12, matmul_cublas_3, dtype=int32)
                      stack_tcode_8[1] = 3
                      @tir.tvm_struct_set(stack_value_8, 2, 12, placeholder_20, dtype=int32)
                      stack_tcode_8[2] = 3
                      @tir.tvm_struct_set(stack_value_8, 3, 12, placeholder_21, dtype=int32)
                      stack_tcode_8[3] = 3
                      @tir.tvm_struct_set(stack_value_8, 4, 12, cast(int64, 1536), dtype=int32)
                      stack_tcode_8[4] = 0
                      @tir.tvm_struct_set(stack_value_8, 5, 12, cast(int64, 1024), dtype=int32)
                      stack_tcode_8[5] = 0
                      @tir.tvm_call_packed_lowered("fused_nn_dense_nn_bias_add_add_kernel0", stack_value_8, stack_tcode_8, 0, 6, dtype=int32)
                    }
                  }
                }
                if (@tir.TVMBackendFreeWorkspace(2, dev_id_8, matmul_cublas_3, dtype=int32) != 0) {
                  @tir.tvm_throw_last_error(, dtype=int32)
                }
              }
            }
          }
        }
      }
    }
  }
}

primfn(args_9: handle, arg_type_ids_9: handle, num_args_9: int32, out_ret_value_9: handle, out_ret_tcode_9: handle, resource_handle_9: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_reshape_transpose_reshape", "calling_conv": 1} {
  let stack_tcode_9: handle = @tir.tvm_stack_alloca("arg_tcode", 5, dtype=handle)
  let stack_value_9: handle = @tir.tvm_stack_alloca("arg_value", 5, dtype=handle)
  assert((num_args_9 == 2), "fused_reshape_transpose_reshape: num_args should be 2")
  let arg0_9: handle = @tir.tvm_struct_get(args_9, 0, 12, dtype=handle)
  let arg0.code_9: int32 = (int32*)arg_type_ids_9[0]
  let arg1_9: handle = @tir.tvm_struct_get(args_9, 1, 12, dtype=handle)
  let arg1.code_9: int32 = (int32*)arg_type_ids_9[1]
  let placeholder_22: Pointer(float32) = @tir.tvm_struct_get(arg0_9, 0, 1, dtype=handle)
  attr [placeholder_22] "storage_alignment" = 128;
  let arg0.shape_9: handle = @tir.tvm_struct_get(arg0_9, 0, 2, dtype=handle)
  let arg0.strides_9: handle = @tir.tvm_struct_get(arg0_9, 0, 3, dtype=handle)
  let dev_id_9: int32 = @tir.tvm_struct_get(arg0_9, 0, 9, dtype=int32)
  let T_reshape: Pointer(float32) = @tir.tvm_struct_get(arg1_9, 0, 1, dtype=handle)
  attr [T_reshape] "storage_alignment" = 128;
  let arg1.shape_9: handle = @tir.tvm_struct_get(arg1_9, 0, 2, dtype=handle)
  let arg1.strides_9: handle = @tir.tvm_struct_get(arg1_9, 0, 3, dtype=handle)
  assert(((((arg0.code_9 == 3) || (arg0.code_9 == 13)) || (arg0.code_9 == 7)) || (arg0.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[0] to be pointer")
  assert(((((arg1.code_9 == 3) || (arg1.code_9 == 13)) || (arg1.code_9 == 7)) || (arg1.code_9 == 4)), "fused_reshape_transpose_reshape: Expect arg[1] to be pointer")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((2 == @tir.tvm_struct_get(arg0_9, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 2")
  assert((((@tir.tvm_struct_get(arg0_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0_9, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((2048 == cast(int32, (int64*)arg0.shape_9[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (2048 == int32(arg0.shape[0]))")
  assert((768 == cast(int32, (int64*)arg0.shape_9[1])), "Argument arg0.shape[1] has an unsatisfied constraint: (768 == int32(arg0.shape[1]))")
   {
    if !@tir.isnullptr(arg0.strides_9, dtype=bool) {
      assert(((1 == cast(int32, (int64*)arg0.strides_9[1])) && (768 == cast(int32, (int64*)arg0.strides_9[0]))), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0_9, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((2 == @tir.tvm_struct_get(arg0_9, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((3 == @tir.tvm_struct_get(arg1_9, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 3")
    assert((((@tir.tvm_struct_get(arg1_9, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1_9, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1_9, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
    assert((192 == cast(int32, (int64*)arg1.shape_9[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (192 == int32(arg1.shape[0]))")
    assert((128 == cast(int32, (int64*)arg1.shape_9[1])), "Argument arg1.shape[1] has an unsatisfied constraint: (128 == int32(arg1.shape[1]))")
    assert((64 == cast(int32, (int64*)arg1.shape_9[2])), "Argument arg1.shape[2] has an unsatisfied constraint: (64 == int32(arg1.shape[2]))")
     {
      if !@tir.isnullptr(arg1.strides_9, dtype=bool) {
        assert((((1 == cast(int32, (int64*)arg1.strides_9[2])) && (64 == cast(int32, (int64*)arg1.strides_9[1]))) && (8192 == cast(int32, (int64*)arg1.strides_9[0]))), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1_9, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((2 == @tir.tvm_struct_get(arg1_9, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id_9 == @tir.tvm_struct_get(arg1_9, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
       {
         {
          @tir.tvm_struct_set(stack_value_9, 0, 12, cast(int64, 2), dtype=int32)
          stack_tcode_9[0] = 0
          @tir.tvm_struct_set(stack_value_9, 1, 12, cast(int64, dev_id_9), dtype=int32)
          stack_tcode_9[1] = 0
          @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value_9, stack_tcode_9, 0, 2, dtype=int32)
        }
        attr [0] "compute_scope" = "fused_reshape_transpose_reshape_compute_" {
          @tir.tvm_struct_set(stack_value_9, 0, 12, T_reshape, dtype=int32)
          stack_tcode_9[0] = 3
          @tir.tvm_struct_set(stack_value_9, 1, 12, placeholder_22, dtype=int32)
          stack_tcode_9[1] = 3
          @tir.tvm_struct_set(stack_value_9, 2, 12, cast(int64, 256), dtype=int32)
          stack_tcode_9[2] = 0
          @tir.tvm_struct_set(stack_value_9, 3, 12, cast(int64, 1024), dtype=int32)
          stack_tcode_9[3] = 0
          @tir.tvm_call_packed_lowered("fused_reshape_transpose_reshape_kernel0", stack_value_9, stack_tcode_9, 0, 4, dtype=int32)
        }
      }
    }
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass Filter
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
    T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.exp(((float32*)placeholder[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x*8)) + floordiv(threadIdx.x, 128))]), dtype=float32)
  }
}

primfn(T_add: Pointer(float32), matmul_cublas: Pointer(float32), placeholder_1: Pointer(float32), placeholder_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_1_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_1[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 768)]) + (float32*)placeholder_2[((blockIdx.x_1*1024) + threadIdx.x_1)])
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_1: Pointer(float32), T_softmax_maxelem_1: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
    T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] = ((float32*)T_softmax_exp_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] / (float32*)T_softmax_maxelem_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_2*8)) + floordiv(threadIdx.x_2, 128))])
  }
}

primfn(T_transpose: Pointer(float32), placeholder_3: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_transpose_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_3[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_4: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_4, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_4, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
    for (k: int32, 0, 128) {
      T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_4[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
    }
  }
}

primfn(T_multiply: Pointer(float32), matmul_cublas_1: Pointer(float32), placeholder_5: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_5, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
  attr [IterVar(threadIdx.x_5, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_multiply[((blockIdx.x_5*1024) + threadIdx.x_5)] = (((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
}

primfn(T_reshape: Pointer(float32), placeholder_6: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_6, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_6, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_6*1024)) + threadIdx.x_6)] = (float32*)placeholder_6[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*64)) + floormod(threadIdx.x_6, 64))]
  }
}

primfn(T_add_1: Pointer(float32), matmul_cublas_2: Pointer(float32), placeholder_7: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_7, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_7, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_1[((blockIdx.x_7*1024) + threadIdx.x_7)] = ((float32*)matmul_cublas_2[((blockIdx.x_7*1024) + threadIdx.x_7)] + (float32*)placeholder_7[floormod(((blockIdx.x_7*1024) + threadIdx.x_7), 768)])
}

primfn(T_softmax_maxelem_3: Pointer(float32), T_softmax_exp_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_8, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_8, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = 0f32
    for (k_1: int32, 0, 128) {
      T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = ((float32*)T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)T_softmax_exp_2[(((blockIdx.x_8*131072) + (threadIdx.x_8*128)) + k_1)])
    }
  }
}

primfn(T_add_2: Pointer(float32), matmul_cublas_3: Pointer(float32), placeholder_8: Pointer(float32), placeholder_9: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_9, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_9, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_2[((blockIdx.x_9*1024) + threadIdx.x_9)] = (((float32*)matmul_cublas_3[((blockIdx.x_9*1024) + threadIdx.x_9)] + (float32*)placeholder_8[floormod(((blockIdx.x_9*1024) + threadIdx.x_9), 768)]) + (float32*)placeholder_9[((blockIdx.x_9*1024) + threadIdx.x_9)])
}

primfn(T_add_3: Pointer(float32), placeholder_10: Pointer(float32), placeholder_11: Pointer(int32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_10, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_3[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_10[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_11[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass BindTarget
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
    T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.exp(((float32*)placeholder[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x*8)) + floordiv(threadIdx.x, 128))]), dtype=float32)
  }
}

primfn(T_add: Pointer(float32), matmul_cublas: Pointer(float32), placeholder_1: Pointer(float32), placeholder_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_1_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_1[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 768)]) + (float32*)placeholder_2[((blockIdx.x_1*1024) + threadIdx.x_1)])
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_1: Pointer(float32), T_softmax_maxelem_1: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
    T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] = ((float32*)T_softmax_exp_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] / (float32*)T_softmax_maxelem_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_2*8)) + floordiv(threadIdx.x_2, 128))])
  }
}

primfn(T_transpose: Pointer(float32), placeholder_3: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_transpose_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_3[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_4: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_4, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_4, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
    for (k: int32, 0, 128) {
      T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_4[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
    }
  }
}

primfn(T_multiply: Pointer(float32), matmul_cublas_1: Pointer(float32), placeholder_5: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_5, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
  attr [IterVar(threadIdx.x_5, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_multiply[((blockIdx.x_5*1024) + threadIdx.x_5)] = (((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
}

primfn(T_reshape: Pointer(float32), placeholder_6: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_6, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_6, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_6*1024)) + threadIdx.x_6)] = (float32*)placeholder_6[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*64)) + floormod(threadIdx.x_6, 64))]
  }
}

primfn(T_add_1: Pointer(float32), matmul_cublas_2: Pointer(float32), placeholder_7: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_7, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_7, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_1[((blockIdx.x_7*1024) + threadIdx.x_7)] = ((float32*)matmul_cublas_2[((blockIdx.x_7*1024) + threadIdx.x_7)] + (float32*)placeholder_7[floormod(((blockIdx.x_7*1024) + threadIdx.x_7), 768)])
}

primfn(T_softmax_maxelem_3: Pointer(float32), T_softmax_exp_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_8, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_8, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = 0f32
    for (k_1: int32, 0, 128) {
      T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = ((float32*)T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)T_softmax_exp_2[(((blockIdx.x_8*131072) + (threadIdx.x_8*128)) + k_1)])
    }
  }
}

primfn(T_add_2: Pointer(float32), matmul_cublas_3: Pointer(float32), placeholder_8: Pointer(float32), placeholder_9: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_9, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_9, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_2[((blockIdx.x_9*1024) + threadIdx.x_9)] = (((float32*)matmul_cublas_3[((blockIdx.x_9*1024) + threadIdx.x_9)] + (float32*)placeholder_8[floormod(((blockIdx.x_9*1024) + threadIdx.x_9), 768)]) + (float32*)placeholder_9[((blockIdx.x_9*1024) + threadIdx.x_9)])
}

primfn(T_add_3: Pointer(float32), placeholder_10: Pointer(float32), placeholder_11: Pointer(int32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_10, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_3[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_10[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_11[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerWarpMemory
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
    T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.exp(((float32*)placeholder[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x*8)) + floordiv(threadIdx.x, 128))]), dtype=float32)
  }
}

primfn(T_add: Pointer(float32), matmul_cublas: Pointer(float32), placeholder_1: Pointer(float32), placeholder_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_1_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_1[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 768)]) + (float32*)placeholder_2[((blockIdx.x_1*1024) + threadIdx.x_1)])
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_1: Pointer(float32), T_softmax_maxelem_1: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
    T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] = ((float32*)T_softmax_exp_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] / (float32*)T_softmax_maxelem_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_2*8)) + floordiv(threadIdx.x_2, 128))])
  }
}

primfn(T_transpose: Pointer(float32), placeholder_3: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_transpose_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_3[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_4: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_4, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_4, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
    for (k: int32, 0, 128) {
      T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_4[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
    }
  }
}

primfn(T_multiply: Pointer(float32), matmul_cublas_1: Pointer(float32), placeholder_5: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_5, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
  attr [IterVar(threadIdx.x_5, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_multiply[((blockIdx.x_5*1024) + threadIdx.x_5)] = (((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
}

primfn(T_reshape: Pointer(float32), placeholder_6: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_6, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_6, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_6*1024)) + threadIdx.x_6)] = (float32*)placeholder_6[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*64)) + floormod(threadIdx.x_6, 64))]
  }
}

primfn(T_add_1: Pointer(float32), matmul_cublas_2: Pointer(float32), placeholder_7: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_7, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_7, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_1[((blockIdx.x_7*1024) + threadIdx.x_7)] = ((float32*)matmul_cublas_2[((blockIdx.x_7*1024) + threadIdx.x_7)] + (float32*)placeholder_7[floormod(((blockIdx.x_7*1024) + threadIdx.x_7), 768)])
}

primfn(T_softmax_maxelem_3: Pointer(float32), T_softmax_exp_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_8, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_8, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = 0f32
    for (k_1: int32, 0, 128) {
      T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = ((float32*)T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)T_softmax_exp_2[(((blockIdx.x_8*131072) + (threadIdx.x_8*128)) + k_1)])
    }
  }
}

primfn(T_add_2: Pointer(float32), matmul_cublas_3: Pointer(float32), placeholder_8: Pointer(float32), placeholder_9: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_9, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_9, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_2[((blockIdx.x_9*1024) + threadIdx.x_9)] = (((float32*)matmul_cublas_3[((blockIdx.x_9*1024) + threadIdx.x_9)] + (float32*)placeholder_8[floormod(((blockIdx.x_9*1024) + threadIdx.x_9), 768)]) + (float32*)placeholder_9[((blockIdx.x_9*1024) + threadIdx.x_9)])
}

primfn(T_add_3: Pointer(float32), placeholder_10: Pointer(float32), placeholder_11: Pointer(int32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_10, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_3[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_10[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128))*128)) + floormod(threadIdx.x_10, 128))]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_11[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.Simplify
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
    T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.exp(((float32*)placeholder[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x*8)) + floordiv(threadIdx.x, 128))]), dtype=float32)
  }
}

primfn(T_add: Pointer(float32), matmul_cublas: Pointer(float32), placeholder_1: Pointer(float32), placeholder_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_1_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_1[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 768)]) + (float32*)placeholder_2[((blockIdx.x_1*1024) + threadIdx.x_1)])
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_1: Pointer(float32), T_softmax_maxelem_1: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
    T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] = ((float32*)T_softmax_exp_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] / (float32*)T_softmax_maxelem_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_2*8)) + floordiv(threadIdx.x_2, 128))])
  }
}

primfn(T_transpose: Pointer(float32), placeholder_3: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_transpose_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_3[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_4: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_4, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_4, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
    for (k: int32, 0, 128) {
      T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_4[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
    }
  }
}

primfn(T_multiply: Pointer(float32), matmul_cublas_1: Pointer(float32), placeholder_5: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_5, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
  attr [IterVar(threadIdx.x_5, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_multiply[((blockIdx.x_5*1024) + threadIdx.x_5)] = (((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
}

primfn(T_reshape: Pointer(float32), placeholder_6: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_6, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_6, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_6*1024)) + threadIdx.x_6)] = (float32*)placeholder_6[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*64)) + floormod(threadIdx.x_6, 64))]
  }
}

primfn(T_add_1: Pointer(float32), matmul_cublas_2: Pointer(float32), placeholder_7: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_7, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_7, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_1[((blockIdx.x_7*1024) + threadIdx.x_7)] = ((float32*)matmul_cublas_2[((blockIdx.x_7*1024) + threadIdx.x_7)] + (float32*)placeholder_7[floormod(((blockIdx.x_7*1024) + threadIdx.x_7), 768)])
}

primfn(T_softmax_maxelem_3: Pointer(float32), T_softmax_exp_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_8, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_8, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = 0f32
    for (k_1: int32, 0, 128) {
      T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = ((float32*)T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)T_softmax_exp_2[(((blockIdx.x_8*131072) + (threadIdx.x_8*128)) + k_1)])
    }
  }
}

primfn(T_add_2: Pointer(float32), matmul_cublas_3: Pointer(float32), placeholder_8: Pointer(float32), placeholder_9: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_9, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_9, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_2[((blockIdx.x_9*1024) + threadIdx.x_9)] = (((float32*)matmul_cublas_3[((blockIdx.x_9*1024) + threadIdx.x_9)] + (float32*)placeholder_8[floormod(((blockIdx.x_9*1024) + threadIdx.x_9), 768)]) + (float32*)placeholder_9[((blockIdx.x_9*1024) + threadIdx.x_9)])
}

primfn(T_add_3: Pointer(float32), placeholder_10: Pointer(float32), placeholder_11: Pointer(int32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_10, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_3[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_10[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_11[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerCustomDatatypes
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
    T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.exp(((float32*)placeholder[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x*8)) + floordiv(threadIdx.x, 128))]), dtype=float32)
  }
}

primfn(T_add: Pointer(float32), matmul_cublas: Pointer(float32), placeholder_1: Pointer(float32), placeholder_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_1_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_1[floormod(((blockIdx.x_1*1024) + threadIdx.x_1), 768)]) + (float32*)placeholder_2[((blockIdx.x_1*1024) + threadIdx.x_1)])
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_1: Pointer(float32), T_softmax_maxelem_1: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
    T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] = ((float32*)T_softmax_exp_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] / (float32*)T_softmax_maxelem_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_2*8)) + floordiv(threadIdx.x_2, 128))])
  }
}

primfn(T_transpose: Pointer(float32), placeholder_3: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_transpose_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_3[((((floordiv(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*98304) + (floormod(threadIdx.x_3, 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer*32) + floordiv(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64)), 12)*64)) + floormod(((blockIdx.x_3*8) + floordiv(threadIdx.x_3, 128)), 64))]
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_4: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_4, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_4, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
    for (k: int32, 0, 128) {
      T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_4[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
    }
  }
}

primfn(T_multiply: Pointer(float32), matmul_cublas_1: Pointer(float32), placeholder_5: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_5, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
  attr [IterVar(threadIdx.x_5, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_multiply[((blockIdx.x_5*1024) + threadIdx.x_5)] = (((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)])*(0.5f32*(1f32 + @tir.tanh((0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]) + (0.044715f32*@tir.pow(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[floormod(((blockIdx.x_5*1024) + threadIdx.x_5), 3072)]), 3f32, dtype=float32)))), dtype=float32))))
}

primfn(T_reshape: Pointer(float32), placeholder_6: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_6, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_6, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_6*1024)) + threadIdx.x_6)] = (float32*)placeholder_6[((((floordiv(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*98304) + (floormod(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)*768)) + (floormod(((ax0.ax1.fused.ax2.fused.outer_1*32) + floordiv(((blockIdx.x_6*16) + floordiv(threadIdx.x_6, 64)), 128)), 12)*64)) + floormod(threadIdx.x_6, 64))]
  }
}

primfn(T_add_1: Pointer(float32), matmul_cublas_2: Pointer(float32), placeholder_7: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_7, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_7, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_1[((blockIdx.x_7*1024) + threadIdx.x_7)] = ((float32*)matmul_cublas_2[((blockIdx.x_7*1024) + threadIdx.x_7)] + (float32*)placeholder_7[floormod(((blockIdx.x_7*1024) + threadIdx.x_7), 768)])
}

primfn(T_softmax_maxelem_3: Pointer(float32), T_softmax_exp_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_8, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_8, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = 0f32
    for (k_1: int32, 0, 128) {
      T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = ((float32*)T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)T_softmax_exp_2[(((blockIdx.x_8*131072) + (threadIdx.x_8*128)) + k_1)])
    }
  }
}

primfn(T_add_2: Pointer(float32), matmul_cublas_3: Pointer(float32), placeholder_8: Pointer(float32), placeholder_9: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_9, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_9, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_2[((blockIdx.x_9*1024) + threadIdx.x_9)] = (((float32*)matmul_cublas_3[((blockIdx.x_9*1024) + threadIdx.x_9)] + (float32*)placeholder_8[floormod(((blockIdx.x_9*1024) + threadIdx.x_9), 768)]) + (float32*)placeholder_9[((blockIdx.x_9*1024) + threadIdx.x_9)])
}

primfn(T_add_3: Pointer(float32), placeholder_10: Pointer(float32), placeholder_11: Pointer(int32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_10, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_3[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_10[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_11[(((floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + floordiv(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)), 12)*16384) + (floormod(((blockIdx.x_10*8) + floordiv(threadIdx.x_10, 128)), 128)*128)) + floormod(threadIdx.x_10, 128))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerIntrin
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
    T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.call_pure_extern("__expf", ((float32*)placeholder[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x*8)) + @tir.shift_right(threadIdx.x, 7, dtype=int32))]), dtype=float32)
  }
}

primfn(T_add: Pointer(float32), matmul_cublas: Pointer(float32), placeholder_1: Pointer(float32), placeholder_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_1_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_1[(((blockIdx.x_1*1024) + threadIdx.x_1) % 768)]) + (float32*)placeholder_2[((blockIdx.x_1*1024) + threadIdx.x_1)])
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_1: Pointer(float32), T_softmax_maxelem_1: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
    T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] = ((float32*)T_softmax_exp_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] / (float32*)T_softmax_maxelem_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_2*8)) + @tir.shift_right(threadIdx.x_2, 7, dtype=int32))])
  }
}

primfn(T_transpose: Pointer(float32), placeholder_3: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_transpose_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_3[(((((((ax0.ax1.fused.ax2.fused.outer*32) + @tir.shift_right(((blockIdx.x_3*8) + @tir.shift_right(threadIdx.x_3, 7, dtype=int32)), 6, dtype=int32)) / 12)*98304) + (@tir.bitwise_and(threadIdx.x_3, 127, dtype=int32)*768)) + ((((ax0.ax1.fused.ax2.fused.outer*32) + @tir.shift_right(((blockIdx.x_3*8) + @tir.shift_right(threadIdx.x_3, 7, dtype=int32)), 6, dtype=int32)) % 12)*64)) + @tir.bitwise_and(((blockIdx.x_3*8) + @tir.shift_right(threadIdx.x_3, 7, dtype=int32)), 63, dtype=int32))]
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_4: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_4, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_4, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
    for (k: int32, 0, 128) {
      T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_4[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
    }
  }
}

primfn(T_multiply: Pointer(float32), matmul_cublas_1: Pointer(float32), placeholder_5: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_5, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
  attr [IterVar(threadIdx.x_5, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_multiply[((blockIdx.x_5*1024) + threadIdx.x_5)] = (((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[(((blockIdx.x_5*1024) + threadIdx.x_5) % 3072)])*(0.5f32*(1f32 + @tir.call_pure_extern("tanhf", (0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[(((blockIdx.x_5*1024) + threadIdx.x_5) % 3072)]) + (0.044715f32*@tir.call_pure_extern("powf", ((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[(((blockIdx.x_5*1024) + threadIdx.x_5) % 3072)]), 3f32, dtype=float32)))), dtype=float32))))
}

primfn(T_reshape: Pointer(float32), placeholder_6: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_6, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_6, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_6*1024)) + threadIdx.x_6)] = (float32*)placeholder_6[(((((((ax0.ax1.fused.ax2.fused.outer_1*32) + @tir.shift_right(((blockIdx.x_6*16) + @tir.shift_right(threadIdx.x_6, 6, dtype=int32)), 7, dtype=int32)) / 12)*98304) + (@tir.bitwise_and(((blockIdx.x_6*16) + @tir.shift_right(threadIdx.x_6, 6, dtype=int32)), 127, dtype=int32)*768)) + ((((ax0.ax1.fused.ax2.fused.outer_1*32) + @tir.shift_right(((blockIdx.x_6*16) + @tir.shift_right(threadIdx.x_6, 6, dtype=int32)), 7, dtype=int32)) % 12)*64)) + @tir.bitwise_and(threadIdx.x_6, 63, dtype=int32))]
  }
}

primfn(T_add_1: Pointer(float32), matmul_cublas_2: Pointer(float32), placeholder_7: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_7, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_7, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_1[((blockIdx.x_7*1024) + threadIdx.x_7)] = ((float32*)matmul_cublas_2[((blockIdx.x_7*1024) + threadIdx.x_7)] + (float32*)placeholder_7[(((blockIdx.x_7*1024) + threadIdx.x_7) % 768)])
}

primfn(T_softmax_maxelem_3: Pointer(float32), T_softmax_exp_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_8, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_8, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = 0f32
    for (k_1: int32, 0, 128) {
      T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = ((float32*)T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)T_softmax_exp_2[(((blockIdx.x_8*131072) + (threadIdx.x_8*128)) + k_1)])
    }
  }
}

primfn(T_add_2: Pointer(float32), matmul_cublas_3: Pointer(float32), placeholder_8: Pointer(float32), placeholder_9: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_9, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_9, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_2[((blockIdx.x_9*1024) + threadIdx.x_9)] = (((float32*)matmul_cublas_3[((blockIdx.x_9*1024) + threadIdx.x_9)] + (float32*)placeholder_8[(((blockIdx.x_9*1024) + threadIdx.x_9) % 768)]) + (float32*)placeholder_9[((blockIdx.x_9*1024) + threadIdx.x_9)])
}

primfn(T_add_3: Pointer(float32), placeholder_10: Pointer(float32), placeholder_11: Pointer(int32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_10, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_3[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_10[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_11[((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + @tir.shift_right(((blockIdx.x_10*8) + @tir.shift_right(threadIdx.x_10, 7, dtype=int32)), 7, dtype=int32)) / 12)*16384) + (@tir.bitwise_and(((blockIdx.x_10*8) + @tir.shift_right(threadIdx.x_10, 7, dtype=int32)), 127, dtype=int32)*128)) + @tir.bitwise_and(threadIdx.x_10, 127, dtype=int32))]))*-10000f32))
  }
}


[11:43:31] /workspace/home/codes/tvm/src/ir/transform.cc:541: After pass tir.LowerDeviceStorageAccessInfo
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer: int32, 0, 12) {
    T_softmax_exp[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = @tir.call_pure_extern("__expf", ((float32*)placeholder[(((i0.i1.fused.i2.fused.i3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] - (float32*)T_softmax_maxelem[(((i0.i1.fused.i2.fused.i3.fused.outer*2048) + (blockIdx.x*8)) + @tir.shift_right(threadIdx.x, 7, dtype=int32))]), dtype=float32)
  }
}

primfn(T_add: Pointer(float32), matmul_cublas: Pointer(float32), placeholder_1: Pointer(float32), placeholder_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_1_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add[((blockIdx.x_1*1024) + threadIdx.x_1)] = (((float32*)matmul_cublas[((blockIdx.x_1*1024) + threadIdx.x_1)] + (float32*)placeholder_1[(((blockIdx.x_1*1024) + threadIdx.x_1) % 768)]) + (float32*)placeholder_2[((blockIdx.x_1*1024) + threadIdx.x_1)])
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_1: Pointer(float32), T_softmax_maxelem_1: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (i0.i1.fused.i2.fused.i3.fused.outer_1: int32, 0, 12) {
    T_softmax_norm[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] = ((float32*)T_softmax_exp_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*262144) + (blockIdx.x_2*1024)) + threadIdx.x_2)] / (float32*)T_softmax_maxelem_1[(((i0.i1.fused.i2.fused.i3.fused.outer_1*2048) + (blockIdx.x_2*8)) + @tir.shift_right(threadIdx.x_2, 7, dtype=int32))])
  }
}

primfn(T_transpose: Pointer(float32), placeholder_3: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_transpose_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer: int32, 0, 6) {
    T_transpose[(((ax0.ax1.fused.ax2.fused.outer*262144) + (blockIdx.x_3*1024)) + threadIdx.x_3)] = (float32*)placeholder_3[(((((((ax0.ax1.fused.ax2.fused.outer*32) + @tir.shift_right(((blockIdx.x_3*8) + @tir.shift_right(threadIdx.x_3, 7, dtype=int32)), 6, dtype=int32)) / 12)*98304) + (@tir.bitwise_and(threadIdx.x_3, 127, dtype=int32)*768)) + ((((ax0.ax1.fused.ax2.fused.outer*32) + @tir.shift_right(((blockIdx.x_3*8) + @tir.shift_right(threadIdx.x_3, 7, dtype=int32)), 6, dtype=int32)) % 12)*64)) + @tir.bitwise_and(((blockIdx.x_3*8) + @tir.shift_right(threadIdx.x_3, 7, dtype=int32)), 63, dtype=int32))]
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), placeholder_4: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_4: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_4: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_4, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_4, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = -3.40282e+38f32
    for (k: int32, 0, 128) {
      T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)] = max((float32*)T_softmax_maxelem_2[((blockIdx.x_4*1024) + threadIdx.x_4)], (float32*)placeholder_4[(((blockIdx.x_4*131072) + (threadIdx.x_4*128)) + k)])
    }
  }
}

primfn(T_multiply: Pointer(float32), matmul_cublas_1: Pointer(float32), placeholder_5: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_power_multiply_add_multiply_tanh_add_multiply_multipl_15213823851033404035__kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_5: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_5: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_5, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 6144;
  attr [IterVar(threadIdx.x_5, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_multiply[((blockIdx.x_5*1024) + threadIdx.x_5)] = (((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[(((blockIdx.x_5*1024) + threadIdx.x_5) % 3072)])*(0.5f32*(1f32 + @tir.call_pure_extern("tanhf", (0.797885f32*(((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[(((blockIdx.x_5*1024) + threadIdx.x_5) % 3072)]) + (0.044715f32*@tir.call_pure_extern("powf", ((float32*)matmul_cublas_1[((blockIdx.x_5*1024) + threadIdx.x_5)] + (float32*)placeholder_5[(((blockIdx.x_5*1024) + threadIdx.x_5) % 3072)]), 3f32, dtype=float32)))), dtype=float32))))
}

primfn(T_reshape: Pointer(float32), placeholder_6: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_transpose_reshape_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_6: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_6: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_6, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_6, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.outer_1: int32, 0, 6) {
    T_reshape[(((ax0.ax1.fused.ax2.fused.outer_1*262144) + (blockIdx.x_6*1024)) + threadIdx.x_6)] = (float32*)placeholder_6[(((((((ax0.ax1.fused.ax2.fused.outer_1*32) + @tir.shift_right(((blockIdx.x_6*16) + @tir.shift_right(threadIdx.x_6, 6, dtype=int32)), 7, dtype=int32)) / 12)*98304) + (@tir.bitwise_and(((blockIdx.x_6*16) + @tir.shift_right(threadIdx.x_6, 6, dtype=int32)), 127, dtype=int32)*768)) + ((((ax0.ax1.fused.ax2.fused.outer_1*32) + @tir.shift_right(((blockIdx.x_6*16) + @tir.shift_right(threadIdx.x_6, 6, dtype=int32)), 7, dtype=int32)) % 12)*64)) + @tir.bitwise_and(threadIdx.x_6, 63, dtype=int32))]
  }
}

primfn(T_add_1: Pointer(float32), matmul_cublas_2: Pointer(float32), placeholder_7: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_7: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_7: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_7, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_7, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_1[((blockIdx.x_7*1024) + threadIdx.x_7)] = ((float32*)matmul_cublas_2[((blockIdx.x_7*1024) + threadIdx.x_7)] + (float32*)placeholder_7[(((blockIdx.x_7*1024) + threadIdx.x_7) % 768)])
}

primfn(T_softmax_maxelem_3: Pointer(float32), T_softmax_exp_2: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_8: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_8: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_8, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 24;
  attr [IterVar(threadIdx.x_8, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024 {
    T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = 0f32
    for (k_1: int32, 0, 128) {
      T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] = ((float32*)T_softmax_maxelem_3[((blockIdx.x_8*1024) + threadIdx.x_8)] + (float32*)T_softmax_exp_2[(((blockIdx.x_8*131072) + (threadIdx.x_8*128)) + k_1)])
    }
  }
}

primfn(T_add_2: Pointer(float32), matmul_cublas_3: Pointer(float32), placeholder_8: Pointer(float32), placeholder_9: Pointer(float32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_dense_nn_bias_add_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_9: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_9: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_9, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 1536;
  attr [IterVar(threadIdx.x_9, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  T_add_2[((blockIdx.x_9*1024) + threadIdx.x_9)] = (((float32*)matmul_cublas_3[((blockIdx.x_9*1024) + threadIdx.x_9)] + (float32*)placeholder_8[(((blockIdx.x_9*1024) + threadIdx.x_9) % 768)]) + (float32*)placeholder_9[((blockIdx.x_9*1024) + threadIdx.x_9)])
}

primfn(T_add_3: Pointer(float32), placeholder_10: Pointer(float32), placeholder_11: Pointer(int32)) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_reshape_multiply_expand_dims_cast_subtract_multiply_add_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_10: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_10: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_10, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 256;
  attr [IterVar(threadIdx.x_10, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 1024;
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer: int32, 0, 12) {
    T_add_3[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)] = (((float32*)placeholder_10[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x_10*1024)) + threadIdx.x_10)]*0.125f32) + ((1f32 - cast(float32, (int32*)placeholder_11[((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*16) + @tir.shift_right(((blockIdx.x_10*8) + @tir.shift_right(threadIdx.x_10, 7, dtype=int32)), 7, dtype=int32)) / 12)*16384) + (@tir.bitwise_and(((blockIdx.x_10*8) + @tir.shift_right(threadIdx.x_10, 7, dtype=int32)), 127, dtype=int32)*128)) + @tir.bitwise_and(threadIdx.x_10, 127, dtype=int32))]))*-10000f32))
  }
}


[11:43:32] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1205: CODEGEN END

Running on (cuda -libs=cublas, cuda(0))
Time: 34.98745 ms
