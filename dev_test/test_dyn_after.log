[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass RemoveUnusedFunctions
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential RemoveUnusedFunctions
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass ToBasicBlockNormalForm
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential ToBasicBlockNormalForm
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass sequential
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential sequential
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Legalize
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass EtaExpand
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential EtaExpand
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x)
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass SimplifyInference
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential SimplifyInference
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass EliminateCommonSubexpr
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass SimplifyExpr
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential SimplifyExpr
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InlinePrimitives
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Inline
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Inline
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass DeadCodeElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential DeadCodeElimination
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InlinePrimitives
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass CombineParallelConv2d
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass CombineParallelDense
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass CombineParallelBatchMatmul
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FoldConstant
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FoldScaleAxis
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BackwardFoldScaleAxis
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass ForwardFoldScaleAxis
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FoldConstant
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FoldScaleAxis
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass CanonicalizeCast
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass CanonicalizeOps
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass AlterOpLayout
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FastMath
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FoldConstant
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FoldConstant
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FuseOps
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  nn.softmax(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FuseOps
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass ToANormalForm
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential ToANormalForm
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2 = %x1(%x);
  %x2
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InferType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InferType
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2: Tensor[(?, ?, ?, ?), float32] = %x1(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x2
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass LambdaLift
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential LambdaLift
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x2: Tensor[(?, ?, ?, ?), float32] = %x1(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x2
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InlinePrimitives
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Inline
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Inline
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: fn (Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] = %0;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %0(%x);
  %x2
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass DeadCodeElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential DeadCodeElimination
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InlinePrimitives
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InlineGlobals
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InlineGlobals
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass sequential
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass RemoveUnusedFunctions
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential RemoveUnusedFunctions
def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  let %x1: Tensor[(?, ?, ?, ?), float32] = %0(%x) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %x1
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass ManifestAlloc
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectPrefetch
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectPrefetch
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageFlatten
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageFlatten
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (i0: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (i0: int32 < 4)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (int64*)placeholder: Pointer(int64)[i0: int32]
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (int64*)placeholder: Pointer(int64)[i0: int32]
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify i0: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify i0: int32
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (i0: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (i0: int32 < 4)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (int64*)placeholder: Pointer(int64)[i0: int32]
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (int64*)placeholder: Pointer(int64)[i0: int32]
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify i0: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify i0: int32
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = add(32 /* ty=int64 */, 7 /* ty=int64 */) /* ty=int64 */;
  %4 = prod(%shape_func_out_0) /* ty=int64 */;
  %5 = divide(%3, 8 /* ty=int64 */) /* ty=int64 */;
  %6 = multiply(%4, %5) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%6, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %7 = (%x,);
  %8 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %7, %8) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FoldConstant
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FuseOps
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
type Storage {
  
}

def @main() -> int64 {
  add(32 /* ty=int64 */, 7 /* ty=int64 */) /* ty=int64 */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FuseOps
type Storage {
  
}

def @main() -> int64 {
  %0 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  %0(32 /* ty=int64 */, 7 /* ty=int64 */) /* ty=int64 */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass ToANormalForm
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential ToANormalForm
type Storage {
  
}

def @main() -> int64 {
  let %x = 32 /* ty=int64 */;
  let %x1 = 7 /* ty=int64 */;
  let %x2 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3 = %x2(%x, %x1);
  %x3
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InferType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass EtaExpand
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential EtaExpand
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1)
  };
  let %x3: int64 = %x2(%x, %x1);
  %x3
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InferType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 32 /* ty=int64 */;
  let %x1: int64 = 7 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    add(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectPrefetch
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  attr [T_add] "realize_scope" = "";
  realize(T_add, [], True {
    T_add[] = (placeholder[] + placeholder_1[])
  })
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageFlatten
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0] + (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0] + (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0] + (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0] + (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.HoistIfThenElse
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerReduction
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerReduction
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.PlanAndUpdateBufferAllocationLocation
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.PlanAndUpdateBufferAllocationLocation
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ConvertBlocksToOpaque
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ConvertBlocksToOpaque
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.CompactBufferAllocation
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.CompactBufferAllocation
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.FlattenBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.FlattenBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0] + (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0] + (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0] + (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0] + (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.HoistIfThenElse
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VerifyMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VerifyMemory
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Apply
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Apply
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InferFragment
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InferFragment
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerThreadAllreduce
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerThreadAllreduce
primfn(placeholder_2: handle, placeholder_3: handle, T_add_1: handle) -> ()
  attr = {"global_symbol": "fused_add", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {T_add: Buffer(T_add_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_add_1: T_add} {
  T_add_2[0] = ((int64*)placeholder_4[0] + (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.MakePackedAPI
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg2: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg2: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg2: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg2: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (dev_id: int32 == @tir.tvm_struct_get(arg2: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (dev_id: int32 == @tir.tvm_struct_get(arg2: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.SplitHostDevice
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerWarpMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerWarpMemory

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Apply
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Apply
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerTVMBuiltin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 3)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg2.code: int32 == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg2: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg2: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg2: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg2: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg2: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg2: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.CombineContextCall
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_add", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_add: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_add: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_add] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_add: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_add: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_add: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_add_compute_";
  T_add[0] = ((int64*)placeholder[0] + (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 3)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg2.code: int32 == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg2: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg2: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg2: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg2: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg2: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg2: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FuseOps
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
type Storage {
  
}

def @main() -> int64 {
  divide(39 /* ty=int64 */, 8 /* ty=int64 */) /* ty=int64 */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FuseOps
type Storage {
  
}

def @main() -> int64 {
  %0 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  %0(39 /* ty=int64 */, 8 /* ty=int64 */) /* ty=int64 */
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass ToANormalForm
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential ToANormalForm
type Storage {
  
}

def @main() -> int64 {
  let %x = 39 /* ty=int64 */;
  let %x1 = 8 /* ty=int64 */;
  let %x2 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3 = %x2(%x, %x1);
  %x3
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InferType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass EtaExpand
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential EtaExpand
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1)
  };
  let %x3: int64 = %x2(%x, %x1);
  %x3
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InferType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InferType
type Storage {
  
}

def @main() -> int64 {
  let %x: int64 = 39 /* ty=int64 */;
  let %x1: int64 = 8 /* ty=int64 */;
  let %x2: fn (int64, int64) -> int64 = fn (%p0: int64, %p1: int64, Primitive=1) -> int64 {
    divide(%p0, %p1) /* ty=int64 */
  };
  let %x3: int64 = %x2(%x, %x1) /* ty=int64 */;
  %x3
}

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectPrefetch
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectPrefetch
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  attr [T_divide] "realize_scope" = "";
  realize(T_divide, [], True {
    T_divide[] = (placeholder[] / placeholder_1[])
  })
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageFlatten
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageFlatten
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0] / (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0] / (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0] / (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0] / (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.HoistIfThenElse
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerReduction
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerReduction
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.PlanAndUpdateBufferAllocationLocation
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.PlanAndUpdateBufferAllocationLocation
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ConvertBlocksToOpaque
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ConvertBlocksToOpaque
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.CompactBufferAllocation
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.CompactBufferAllocation
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.FlattenBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.FlattenBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0] / (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0] / (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0] / (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0] / (int64*)placeholder_1: Pointer(int64)[0])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.HoistIfThenElse
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.HoistIfThenElse
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VerifyMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VerifyMemory
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Apply
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Apply
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InferFragment
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InferFragment
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerThreadAllreduce
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerThreadAllreduce
primfn(placeholder_2: handle, placeholder_3: handle, T_divide_1: handle) -> ()
  attr = {"global_symbol": "fused_divide", "tir.noalias": True, "target": meta[Target][0], "tir.is_entry_func": True}
  buffers = {placeholder: Buffer(placeholder_4: Pointer(int64), int64, [], []),
             T_divide: Buffer(T_divide_2: Pointer(int64), int64, [], []),
             placeholder_1: Buffer(placeholder_5: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_2: placeholder, placeholder_3: placeholder_1, T_divide_1: T_divide} {
  T_divide_2[0] = ((int64*)placeholder_4[0] / (int64*)placeholder_5[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.MakePackedAPI
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg2: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg2: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg2: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg2: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (dev_id: int32 == @tir.tvm_struct_get(arg2: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (dev_id: int32 == @tir.tvm_struct_get(arg2: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.SplitHostDevice
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerWarpMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerWarpMemory

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Apply
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Apply
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerTVMBuiltin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 3)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg2.code: int32 == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg2: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg2: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg2: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg2: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg2: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg2: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.CombineContextCall
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_divide", "tir.is_entry_func": True, "calling_conv": 1} {
  assert((num_args == 3), "fused_divide: num_args should be 3")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let arg2: handle = @tir.tvm_struct_get(args, 2, 12, dtype=handle)
  let arg2.code: int32 = (int32*)arg_type_ids[2]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_1: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let T_divide: Pointer(int64) = @tir.tvm_struct_get(arg2, 0, 1, dtype=handle)
  attr [T_divide] "storage_alignment" = 128;
  let arg2.shape: handle = @tir.tvm_struct_get(arg2, 0, 2, dtype=handle)
  let arg2.strides: handle = @tir.tvm_struct_get(arg2, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_divide: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_divide: Expect arg[1] to be pointer")
  assert(((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), "fused_divide: Expect arg[2] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg2, 0, 4, dtype=int32)), "arg2.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg2, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16)), "arg2.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg2, 0, 8, dtype=uint64)), "Argument arg2.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg2, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg2, 0, 10, dtype=int32)), "Argument arg2.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg2, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg2, 0, 9, dtype=int32)), "Argument arg2.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg2, 0, 9))")
  attr [0] "compute_scope" = "fused_divide_compute_";
  T_divide[0] = ((int64*)placeholder[0] / (int64*)placeholder_1[0])
}


[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 3)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg2.code: int32 == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg2: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg2: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg2: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg2, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg2, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg2: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg2: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg2: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = prod(%shape_func_out_0) /* ty=int64 */;
  %4 = multiply(%3, 4 /* ty=int64 */) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%4, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %5 = (%x,);
  %6 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %5, %6) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FuseOps
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = prod(%shape_func_out_0) /* ty=int64 */;
  %4 = multiply(%3, 4 /* ty=int64 */) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%4, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %5 = (%x,);
  %6 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %5, %6) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  %3 = fn (%p02: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p02) /* ty=int64 */
  };
  %4 = %3(%shape_func_out_0) /* ty=int64 */;
  %5 = fn (%p01: int64, Primitive=1) -> int64 {
    multiply(%p01, 4 /* ty=int64 */) /* ty=int64 */
  };
  %6 = %5(%4) /* ty=int64 */;
  let %storage_01: Storage[] = memory.alloc_storage(%6, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %7 = (%x,);
  %8 = (%out_0,);
  let %x1: () = vm.invoke_tvm_op(%0, %7, %8) /* ty=() */;
  let %x2: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x2
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass ManifestAlloc
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FuseOps
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FoldConstant
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FuseOps
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:468: InferType;
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:470: After this dependency pass
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FuseOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass ManifestAlloc
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential ManifestAlloc
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass FoldConstant
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential FoldConstant
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential sequential
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass InferType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential InferType
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32]) -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1) -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass LabelOps
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential LabelOps
type Storage {
  
}

def @main(%x: Tensor[(?, ?, ?, ?), float32], hash="145913305f625cf1") -> Tensor[(?, ?, ?, ?), float32] {
  let %in_shape_0: Tensor[(4), int64] = vm.shape_of(%x, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %storage_0: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(4), int64] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0: Tensor[(4), int64] = %tensor_0;
  %0 = fn (%p0: Tensor[(?, ?, ?, ?), float32], Primitive=1, hash="e2782cdc77404249") -> Tensor[(?, ?, ?, ?), float32] {
    nn.softmax(%p0) /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1 = (%in_shape_0,);
  %2 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%0, %1, %2, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_01: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: int64 = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][1] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=int64 */;
  %3 = fn (%p01: Tensor[(4), int64], Primitive=1, hash="75ec56f3169a1497") -> int64 {
    prod(%p01) /* ty=int64 */
  };
  %4 = (%shape_func_out_0,);
  %5 = (%tensor_01,);
  let %x1: () = vm.invoke_tvm_op(%3, %4, %5) /* ty=() */;
  let %storage_02: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: int64 = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][2] /* ty=Tensor[(0), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=int64 */;
  %6 = fn (%p02: int64, Primitive=1, hash="e2e2680f0ff08f46") -> int64 {
    multiply(%p02, 4 /* ty=int64 */) /* ty=int64 */
  };
  %7 = (%tensor_01,);
  %8 = (%tensor_02,);
  let %x2: () = vm.invoke_tvm_op(%6, %7, %8) /* ty=() */;
  let %storage_03: Storage[] = memory.alloc_storage(%tensor_02, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %9 = (%x,);
  %10 = (%out_0,);
  let %x3: () = vm.invoke_tvm_op(%0, %9, %10) /* ty=() */;
  let %x4: Tensor[(?, ?, ?, ?), float32] = %out_0;
  %x4
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectPrefetch
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectPrefetch
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  attr [compute] "realize_scope" = "";
  realize(compute, [0:4], True {
    for (i0: int32, 0, 4) {
      compute[i0] = placeholder[i0]
    }
  })
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageFlatten
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageFlatten
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (i0: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (i0: int32 < 4)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (int64*)placeholder: Pointer(int64)[i0: int32]
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (int64*)placeholder: Pointer(int64)[i0: int32]
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify i0: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify i0: int32
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (i0: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (i0: int32 < 4)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (int64*)placeholder: Pointer(int64)[i0: int32]
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (int64*)placeholder: Pointer(int64)[i0: int32]
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify i0: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify i0: int32
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectPrefetch
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectPrefetch
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  attr [placeholder_red] "realize_scope" = "";
  realize(placeholder_red, [], True {
    placeholder_red[] = 1i64
    for (k0: int32, 0, 4) {
      placeholder_red[] = (placeholder_red[]*placeholder[k0])
    }
  })
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageFlatten
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageFlatten
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k0: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k0: int32 < 4)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder_red: Pointer(int64)[0]*(int64*)placeholder: Pointer(int64)[k0: int32])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder_red: Pointer(int64)[0]*(int64*)placeholder: Pointer(int64)[k0: int32])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k0: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k0: int32 < 4)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder_red: Pointer(int64)[0]*(int64*)placeholder: Pointer(int64)[k0: int32])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder_red: Pointer(int64)[0]*(int64*)placeholder: Pointer(int64)[k0: int32])
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.HoistIfThenElse
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.HoistIfThenElse
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectPrefetch
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectPrefetch
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  attr [T_multiply] "realize_scope" = "";
  realize(T_multiply, [], True {
    T_multiply[] = (placeholder[]*4i64)
  })
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageFlatten
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageFlatten
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0]*4i64)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0]*4i64)
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((int64*)placeholder: Pointer(int64)[0]*4i64)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((int64*)placeholder: Pointer(int64)[0]*4i64)
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.HoistIfThenElse
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.HoistIfThenElse
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32 + -1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32 - 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32 + -1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32 - 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32 + -1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32 - 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32 + -1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32 - 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectPrefetch
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectPrefetch
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Buffer(T_softmax_maxelem_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2], [])] "realize_scope" = "";
  realize(T_softmax_maxelem, [0:any_dim, 0:any_dim_1, 0:any_dim_2], True {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod((threadIdx.x + (blockIdx.x*512)), any_dim_2)] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod((threadIdx.x + (blockIdx.x*512)), any_dim_2)] = max(T_softmax_maxelem[floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod((threadIdx.x + (blockIdx.x*512)), any_dim_2)], placeholder[floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1), floormod((threadIdx.x + (blockIdx.x*512)), any_dim_2), k])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Buffer(T_softmax_exp_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [])] "realize_scope" = "";
    realize(T_softmax_exp, [0:any_dim, 0:any_dim_1, 0:any_dim_2, 0:any_dim_3], True {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            if @tir.likely(((threadIdx.x_1 + (blockIdx.x_1*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
              T_softmax_exp[floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), floormod((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3)] = @tir.exp((placeholder[floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), floormod((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3)] - T_softmax_maxelem[floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2)]), dtype=float32)
            }
          }
        }
      }
      attr [T_softmax_expsum: Buffer(T_softmax_expsum_1: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2], [])] "realize_scope" = "";
      realize(T_softmax_expsum, [0:any_dim, 0:any_dim_1, 0:any_dim_2], True {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
              if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2)] = 0f32
              }
            }
          }
          for (k_1: int32, 0, any_dim_3) {
            if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
              if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
                if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                  T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2)] = (T_softmax_expsum[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2)] + T_softmax_exp[floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1), floormod((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), k_1])
                }
              }
            }
          }
        }
        attr [T_softmax_norm] "realize_scope" = "";
        realize(T_softmax_norm, [0:any_dim, 0:any_dim_1, 0:any_dim_2, 0:any_dim_3], True {
          attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
          attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
          if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
            if @tir.likely((floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
              if @tir.likely((floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                if @tir.likely(((threadIdx.x_3 + (blockIdx.x_3*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
                  T_softmax_norm[floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), floormod((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3)] = (T_softmax_exp[floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), floormod((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3)] / T_softmax_expsum[floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1), floormod(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2)])
                }
              }
            }
          }
        })
      })
    })
  })
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageFlatten
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32)*stride: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*stride: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1)*stride_1: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod((threadIdx.x + (blockIdx.x*512)), any_dim)*stride_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (floordiv(floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1), any_dim_2)*stride_1: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1)*stride_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod((threadIdx.x + (blockIdx.x*512)), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*any_dim_2) + floormod(floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1), any_dim_2))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*any_dim_2) + floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*any_dim_2) + floormod(floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1), any_dim_2))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*any_dim_2) + floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((threadIdx.x: int32 + (blockIdx.x: int32*512))*any_dim: int32) + k: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((blockIdx.x: int32*512) + threadIdx.x: int32)*any_dim: int32) + k: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*any_dim_2) + floormod(floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1), any_dim_2))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*any_dim_2) + floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod((threadIdx.x + (blockIdx.x*512)), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32)*any_dim) + floormod(((blockIdx.x*512) + threadIdx.x), any_dim))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*any_dim_2) + floormod(floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1), any_dim_2))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*any_dim_2) + floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32)*any_dim_1) + floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (floordiv(floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1), any_dim_2)*stride_1: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim), any_dim_1)*stride_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod((threadIdx.x + (blockIdx.x*512)), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageFlatten
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            if @tir.likely(((threadIdx.x_1 + (blockIdx.x_1*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
              T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
              if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
              }
            }
          }
          for (k_1: int32, 0, any_dim_3) {
            if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
              if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
                if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                  T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              if @tir.likely(((threadIdx.x_3 + (blockIdx.x_3*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
                T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Legalize
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16Promote
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Promote
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            if @tir.likely(((threadIdx.x_1 + (blockIdx.x_1*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
              T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
              if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
              }
            }
          }
          for (k_1: int32, 0, any_dim_3) {
            if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
              if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
                if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                  T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              if @tir.likely(((threadIdx.x_3 + (blockIdx.x_3*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
                T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16CastElimination
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16CastElimination
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            if @tir.likely(((threadIdx.x_1 + (blockIdx.x_1*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
              T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
              if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
              }
            }
          }
          for (k_1: int32, 0, any_dim_3) {
            if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
              if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
                if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                  T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              if @tir.likely(((threadIdx.x_3 + (blockIdx.x_3*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
                T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.BF16TypeLowering
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16TypeLowering
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            if @tir.likely(((threadIdx.x_1 + (blockIdx.x_1*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
              T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
              if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
              }
            }
          }
          for (k_1: int32, 0, any_dim_3) {
            if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
              if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
                if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                  T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              if @tir.likely(((threadIdx.x_3 + (blockIdx.x_3*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
                T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.BF16Legalize
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            if @tir.likely(((threadIdx.x_1 + (blockIdx.x_1*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
              T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
              if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
              }
            }
          }
          for (k_1: int32, 0, any_dim_3) {
            if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
              if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
                if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                  T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              if @tir.likely(((threadIdx.x_3 + (blockIdx.x_3*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
                T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.NarrowDataType
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.NarrowDataType
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if @tir.likely((floordiv(floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x + (blockIdx.x*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely(((threadIdx.x + (blockIdx.x*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))] = max((float32*)T_softmax_maxelem[(threadIdx.x + (blockIdx.x*512))], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
        if @tir.likely((floordiv(floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
          if @tir.likely((floordiv((threadIdx.x_1 + (blockIdx.x_1*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            if @tir.likely(((threadIdx.x_1 + (blockIdx.x_1*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
              T_softmax_exp[(threadIdx.x_1 + (blockIdx.x_1*512))] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
              if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = 0f32
              }
            }
          }
          for (k_1: int32, 0, any_dim_3) {
            if @tir.likely((floordiv(floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
              if @tir.likely((floordiv((threadIdx.x_2 + (blockIdx.x_2*512)), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
                if @tir.likely(((threadIdx.x_2 + (blockIdx.x_2*512)) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                  T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] = ((float32*)T_softmax_expsum[(threadIdx.x_2 + (blockIdx.x_2*512))] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if @tir.likely((floordiv(floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2), any_dim_1) < any_dim), dtype=bool) {
          if @tir.likely((floordiv(floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3), any_dim_2) < (any_dim*any_dim_1)), dtype=bool) {
            if @tir.likely((floordiv((threadIdx.x_3 + (blockIdx.x_3*512)), any_dim_3) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              if @tir.likely(((threadIdx.x_3 + (blockIdx.x_3*512)) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
                T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[(threadIdx.x_3 + (blockIdx.x_3*512))] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32) < any_dim_2: int32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32) < (any_dim_1: int32*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (threadIdx.x: int32 + (blockIdx.x: int32*512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32) < any_dim_2: int32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32) < (any_dim_1: int32*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify max((float32*)T_softmax_maxelem: Pointer(float32)[(threadIdx.x: int32 + (blockIdx.x: int32*512))], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (threadIdx.x: int32 + (blockIdx.x: int32*512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv(floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32), any_dim_2: int32) < any_dim_3: int32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely((floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32) < (any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32) < (any_dim_2: int32*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32) < ((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (threadIdx.x: int32 + (blockIdx.x: int32*512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32) < any_dim_2: int32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32) < (any_dim_1: int32*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (threadIdx.x: int32 + (blockIdx.x: int32*512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32) < any_dim_2: int32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32) < (any_dim_1: int32*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_expsum: Pointer(float32)[(threadIdx.x: int32 + (blockIdx.x: int32*512))] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_expsum: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (threadIdx.x: int32 + (blockIdx.x: int32*512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv(floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32), any_dim_2: int32) < any_dim_3: int32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely((floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32) < (any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv(floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32), any_dim_1: int32) < (any_dim_2: int32*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32)))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely((floordiv((threadIdx.x: int32 + (blockIdx.x: int32*512)), any_dim: int32) < ((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32))), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.likely(((threadIdx.x: int32 + (blockIdx.x: int32*512)) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.likely((((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_exp: Pointer(float32)[(threadIdx.x: int32 + (blockIdx.x: int32*512))] / (float32*)T_softmax_expsum: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_expsum: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
      if @tir.likely((((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))), dtype=bool) {
        if @tir.likely((((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))), dtype=bool) {
          if @tir.likely((((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if @tir.likely((((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))), dtype=bool) {
          if @tir.likely((((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))), dtype=bool) {
            if @tir.likely((((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if @tir.likely((((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), dtype=bool) {
        if @tir.likely((((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), dtype=bool) {
          if @tir.likely((((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), dtype=bool) {
            if @tir.likely((((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512 {
          if @tir.likely((((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))), dtype=bool) {
            if @tir.likely((((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))), dtype=bool) {
              if @tir.likely((((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_1: int32, 0, any_dim_3) {
            if @tir.likely((((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))), dtype=bool) {
              if @tir.likely((((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))), dtype=bool) {
                if @tir.likely((((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)), dtype=bool) {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_1)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if @tir.likely((((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), dtype=bool) {
          if @tir.likely((((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), dtype=bool) {
            if @tir.likely((((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), dtype=bool) {
              if @tir.likely((((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)), dtype=bool) {
                T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LoopPartition
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (floordiv(min(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), 512) + -1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (floordiv(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512) - 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify neg_inf: handle
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify neg_inf: handle
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512)
[16:18:29] /workspace/home/codes/tvm/src/tir/transforms/loop_partition.cc:554: Warning: Cannot prove: ((((floordiv(((({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}) + 511), 512) - 1) - floordiv(min(min(min((({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}), ({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0}))), ({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0}))), (({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0})), 512)) + 1) >= 0), when generating the post doubt loop
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512) + -1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512) - 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify neg_inf: handle
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify neg_inf: handle
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512)
[16:18:29] /workspace/home/codes/tvm/src/tir/transforms/loop_partition.cc:554: Warning: Cannot prove: ((((floordiv((((({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}) + 511), 512) - 1) - floordiv(min(min(min(((({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}), ({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0})))), ({any_dim|any_dim>=0}*(({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}))), ({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0})))), 512)) + 1) >= 0), when generating the post doubt loop
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (floordiv(min(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), ((any_dim_1*any_dim_2)*any_dim)), 512) + -1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (floordiv(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), 512) - 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify neg_inf: handle
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify neg_inf: handle
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), 512)
[16:18:29] /workspace/home/codes/tvm/src/tir/transforms/loop_partition.cc:554: Warning: Cannot prove: ((((floordiv(((({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}) + 511), 512) - 1) - floordiv(min(min(min(({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0})), ({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0}))), (({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0})), ({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0}))), 512)) + 1) >= 0), when generating the post doubt loop
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512) + -1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512) - 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify neg_inf: handle
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify neg_inf: handle
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512)
[16:18:29] /workspace/home/codes/tvm/src/tir/transforms/loop_partition.cc:554: Warning: Cannot prove: ((((floordiv((((({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}) + 511), 512) - 1) - floordiv(min(min(min(((({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}), ({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0})))), ({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*({any_dim|any_dim>=0}*{any_dim|any_dim>=0})))), ({any_dim|any_dim>=0}*(({any_dim|any_dim>=0}*{any_dim|any_dim>=0})*{any_dim|any_dim>=0}))), 512)) + 1) >= 0), when generating the post doubt loop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LoopPartition
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < min(floordiv(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
      if True {
        if True {
          if True {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if True {
          if True {
            if True {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_1 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
        if True {
          if True {
            if True {
              if True {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      } else {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_2 < min(floordiv(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_2: int32, 0, any_dim_3) {
            if True {
              if True {
                if True {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_3: int32, 0, any_dim_3) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
                if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_3 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                if True {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
              if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
                if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VectorizeLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VectorizeLoop
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < min(floordiv(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
      if True {
        if True {
          if True {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if True {
          if True {
            if True {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_1 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
        if True {
          if True {
            if True {
              if True {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      } else {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_2 < min(floordiv(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_2: int32, 0, any_dim_3) {
            if True {
              if True {
                if True {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_3: int32, 0, any_dim_3) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
                if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_3 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                if True {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
              if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
                if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectVirtualThread
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectVirtualThread
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < min(floordiv(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
      if True {
        if True {
          if True {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if True {
          if True {
            if True {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_1 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
        if True {
          if True {
            if True {
              if True {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      } else {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_2 < min(floordiv(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_2: int32, 0, any_dim_3) {
            if True {
              if True {
                if True {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_3: int32, 0, any_dim_3) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
                if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_3 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                if True {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
              if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
                if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InjectDoubleBuffer
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InjectDoubleBuffer
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [any_dim, any_dim_1, any_dim_2]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < min(floordiv(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
      if True {
        if True {
          if True {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if True {
          if True {
            if True {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [any_dim, any_dim_1, any_dim_2, any_dim_3]) {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_1 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
        if True {
          if True {
            if True {
              if True {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      } else {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      }
      attr [T_softmax_expsum: Pointer(float32)] "storage_scope" = "global";
      allocate(T_softmax_expsum, float32, [any_dim, any_dim_1, any_dim_2]) {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_2 < min(floordiv(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_2: int32, 0, any_dim_3) {
            if True {
              if True {
                if True {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_3: int32, 0, any_dim_3) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
                if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                  T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_expsum[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_3 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                if True {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
              if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
                if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_expsum[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.StorageRewrite
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.StorageRewrite
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < min(floordiv(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
      if True {
        if True {
          if True {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if True {
          if True {
            if True {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_1 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
        if True {
          if True {
            if True {
              if True {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      } else {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      }
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_2 < min(floordiv(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_2: int32, 0, any_dim_3) {
            if True {
              if True {
                if True {
                  T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_3: int32, 0, any_dim_3) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
                if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                  T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_3 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                if True {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
              if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
                if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.UnrollLoop
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.UnrollLoop
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < min(floordiv(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
      if True {
        if True {
          if True {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k: int32, 0, any_dim_3) {
        if True {
          if True {
            if True {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
            }
          }
        }
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_1 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
        if True {
          if True {
            if True {
              if True {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      } else {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      }
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_2 < min(floordiv(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_2: int32, 0, any_dim_3) {
            if True {
              if True {
                if True {
                  T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_3: int32, 0, any_dim_3) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
                if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                  T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_3 < min(floordiv(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1))) {
          if True {
            if True {
              if True {
                if True {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        } else {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
              if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
                if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify "global"
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < min(floordiv(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), 512), ((floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512) - 1) + 1)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < min(floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < min(floordiv(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), 512), ((floordiv((((any_dim_1*any_dim_2)*any_dim) + 511), 512) - 1) + 1)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < min(floordiv(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), 512), ((floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512) - 1) + 1)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition True
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify conditionTrue
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint True
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
     {
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
        T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      } else {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      }
       {
        attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
        attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
          T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          for (k_2: int32, 0, any_dim_3) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
          }
        } else {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
              }
            }
          }
          for (k_3: int32, 0, any_dim_3) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
                if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                  T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
                }
              }
            }
          }
        }
        attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
        attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
        if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
          T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
        } else {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
              if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
                if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                  T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
                }
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RemoveNoOp
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RemoveNoOp
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.RewriteUnsafeSelect
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.RewriteUnsafeSelect
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.HoistIfThenElse
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.HoistIfThenElse
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1151: CODEGEN!
[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1162: Lower cached function shape_func_nn_softmax_1 in target llvm -keys=cpu -link-params=0
[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1162: Lower cached function fused_prod in target llvm -keys=cpu -link-params=0
[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1162: Lower cached function fused_multiply in target llvm -keys=cpu -link-params=0
[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1162: Lower cached function fused_nn_softmax in target cuda -keys=cuda,gpu -max_num_threads=1024 -thread_warp_size=32
[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1184: FUNCS MAP
[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1186: Target: llvm -keys=cpu -link-params=0, primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1186: Target: llvm -keys=cpu -link-params=0, primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1186: Target: llvm -keys=cpu -link-params=0, primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/relay/backend/vm/compiler.cc:1186: Target: cuda -keys=cuda,gpu -max_num_threads=1024 -thread_warp_size=32, primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VerifyMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VerifyMemory
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InferFragment
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InferFragment
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerThreadAllreduce
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerThreadAllreduce
primfn(placeholder_1: handle, compute_1: handle) -> ()
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {compute: Buffer(compute_2: Pointer(int64), int64, [4], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, compute_1: compute} {
  for (i0: int32, 0, 4) {
    compute_2[i0] = (int64*)placeholder_2[i0]
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.MakePackedAPI
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (4 == cast(int32, (int64*)arg0.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (4 == cast(int32, (int64*)arg0.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (4 == cast(int32, (int64*)arg1.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (4 == cast(int32, (int64*)arg1.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"global_symbol": "shape_func_nn_softmax_1", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.SplitHostDevice
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerTVMBuiltin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 2)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == cast(int32, (int64*)arg0.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition!@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == cast(int32, (int64*)arg0.strides: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == cast(int32, (int64*)arg1.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = !@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = !@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition !@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition!@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == cast(int32, (int64*)arg1.strides: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.CombineContextCall
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "shape_func_nn_softmax_1", "calling_conv": 1} {
  assert((num_args == 2), "shape_func_nn_softmax_1: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let compute: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [compute] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "shape_func_nn_softmax_1: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "shape_func_nn_softmax_1: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 1")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((4 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: (4 == int32(arg1.shape[0]))")
     {
      if !@tir.isnullptr(arg1.strides, dtype=bool) {
        assert((1 == cast(int32, (int64*)arg1.strides[0])), "arg1.strides: expected to be compact array")
        0
      }
      assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
      assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
      assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
      attr [0] "compute_scope" = "shape_func_nn_softmax_1_compute_";
      for (i0: int32, 0, 4) {
        compute[i0] = (int64*)placeholder[i0]
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerWarpMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerWarpMemory

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VerifyMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VerifyMemory
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InferFragment
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InferFragment
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerThreadAllreduce
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerThreadAllreduce
primfn(placeholder_1: handle, placeholder_red_1: handle) -> ()
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {placeholder_red: Buffer(placeholder_red_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [4], [])}
  buffer_map = {placeholder_1: placeholder, placeholder_red_1: placeholder_red} {
  placeholder_red_2[0] = 1i64
  for (k0: int32, 0, 4) {
    placeholder_red_2[0] = ((int64*)placeholder_red_2[0]*(int64*)placeholder_2[k0])
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.MakePackedAPI
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (4 == cast(int32, (int64*)arg0.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (4 == cast(int32, (int64*)arg0.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"global_symbol": "fused_prod", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.SplitHostDevice
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerTVMBuiltin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 2)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == cast(int32, (int64*)arg0.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition!@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == cast(int32, (int64*)arg0.strides: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.CombineContextCall
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_prod", "calling_conv": 1} {
  assert((num_args == 2), "fused_prod: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let placeholder_red: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [placeholder_red] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_prod: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_prod: Expect arg[1] to be pointer")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 1")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((4 == cast(int32, (int64*)arg0.shape[0])), "Argument arg0.shape[0] has an unsatisfied constraint: (4 == int32(arg0.shape[0]))")
   {
    if !@tir.isnullptr(arg0.strides, dtype=bool) {
      assert((1 == cast(int32, (int64*)arg0.strides[0])), "arg0.strides: expected to be compact array")
      0
    }
    assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
    assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
    assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
    assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
    assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
    attr [0] "compute_scope" = "fused_prod_compute_" {
      placeholder_red[0] = 1i64
      for (k0: int32, 0, 4) {
        placeholder_red[0] = ((int64*)placeholder_red[0]*(int64*)placeholder[k0])
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerWarpMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerWarpMemory

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VerifyMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VerifyMemory
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InferFragment
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InferFragment
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerThreadAllreduce
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerThreadAllreduce
primfn(placeholder_1: handle, T_multiply_1: handle) -> ()
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_multiply: Buffer(T_multiply_2: Pointer(int64), int64, [], []),
             placeholder: Buffer(placeholder_2: Pointer(int64), int64, [], [])}
  buffer_map = {placeholder_1: placeholder, T_multiply_1: T_multiply} {
  T_multiply_2[0] = ((int64*)placeholder_2[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.MakePackedAPI
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"global_symbol": "fused_multiply", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.SplitHostDevice
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.SplitHostDevice
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 1;
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerTVMBuiltin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 2)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.CombineContextCall
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_multiply", "calling_conv": 1} {
  assert((num_args == 2), "fused_multiply: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(int64) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_multiply: Pointer(int64) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_multiply] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_multiply: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_multiply: Expect arg[1] to be pointer")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((0 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 0")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be int64")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((1 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (1 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
  attr [0] "compute_scope" = "fused_multiply_compute_";
  T_multiply[0] = ((int64*)placeholder[0]*4i64)
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerWarpMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerWarpMemory

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo

[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.VerifyMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.VerifyMemory
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.ThreadSync
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.ThreadSync
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.InferFragment
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.InferFragment
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerThreadAllreduce
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerThreadAllreduce
primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0]}
  buffers = {T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32], [stride: int32, stride_1: int32, stride_2: int32, stride_3: int32], type="auto"),
             placeholder: Buffer(placeholder_2: Pointer(float32), float32, [any_dim, any_dim_1, any_dim_2, any_dim_3], [stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32], type="auto")}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm} {
  attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
  attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
  allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
    attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
      for (k: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k*stride_7))])
      }
    } else {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
          }
        }
      }
      for (k_1: int32, 0, any_dim_3) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder_2[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_5)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_6)) + (k_1*stride_7))])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
    } else {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder_2[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_4) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_5)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_6)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride_7))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
    attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
      T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
      for (k_2: int32, 0, any_dim_3) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
      }
    } else {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
            T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
          }
        }
      }
      for (k_3: int32, 0, any_dim_3) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
            }
          }
        }
      }
    }
    attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
    attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
    if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
      T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
    } else {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
              T_softmax_norm_2[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_3))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.MakePackedAPI
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (2 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (2 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[1]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[1]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[2]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[2]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[3]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[3]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (any_dim: int32*any_dim_1: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (2 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (2 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.MakePackedAPI
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"global_symbol": "fused_nn_softmax", "tir.noalias": True, "target": meta[Target][0], "calling_conv": 1} {
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
    @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
      attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x < floordiv(min(min(min(min(((any_dim*any_dim_1)*any_dim_2), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
        T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
        for (k: int32, 0, any_dim_3) {
          T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_3) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_1)) + (k*stride))])
        }
      } else {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = -3.40282e+38f32
            }
          }
        }
        for (k_1: int32, 0, any_dim_3) {
          if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x*512) + threadIdx.x) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x*512) + threadIdx.x) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)] = max((float32*)T_softmax_maxelem[((blockIdx.x*512) + threadIdx.x)], (float32*)placeholder[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_3) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_2), any_dim_1)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_2)*stride_1)) + (k_1*stride))])
              }
            }
          }
        }
      }
      attr [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_1 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
        T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_3) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_2)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_1)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
      } else {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_1*512) + threadIdx.x_1) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_exp[((blockIdx.x_1*512) + threadIdx.x_1)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_3) + (floormod(floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2), any_dim_1)*stride_2)) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3), any_dim_2)*stride_1)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)*stride))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_3)]), dtype=float32)
              }
            }
          }
        }
      }
      attr [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512);
      attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_2*(any_dim*any_dim_1)), (any_dim_2*(any_dim_1*any_dim))), ((any_dim*any_dim_1)*any_dim_2)), (any_dim_2*(any_dim*any_dim_1))), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512)) {
        T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        for (k_2: int32, 0, any_dim_3) {
          T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_2)])
        }
      } else {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
              T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
            }
          }
        }
        for (k_3: int32, 0, any_dim_3) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim_1*any_dim))) {
            if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_2*(any_dim*any_dim_1))) {
              if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim*any_dim_1)*any_dim_2)) {
                T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_3) + k_3)])
              }
            }
          }
        }
      }
      attr [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
      attr [IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
      if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
        T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_6)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_5)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_4))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
      } else {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
            if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
              if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
                T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_7) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2), any_dim_1)*stride_6)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3), any_dim_2)*stride_5)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)*stride_4))] = ((float32*)T_softmax_exp[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_3)])
              }
            }
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.SplitHostDevice
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.SplitHostDevice
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32), any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
    T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
  } else {
    if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
          if (((blockIdx.x*512) + threadIdx.x) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
            T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder_1: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, any_dim_7: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_4*any_dim_5)*any_dim_6) + 511), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_1 < floordiv(min(min(min(min(((any_dim_4*any_dim_5)*any_dim_6), (any_dim_6*(any_dim_5*any_dim_4))), (any_dim_6*(any_dim_4*any_dim_5))), ((any_dim_4*any_dim_5)*any_dim_6)), (((any_dim_4*any_dim_5)*any_dim_6) + 511)), 512)) {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k: int32, 0, any_dim_7) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k*stride_7))])
    }
  } else {
    if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
          T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
        }
      }
    }
    for (k_1: int32, 0, any_dim_7) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
            T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k_1*stride_7))])
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), T_softmax_exp_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, any_dim_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_9*any_dim_10)*any_dim_8) + 511), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_8*(any_dim_9*any_dim_10)), (any_dim_8*(any_dim_10*any_dim_9))), ((any_dim_9*any_dim_10)*any_dim_8)), (any_dim_8*(any_dim_9*any_dim_10))), (((any_dim_9*any_dim_10)*any_dim_8) + 511)), 512)) {
    T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
    for (k_2: int32, 0, any_dim_11) {
      T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_2)])
    }
  } else {
    if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
          T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        }
      }
    }
    for (k_3: int32, 0, any_dim_11) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
            T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_3)])
          }
        }
      }
    }
  }
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, any_dim_15: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15), (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))), (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))), (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))), ((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511)), 512)) {
    T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
  } else {
    if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))) {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15)) {
            T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
          }
        }
      }
    }
  }
}

primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder_2: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder_2] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim_16: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_17: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_18: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_19: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride_12: int32 = @tir.if_then_else((any_dim_19 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_13: int32 = @tir.if_then_else((any_dim_18 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_19, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_14: int32 = @tir.if_then_else((any_dim_17 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_19*any_dim_18), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_15: int32 = @tir.if_then_else((any_dim_16 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_19*any_dim_18)*any_dim_17), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm_1: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm_1] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_16: int32 = @tir.if_then_else((any_dim_19 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_17: int32 = @tir.if_then_else((any_dim_18 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_19, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_18: int32 = @tir.if_then_else((any_dim_17 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_19*any_dim_18), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_19: int32 = @tir.if_then_else((any_dim_16 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_19*any_dim_18)*any_dim_17), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim_16 == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_17 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_18 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_19 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
    @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem_4: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem_4, float32, [((any_dim_16*any_dim_17)*any_dim_18)]);
    attr [T_softmax_exp_3: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp_3, float32, [(((any_dim_16*any_dim_17)*any_dim_18)*any_dim_19)]) {
      @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem_4, placeholder_2, any_dim_16, any_dim_17, any_dim_18, any_dim_19, stride_15, stride_14, stride_13, stride_12, floordiv((((any_dim_16*any_dim_17)*any_dim_18) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp_3, placeholder_2, T_softmax_maxelem_4, any_dim_16, any_dim_17, any_dim_18, any_dim_19, stride_15, stride_14, stride_13, stride_12, floordiv(((((any_dim_16*any_dim_17)*any_dim_18)*any_dim_19) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem_4, T_softmax_exp_3, any_dim_18, any_dim_16, any_dim_17, any_dim_19, floordiv((((any_dim_16*any_dim_17)*any_dim_18) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm_1, T_softmax_exp_3, T_softmax_maxelem_4, any_dim_16, any_dim_17, any_dim_18, any_dim_19, stride_19, stride_18, stride_17, stride_16, floordiv(((((any_dim_16*any_dim_17)*any_dim_18)*any_dim_19) + 511), 512), 512, dtype=int32)
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": (nullptr), "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
    @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem, placeholder, any_dim, any_dim_1, any_dim_2, any_dim_3, stride_3, stride_2, stride_1, stride, floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp, placeholder, T_softmax_maxelem, any_dim, any_dim_1, any_dim_2, any_dim_3, stride_3, stride_2, stride_1, stride, floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem, T_softmax_exp, any_dim_2, any_dim, any_dim_1, any_dim_3, floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm, T_softmax_exp, T_softmax_maxelem, any_dim, any_dim_1, any_dim_2, any_dim_3, stride_7, stride_6, stride_5, stride_4, floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512), 512, dtype=int32)
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  attr ["default"] "device_id" = dev_id;
  attr ["default"] "device_type" = 2;
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
    @tir.tvm_call_packed("__tvm_set_device", 2, dev_id, dtype=int32)
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_maxelem, float32, [((any_dim*any_dim_1)*any_dim_2)]);
    attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
    allocate(T_softmax_exp, float32, [(((any_dim*any_dim_1)*any_dim_2)*any_dim_3)]) {
      @tir.tvm_call_packed("fused_nn_softmax_kernel0", T_softmax_maxelem, placeholder, any_dim, any_dim_1, any_dim_2, any_dim_3, stride_3, stride_2, stride_1, stride, floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel1", T_softmax_exp, placeholder, T_softmax_maxelem, any_dim, any_dim_1, any_dim_2, any_dim_3, stride_3, stride_2, stride_1, stride, floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel2", T_softmax_maxelem, T_softmax_exp, any_dim_2, any_dim, any_dim_1, any_dim_3, floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512), 512, dtype=int32)
      @tir.tvm_call_packed("fused_nn_softmax_kernel3", T_softmax_norm, T_softmax_exp, T_softmax_maxelem, any_dim, any_dim_1, any_dim_2, any_dim_3, stride_7, stride_6, stride_5, stride_4, floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512), 512, dtype=int32)
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerTVMBuiltin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerTVMBuiltin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 14, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 14, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512)), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, 512), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 8, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 14, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 14, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, floordiv((((any_dim*any_dim_1)*any_dim_2) + 511), 512)), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, 512), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 8, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 2)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg0.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(arg1.strides: handle, dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (2 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[1]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[2]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[3]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (2 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.isnullptr(T_softmax_maxelem: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.isnullptr(T_softmax_maxelem: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition @tir.isnullptr(T_softmax_maxelem: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition@tir.isnullptr(T_softmax_maxelem: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(T_softmax_maxelem: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = @tir.isnullptr(T_softmax_exp: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = @tir.isnullptr(T_softmax_exp: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition @tir.isnullptr(T_softmax_exp: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition@tir.isnullptr(T_softmax_exp: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(T_softmax_exp: Pointer(float32), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_exp: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_exp: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_exp: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_exp: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_exp: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_maxelem: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_maxelem: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_maxelem: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_maxelem: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (@tir.TVMBackendFreeWorkspace(2, dev_id: int32, T_softmax_maxelem: Pointer(float32), dtype=int32) != 0)
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 14, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 14, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, @tir.shift_right(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, 512), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 8, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, @tir.shift_right(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 14, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 14, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, @tir.shift_right(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, 512), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 8, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, @tir.shift_right(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.CombineContextCall
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.CombineContextCall
primfn(args: handle, arg_type_ids: handle, num_args: int32, out_ret_value: handle, out_ret_tcode: handle, resource_handle: handle) -> int32
  attr = {"target": meta[Target][0], "tir.noalias": True, "global_symbol": "fused_nn_softmax", "calling_conv": 1} {
  let stack_tcode: handle = @tir.tvm_stack_alloca("arg_tcode", 14, dtype=handle)
  let stack_value: handle = @tir.tvm_stack_alloca("arg_value", 14, dtype=handle)
  assert((num_args == 2), "fused_nn_softmax: num_args should be 2")
  let arg0: handle = @tir.tvm_struct_get(args, 0, 12, dtype=handle)
  let arg0.code: int32 = (int32*)arg_type_ids[0]
  let arg1: handle = @tir.tvm_struct_get(args, 1, 12, dtype=handle)
  let arg1.code: int32 = (int32*)arg_type_ids[1]
  let placeholder: Pointer(float32) = @tir.tvm_struct_get(arg0, 0, 1, dtype=handle)
  attr [placeholder] "storage_alignment" = 128;
  let arg0.shape: handle = @tir.tvm_struct_get(arg0, 0, 2, dtype=handle)
  let any_dim: int32 = cast(int32, (int64*)arg0.shape[0])
  let any_dim_1: int32 = cast(int32, (int64*)arg0.shape[1])
  let any_dim_2: int32 = cast(int32, (int64*)arg0.shape[2])
  let any_dim_3: int32 = cast(int32, (int64*)arg0.shape[3])
  let arg0.strides: handle = @tir.tvm_struct_get(arg0, 0, 3, dtype=handle)
  let stride: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), 1, cast(int32, (int64*)arg0.strides[3]), dtype=int32), dtype=int32)
  let stride_1: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg0.strides[2]), dtype=int32), dtype=int32)
  let stride_2: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg0.strides[1]), dtype=int32), dtype=int32)
  let stride_3: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg0.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg0.strides[0]), dtype=int32), dtype=int32)
  let dev_id: int32 = @tir.tvm_struct_get(arg0, 0, 9, dtype=int32)
  let T_softmax_norm: Pointer(float32) = @tir.tvm_struct_get(arg1, 0, 1, dtype=handle)
  attr [T_softmax_norm] "storage_alignment" = 128;
  let arg1.shape: handle = @tir.tvm_struct_get(arg1, 0, 2, dtype=handle)
  let arg1.strides: handle = @tir.tvm_struct_get(arg1, 0, 3, dtype=handle)
  let stride_4: int32 = @tir.if_then_else((any_dim_3 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), 1, cast(int32, (int64*)arg1.strides[3]), dtype=int32), dtype=int32)
  let stride_5: int32 = @tir.if_then_else((any_dim_2 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), any_dim_3, cast(int32, (int64*)arg1.strides[2]), dtype=int32), dtype=int32)
  let stride_6: int32 = @tir.if_then_else((any_dim_1 == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), (any_dim_3*any_dim_2), cast(int32, (int64*)arg1.strides[1]), dtype=int32), dtype=int32)
  let stride_7: int32 = @tir.if_then_else((any_dim == 1), 0, @tir.if_then_else(@tir.isnullptr(arg1.strides, dtype=bool), ((any_dim_3*any_dim_2)*any_dim_1), cast(int32, (int64*)arg1.strides[0]), dtype=int32), dtype=int32)
  assert(((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), "fused_nn_softmax: Expect arg[0] to be pointer")
  assert(((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), "fused_nn_softmax: Expect arg[1] to be pointer")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg0, 0, 4, dtype=int32)), "arg0.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg0, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16)), "arg0.dtype is expected to be float32")
  assert((0u64 == @tir.tvm_struct_get(arg0, 0, 8, dtype=uint64)), "Argument arg0.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg0, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg0, 0, 10, dtype=int32)), "Argument arg0.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg0, 0, 10))")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((4 == @tir.tvm_struct_get(arg1, 0, 4, dtype=int32)), "arg1.ndim is expected to equal 4")
  assert((((@tir.tvm_struct_get(arg1, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16)), "arg1.dtype is expected to be float32")
  assert((any_dim == cast(int32, (int64*)arg1.shape[0])), "Argument arg1.shape[0] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[0]))")
  assert((any_dim_1 == cast(int32, (int64*)arg1.shape[1])), "Argument arg1.shape[1] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[1]))")
  assert((any_dim_2 == cast(int32, (int64*)arg1.shape[2])), "Argument arg1.shape[2] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[2]))")
  assert((any_dim_3 == cast(int32, (int64*)arg1.shape[3])), "Argument arg1.shape[3] has an unsatisfied constraint: ({any_dim|any_dim>=0} == int32(arg1.shape[3]))")
  assert((0u64 == @tir.tvm_struct_get(arg1, 0, 8, dtype=uint64)), "Argument arg1.byte_offset has an unsatisfied constraint: ((uint64)0 == tir.tvm_struct_get(arg1, 0, 8))")
  assert((2 == @tir.tvm_struct_get(arg1, 0, 10, dtype=int32)), "Argument arg1.device_type has an unsatisfied constraint: (2 == tir.tvm_struct_get(arg1, 0, 10))")
  assert((dev_id == @tir.tvm_struct_get(arg1, 0, 9, dtype=int32)), "Argument arg1.device_id has an unsatisfied constraint: (dev_id == tir.tvm_struct_get(arg1, 0, 9))")
   {
     {
      @tir.tvm_struct_set(stack_value, 0, 12, cast(int64, 2), dtype=int32)
      stack_tcode[0] = 0
      @tir.tvm_struct_set(stack_value, 1, 12, cast(int64, dev_id), dtype=int32)
      stack_tcode[1] = 0
      @tir.tvm_call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2, dtype=int32)
    }
    attr [0] "compute_scope" = "fused_nn_softmax_compute_";
    attr [T_softmax_maxelem: Pointer(float32)] "storage_scope" = "global";
    attr [T_softmax_maxelem] "storage_alignment" = 128 {
      let T_softmax_maxelem = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*((any_dim*any_dim_1)*any_dim_2))), 2, 32, dtype=handle)
       {
        if @tir.isnullptr(T_softmax_maxelem, dtype=bool) {
          @tir.tvm_throw_last_error(, dtype=int32)
        }
        attr [T_softmax_exp: Pointer(float32)] "storage_scope" = "global";
        attr [T_softmax_exp] "storage_alignment" = 128 {
          let T_softmax_exp = @tir.TVMBackendAllocWorkspace(2, dev_id, cast(uint64, (4*(((any_dim*any_dim_1)*any_dim_2)*any_dim_3))), 2, 32, dtype=handle)
           {
            if @tir.isnullptr(T_softmax_exp, dtype=bool) {
              @tir.tvm_throw_last_error(, dtype=int32)
            }
             {
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, 512), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel0", stack_value, stack_tcode, 0, 12, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_exp, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, placeholder, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_3), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_2), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_1), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, @tir.shift_right(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel1", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[2] = 0
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, @tir.shift_right((((any_dim*any_dim_1)*any_dim_2) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, 512), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel2", stack_value, stack_tcode, 0, 8, dtype=int32)
              }
               {
                @tir.tvm_struct_set(stack_value, 0, 12, T_softmax_norm, dtype=int32)
                stack_tcode[0] = 3
                @tir.tvm_struct_set(stack_value, 1, 12, T_softmax_exp, dtype=int32)
                stack_tcode[1] = 3
                @tir.tvm_struct_set(stack_value, 2, 12, T_softmax_maxelem, dtype=int32)
                stack_tcode[2] = 3
                @tir.tvm_struct_set(stack_value, 3, 12, cast(int64, any_dim), dtype=int32)
                stack_tcode[3] = 0
                @tir.tvm_struct_set(stack_value, 4, 12, cast(int64, any_dim_1), dtype=int32)
                stack_tcode[4] = 0
                @tir.tvm_struct_set(stack_value, 5, 12, cast(int64, any_dim_2), dtype=int32)
                stack_tcode[5] = 0
                @tir.tvm_struct_set(stack_value, 6, 12, cast(int64, any_dim_3), dtype=int32)
                stack_tcode[6] = 0
                @tir.tvm_struct_set(stack_value, 7, 12, cast(int64, stride_7), dtype=int32)
                stack_tcode[7] = 0
                @tir.tvm_struct_set(stack_value, 8, 12, cast(int64, stride_6), dtype=int32)
                stack_tcode[8] = 0
                @tir.tvm_struct_set(stack_value, 9, 12, cast(int64, stride_5), dtype=int32)
                stack_tcode[9] = 0
                @tir.tvm_struct_set(stack_value, 10, 12, cast(int64, stride_4), dtype=int32)
                stack_tcode[10] = 0
                @tir.tvm_struct_set(stack_value, 11, 12, cast(int64, @tir.shift_right(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 9, dtype=int32)), dtype=int32)
                stack_tcode[11] = 0
                @tir.tvm_struct_set(stack_value, 12, 12, cast(int64, 512), dtype=int32)
                stack_tcode[12] = 0
                @tir.tvm_call_packed_lowered("fused_nn_softmax_kernel3", stack_value, stack_tcode, 0, 13, dtype=int32)
              }
            }
          }
          if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_exp, dtype=int32) != 0) {
            @tir.tvm_throw_last_error(, dtype=int32)
          }
        }
      }
      if (@tir.TVMBackendFreeWorkspace(2, dev_id, T_softmax_maxelem, dtype=int32) != 0) {
        @tir.tvm_throw_last_error(, dtype=int32)
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass Filter
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential Filter
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32), any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
    T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
  } else {
    if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
          if (((blockIdx.x*512) + threadIdx.x) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
            T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder_1: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, any_dim_7: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_4*any_dim_5)*any_dim_6) + 511), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_1 < floordiv(min(min(min(min(((any_dim_4*any_dim_5)*any_dim_6), (any_dim_6*(any_dim_5*any_dim_4))), (any_dim_6*(any_dim_4*any_dim_5))), ((any_dim_4*any_dim_5)*any_dim_6)), (((any_dim_4*any_dim_5)*any_dim_6) + 511)), 512)) {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k: int32, 0, any_dim_7) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k*stride_7))])
    }
  } else {
    if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
          T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
        }
      }
    }
    for (k_1: int32, 0, any_dim_7) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
            T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k_1*stride_7))])
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), T_softmax_exp_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, any_dim_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_9*any_dim_10)*any_dim_8) + 511), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_8*(any_dim_9*any_dim_10)), (any_dim_8*(any_dim_10*any_dim_9))), ((any_dim_9*any_dim_10)*any_dim_8)), (any_dim_8*(any_dim_9*any_dim_10))), (((any_dim_9*any_dim_10)*any_dim_8) + 511)), 512)) {
    T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
    for (k_2: int32, 0, any_dim_11) {
      T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_2)])
    }
  } else {
    if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
          T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        }
      }
    }
    for (k_3: int32, 0, any_dim_11) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
            T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_3)])
          }
        }
      }
    }
  }
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, any_dim_15: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15), (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))), (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))), (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))), ((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511)), 512)) {
    T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
  } else {
    if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))) {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15)) {
            T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass BindTarget
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential BindTarget
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32), any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
    T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
  } else {
    if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
          if (((blockIdx.x*512) + threadIdx.x) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
            T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder_1: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, any_dim_7: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_4*any_dim_5)*any_dim_6) + 511), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_1 < floordiv(min(min(min(min(((any_dim_4*any_dim_5)*any_dim_6), (any_dim_6*(any_dim_5*any_dim_4))), (any_dim_6*(any_dim_4*any_dim_5))), ((any_dim_4*any_dim_5)*any_dim_6)), (((any_dim_4*any_dim_5)*any_dim_6) + 511)), 512)) {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k: int32, 0, any_dim_7) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k*stride_7))])
    }
  } else {
    if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
          T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
        }
      }
    }
    for (k_1: int32, 0, any_dim_7) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
            T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k_1*stride_7))])
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), T_softmax_exp_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, any_dim_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_9*any_dim_10)*any_dim_8) + 511), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_8*(any_dim_9*any_dim_10)), (any_dim_8*(any_dim_10*any_dim_9))), ((any_dim_9*any_dim_10)*any_dim_8)), (any_dim_8*(any_dim_9*any_dim_10))), (((any_dim_9*any_dim_10)*any_dim_8) + 511)), 512)) {
    T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
    for (k_2: int32, 0, any_dim_11) {
      T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_2)])
    }
  } else {
    if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
          T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        }
      }
    }
    for (k_3: int32, 0, any_dim_11) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
            T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_3)])
          }
        }
      }
    }
  }
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, any_dim_15: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15), (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))), (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))), (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))), ((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511)), 512)) {
    T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
  } else {
    if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))) {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15)) {
            T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerWarpMemory
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerWarpMemory
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32), any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
    T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
  } else {
    if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
          if (((blockIdx.x*512) + threadIdx.x) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
            T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder_1: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, any_dim_7: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_4*any_dim_5)*any_dim_6) + 511), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_1 < floordiv(min(min(min(min(((any_dim_4*any_dim_5)*any_dim_6), (any_dim_6*(any_dim_5*any_dim_4))), (any_dim_6*(any_dim_4*any_dim_5))), ((any_dim_4*any_dim_5)*any_dim_6)), (((any_dim_4*any_dim_5)*any_dim_6) + 511)), 512)) {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k: int32, 0, any_dim_7) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k*stride_7))])
    }
  } else {
    if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
          T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
        }
      }
    }
    for (k_1: int32, 0, any_dim_7) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
            T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k_1*stride_7))])
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), T_softmax_exp_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, any_dim_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_9*any_dim_10)*any_dim_8) + 511), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_8*(any_dim_9*any_dim_10)), (any_dim_8*(any_dim_10*any_dim_9))), ((any_dim_9*any_dim_10)*any_dim_8)), (any_dim_8*(any_dim_9*any_dim_10))), (((any_dim_9*any_dim_10)*any_dim_8) + 511)), 512)) {
    T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
    for (k_2: int32, 0, any_dim_11) {
      T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_2)])
    }
  } else {
    if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
          T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        }
      }
    }
    for (k_3: int32, 0, any_dim_11) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
            T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_3)])
          }
        }
      }
    }
  }
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, any_dim_15: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15), (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))), (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))), (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))), ((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511)), 512)) {
    T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
  } else {
    if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))) {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15)) {
            T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.Simplify
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify @tir.exp(((float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))] - (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim)]), dtype=float32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify -3.40282e+38f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify max((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)], (float32*)placeholder: Pointer(float32)[((((floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32), any_dim_1: int32)*stride: int32) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_1: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_2: int32)) + (k: int32*stride_3: int32))])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify 0f32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 >= 0)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (k: int32 < any_dim: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify any_dim: int32
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_maxelem: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] + (float32*)T_softmax_exp: Pointer(float32)[((((blockIdx.x*512) + threadIdx.x)*any_dim: int32) + k: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((blockIdx.x: int32*512) + threadIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify floordiv(((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32) + 511), 512)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((float32*)T_softmax_exp: Pointer(float32)[((blockIdx.x: int32*512) + threadIdx.x: int32)] / (float32*)T_softmax_maxelem: Pointer(float32)[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim: int32)])
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:131: After rewrite simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:134: After canonical simplify ((((floordiv(floordiv(floordiv(((blockIdx.x: int32*512) + threadIdx.x: int32), any_dim: int32), any_dim_1: int32), any_dim_2: int32)*stride: int32) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1), any_dim_2)*stride_1: int32)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim), any_dim_1)*stride_2: int32)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim)*stride_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.Simplify
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32), any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
    T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
  } else {
    if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
          if (((blockIdx.x*512) + threadIdx.x) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
            T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder_1: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, any_dim_7: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_4*any_dim_5)*any_dim_6) + 511), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_1 < floordiv(min(min(min(min(((any_dim_4*any_dim_5)*any_dim_6), (any_dim_6*(any_dim_5*any_dim_4))), (any_dim_6*(any_dim_4*any_dim_5))), ((any_dim_4*any_dim_5)*any_dim_6)), (((any_dim_4*any_dim_5)*any_dim_6) + 511)), 512)) {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k: int32, 0, any_dim_7) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k*stride_7))])
    }
  } else {
    if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
          T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
        }
      }
    }
    for (k_1: int32, 0, any_dim_7) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
            T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k_1*stride_7))])
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), T_softmax_exp_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, any_dim_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_9*any_dim_10)*any_dim_8) + 511), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_8*(any_dim_9*any_dim_10)), (any_dim_8*(any_dim_10*any_dim_9))), ((any_dim_9*any_dim_10)*any_dim_8)), (any_dim_8*(any_dim_9*any_dim_10))), (((any_dim_9*any_dim_10)*any_dim_8) + 511)), 512)) {
    T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
    for (k_2: int32, 0, any_dim_11) {
      T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_2)])
    }
  } else {
    if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
          T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        }
      }
    }
    for (k_3: int32, 0, any_dim_11) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
            T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_3)])
          }
        }
      }
    }
  }
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, any_dim_15: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15), (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))), (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))), (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))), ((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511)), 512)) {
    T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
  } else {
    if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))) {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15)) {
            T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerCustomDatatypes
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerCustomDatatypes
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32), any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 512);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x < floordiv(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512)) {
    T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
  } else {
    if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
          if (((blockIdx.x*512) + threadIdx.x) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
            T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.exp(((float32*)placeholder[((((floordiv(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride) + (floormod(floordiv(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2), any_dim_1)*stride_1)) + (floormod(floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3), any_dim_2)*stride_2)) + (floormod(((blockIdx.x*512) + threadIdx.x), any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[floordiv(((blockIdx.x*512) + threadIdx.x), any_dim_3)]), dtype=float32)
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder_1: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, any_dim_7: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_4*any_dim_5)*any_dim_6) + 511), 512);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_1 < floordiv(min(min(min(min(((any_dim_4*any_dim_5)*any_dim_6), (any_dim_6*(any_dim_5*any_dim_4))), (any_dim_6*(any_dim_4*any_dim_5))), ((any_dim_4*any_dim_5)*any_dim_6)), (((any_dim_4*any_dim_5)*any_dim_6) + 511)), 512)) {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k: int32, 0, any_dim_7) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k*stride_7))])
    }
  } else {
    if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
          T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
        }
      }
    }
    for (k_1: int32, 0, any_dim_7) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
            T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[((((floordiv(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_4) + (floormod(floordiv(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6), any_dim_5)*stride_5)) + (floormod(((blockIdx.x_1*512) + threadIdx.x_1), any_dim_6)*stride_6)) + (k_1*stride_7))])
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), T_softmax_exp_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, any_dim_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv((((any_dim_9*any_dim_10)*any_dim_8) + 511), 512);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_2 < floordiv(min(min(min(min((any_dim_8*(any_dim_9*any_dim_10)), (any_dim_8*(any_dim_10*any_dim_9))), ((any_dim_9*any_dim_10)*any_dim_8)), (any_dim_8*(any_dim_9*any_dim_10))), (((any_dim_9*any_dim_10)*any_dim_8) + 511)), 512)) {
    T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
    for (k_2: int32, 0, any_dim_11) {
      T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_2)])
    }
  } else {
    if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
          T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        }
      }
    }
    for (k_3: int32, 0, any_dim_11) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
            T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_3)])
          }
        }
      }
    }
  }
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, any_dim_15: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = floordiv(((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511), 512);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_3 < floordiv(min(min(min(min((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15), (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))), (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))), (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))), ((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511)), 512)) {
    T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
  } else {
    if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))) {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15)) {
            T_softmax_norm[((((floordiv(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_8) + (floormod(floordiv(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14), any_dim_13)*stride_9)) + (floormod(floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15), any_dim_14)*stride_10)) + (floormod(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[floordiv(((blockIdx.x_3*512) + threadIdx.x_3), any_dim_15)])
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerIntrin
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < @tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (@tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < @tir.shift_right(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < @tir.shift_right(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < @tir.shift_right(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < @tir.shift_right(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (@tir.shift_right(min(min(min(min(((any_dim: int32*any_dim_1: int32)*any_dim_2: int32), (any_dim_2*(any_dim_1*any_dim))), (any_dim_2*(any_dim*any_dim_1))), ((any_dim*any_dim_1)*any_dim_2)), (((any_dim*any_dim_1)*any_dim_2) + 511)), 9, dtype=int32) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < @tir.shift_right(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (@tir.shift_right(min(min(min(min((any_dim: int32*(any_dim_1: int32*any_dim_2: int32)), (any_dim*(any_dim_2*any_dim_1))), ((any_dim_1*any_dim_2)*any_dim)), (any_dim*(any_dim_1*any_dim_2))), (((any_dim_1*any_dim_2)*any_dim) + 511)), 9, dtype=int32) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*any_dim_2: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < ((any_dim: int32*any_dim_1: int32)*any_dim_2: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (blockIdx.x: int32 < floordiv(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 512))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(blockIdx.x: int32 < @tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (blockIdx.x: int32 < @tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (@tir.shift_right(min(min(min(min((((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32) <= blockIdx.x: int32)
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*(any_dim_1: int32*(any_dim_2: int32*any_dim_3: int32))))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (any_dim: int32*((any_dim_1: int32*any_dim_2: int32)*any_dim_3: int32)))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:57: Before VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:59: After VisitExpr, condition = (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:69: Judge condition (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/ir_mutator_with_analyzer.cc:70: After simplify condition(((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((blockIdx.x: int32*512) + threadIdx.x: int32) < (((any_dim: int32*any_dim_1: int32)*any_dim_2: int32)*any_dim_3: int32))
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerIntrin
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32), any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 9, dtype=int32);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x < @tir.shift_right(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32)) {
    T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.call_pure_extern("__expf", ((float32*)placeholder[(((((((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) / any_dim_1) + @tir.shift_right(((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1), 31, dtype=int32))*stride) + ((((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1) + @tir.bitwise_and(any_dim_1, @tir.shift_right(((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1), 31, dtype=int32), dtype=int32))*stride_1)) + ((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2) + @tir.bitwise_and(any_dim_2, @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32), dtype=int32))*stride_2)) + ((((blockIdx.x*512) + threadIdx.x) % any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[(((blockIdx.x*512) + threadIdx.x) / any_dim_3)]), dtype=float32)
  } else {
    if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
          if (((blockIdx.x*512) + threadIdx.x) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
            T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.call_pure_extern("__expf", ((float32*)placeholder[(((((((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) / any_dim_1) + @tir.shift_right(((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1), 31, dtype=int32))*stride) + ((((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1) + @tir.bitwise_and(any_dim_1, @tir.shift_right(((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1), 31, dtype=int32), dtype=int32))*stride_1)) + ((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2) + @tir.bitwise_and(any_dim_2, @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32), dtype=int32))*stride_2)) + ((((blockIdx.x*512) + threadIdx.x) % any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[(((blockIdx.x*512) + threadIdx.x) / any_dim_3)]), dtype=float32)
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder_1: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, any_dim_7: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right((((any_dim_4*any_dim_5)*any_dim_6) + 511), 9, dtype=int32);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_1 < @tir.shift_right(min(min(min(min(((any_dim_4*any_dim_5)*any_dim_6), (any_dim_6*(any_dim_5*any_dim_4))), (any_dim_6*(any_dim_4*any_dim_5))), ((any_dim_4*any_dim_5)*any_dim_6)), (((any_dim_4*any_dim_5)*any_dim_6) + 511)), 9, dtype=int32)) {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k: int32, 0, any_dim_7) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[(((((((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) / any_dim_5) + @tir.shift_right(((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5), 31, dtype=int32))*stride_4) + ((((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5) + @tir.bitwise_and(any_dim_5, @tir.shift_right(((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5), 31, dtype=int32), dtype=int32))*stride_5)) + ((((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_6)*stride_6)) + (k*stride_7))])
    }
  } else {
    if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
          T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
        }
      }
    }
    for (k_1: int32, 0, any_dim_7) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
            T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[(((((((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) / any_dim_5) + @tir.shift_right(((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5), 31, dtype=int32))*stride_4) + ((((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5) + @tir.bitwise_and(any_dim_5, @tir.shift_right(((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5), 31, dtype=int32), dtype=int32))*stride_5)) + ((((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_6)*stride_6)) + (k_1*stride_7))])
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), T_softmax_exp_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, any_dim_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right((((any_dim_9*any_dim_10)*any_dim_8) + 511), 9, dtype=int32);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_2 < @tir.shift_right(min(min(min(min((any_dim_8*(any_dim_9*any_dim_10)), (any_dim_8*(any_dim_10*any_dim_9))), ((any_dim_9*any_dim_10)*any_dim_8)), (any_dim_8*(any_dim_9*any_dim_10))), (((any_dim_9*any_dim_10)*any_dim_8) + 511)), 9, dtype=int32)) {
    T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
    for (k_2: int32, 0, any_dim_11) {
      T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_2)])
    }
  } else {
    if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
          T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        }
      }
    }
    for (k_3: int32, 0, any_dim_11) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
            T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_3)])
          }
        }
      }
    }
  }
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, any_dim_15: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right(((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511), 9, dtype=int32);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_3 < @tir.shift_right(min(min(min(min((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15), (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))), (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))), (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))), ((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511)), 9, dtype=int32)) {
    T_softmax_norm[(((((((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) / any_dim_13) + @tir.shift_right(((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13), 31, dtype=int32))*stride_8) + ((((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13) + @tir.bitwise_and(any_dim_13, @tir.shift_right(((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13), 31, dtype=int32), dtype=int32))*stride_9)) + ((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14) + @tir.bitwise_and(any_dim_14, @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32), dtype=int32))*stride_10)) + ((((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[(((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15)])
  } else {
    if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))) {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15)) {
            T_softmax_norm[(((((((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) / any_dim_13) + @tir.shift_right(((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13), 31, dtype=int32))*stride_8) + ((((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13) + @tir.bitwise_and(any_dim_13, @tir.shift_right(((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13), 31, dtype=int32), dtype=int32))*stride_9)) + ((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14) + @tir.bitwise_and(any_dim_14, @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32), dtype=int32))*stride_10)) + ((((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[(((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15)])
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:463: DOING Pass tir.LowerDeviceStorageAccessInfo
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:466: DEPENDENCIES: 
[16:18:29] /workspace/home/codes/tvm/src/ir/transform.cc:473: After tir sequential tir.LowerDeviceStorageAccessInfo
primfn(T_softmax_exp: Pointer(float32), placeholder: Pointer(float32), T_softmax_maxelem: Pointer(float32), any_dim: int32, any_dim_1: int32, any_dim_2: int32, any_dim_3: int32, stride: int32, stride_1: int32, stride_2: int32, stride_3: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel1", "tir.device_thread_axis": [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right(((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511), 9, dtype=int32);
  attr [IterVar(threadIdx.x, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x < @tir.shift_right(min(min(min(min((((any_dim*any_dim_1)*any_dim_2)*any_dim_3), (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))), (any_dim_3*((any_dim*any_dim_1)*any_dim_2))), (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))), ((((any_dim*any_dim_1)*any_dim_2)*any_dim_3) + 511)), 9, dtype=int32)) {
    T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.call_pure_extern("__expf", ((float32*)placeholder[(((((((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) / any_dim_1) + @tir.shift_right(((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1), 31, dtype=int32))*stride) + ((((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1) + @tir.bitwise_and(any_dim_1, @tir.shift_right(((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1), 31, dtype=int32), dtype=int32))*stride_1)) + ((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2) + @tir.bitwise_and(any_dim_2, @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32), dtype=int32))*stride_2)) + ((((blockIdx.x*512) + threadIdx.x) % any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[(((blockIdx.x*512) + threadIdx.x) / any_dim_3)]), dtype=float32)
  } else {
    if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim_1*any_dim)))) {
      if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*(any_dim_2*(any_dim*any_dim_1)))) {
        if (((blockIdx.x*512) + threadIdx.x) < (any_dim_3*((any_dim*any_dim_1)*any_dim_2))) {
          if (((blockIdx.x*512) + threadIdx.x) < (((any_dim*any_dim_1)*any_dim_2)*any_dim_3)) {
            T_softmax_exp[((blockIdx.x*512) + threadIdx.x)] = @tir.call_pure_extern("__expf", ((float32*)placeholder[(((((((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) / any_dim_1) + @tir.shift_right(((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1), 31, dtype=int32))*stride) + ((((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1) + @tir.bitwise_and(any_dim_1, @tir.shift_right(((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) / any_dim_2) + @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32)) % any_dim_1), 31, dtype=int32), dtype=int32))*stride_1)) + ((((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2) + @tir.bitwise_and(any_dim_2, @tir.shift_right(((((blockIdx.x*512) + threadIdx.x) / any_dim_3) % any_dim_2), 31, dtype=int32), dtype=int32))*stride_2)) + ((((blockIdx.x*512) + threadIdx.x) % any_dim_3)*stride_3))] - (float32*)T_softmax_maxelem[(((blockIdx.x*512) + threadIdx.x) / any_dim_3)]), dtype=float32)
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_1: Pointer(float32), placeholder_1: Pointer(float32), any_dim_4: int32, any_dim_5: int32, any_dim_6: int32, any_dim_7: int32, stride_4: int32, stride_5: int32, stride_6: int32, stride_7: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel0", "tir.device_thread_axis": [IterVar(blockIdx.x_1: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_1, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right((((any_dim_4*any_dim_5)*any_dim_6) + 511), 9, dtype=int32);
  attr [IterVar(threadIdx.x_1, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_1 < @tir.shift_right(min(min(min(min(((any_dim_4*any_dim_5)*any_dim_6), (any_dim_6*(any_dim_5*any_dim_4))), (any_dim_6*(any_dim_4*any_dim_5))), ((any_dim_4*any_dim_5)*any_dim_6)), (((any_dim_4*any_dim_5)*any_dim_6) + 511)), 9, dtype=int32)) {
    T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
    for (k: int32, 0, any_dim_7) {
      T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[(((((((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) / any_dim_5) + @tir.shift_right(((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5), 31, dtype=int32))*stride_4) + ((((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5) + @tir.bitwise_and(any_dim_5, @tir.shift_right(((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5), 31, dtype=int32), dtype=int32))*stride_5)) + ((((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_6)*stride_6)) + (k*stride_7))])
    }
  } else {
    if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
          T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = -3.40282e+38f32
        }
      }
    }
    for (k_1: int32, 0, any_dim_7) {
      if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_5*any_dim_4))) {
        if (((blockIdx.x_1*512) + threadIdx.x_1) < (any_dim_6*(any_dim_4*any_dim_5))) {
          if (((blockIdx.x_1*512) + threadIdx.x_1) < ((any_dim_4*any_dim_5)*any_dim_6)) {
            T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)] = max((float32*)T_softmax_maxelem_1[((blockIdx.x_1*512) + threadIdx.x_1)], (float32*)placeholder_1[(((((((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) / any_dim_5) + @tir.shift_right(((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5), 31, dtype=int32))*stride_4) + ((((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5) + @tir.bitwise_and(any_dim_5, @tir.shift_right(((((blockIdx.x_1*512) + threadIdx.x_1) / any_dim_6) % any_dim_5), 31, dtype=int32), dtype=int32))*stride_5)) + ((((blockIdx.x_1*512) + threadIdx.x_1) % any_dim_6)*stride_6)) + (k_1*stride_7))])
          }
        }
      }
    }
  }
}

primfn(T_softmax_maxelem_2: Pointer(float32), T_softmax_exp_1: Pointer(float32), any_dim_8: int32, any_dim_9: int32, any_dim_10: int32, any_dim_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel2", "tir.device_thread_axis": [IterVar(blockIdx.x_2: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_2, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right((((any_dim_9*any_dim_10)*any_dim_8) + 511), 9, dtype=int32);
  attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_2 < @tir.shift_right(min(min(min(min((any_dim_8*(any_dim_9*any_dim_10)), (any_dim_8*(any_dim_10*any_dim_9))), ((any_dim_9*any_dim_10)*any_dim_8)), (any_dim_8*(any_dim_9*any_dim_10))), (((any_dim_9*any_dim_10)*any_dim_8) + 511)), 9, dtype=int32)) {
    T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
    for (k_2: int32, 0, any_dim_11) {
      T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_2)])
    }
  } else {
    if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
          T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = 0f32
        }
      }
    }
    for (k_3: int32, 0, any_dim_11) {
      if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_10*any_dim_9))) {
        if (((blockIdx.x_2*512) + threadIdx.x_2) < (any_dim_8*(any_dim_9*any_dim_10))) {
          if (((blockIdx.x_2*512) + threadIdx.x_2) < ((any_dim_9*any_dim_10)*any_dim_8)) {
            T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] = ((float32*)T_softmax_maxelem_2[((blockIdx.x_2*512) + threadIdx.x_2)] + (float32*)T_softmax_exp_1[((((blockIdx.x_2*512) + threadIdx.x_2)*any_dim_11) + k_3)])
          }
        }
      }
    }
  }
}

primfn(T_softmax_norm: Pointer(float32), T_softmax_exp_2: Pointer(float32), T_softmax_maxelem_3: Pointer(float32), any_dim_12: int32, any_dim_13: int32, any_dim_14: int32, any_dim_15: int32, stride_8: int32, stride_9: int32, stride_10: int32, stride_11: int32) -> ()
  attr = {"target": meta[Target][0], "tir.noalias": 1, "global_symbol": "fused_nn_softmax_kernel3", "tir.device_thread_axis": [IterVar(blockIdx.x_3: int32, (nullptr), "ThreadIndex", "blockIdx.x"), IterVar(threadIdx.x_3: int32, (nullptr), "ThreadIndex", "threadIdx.x")], "calling_conv": 2} {
  attr [IterVar(blockIdx.x_3, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = @tir.shift_right(((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511), 9, dtype=int32);
  attr [IterVar(threadIdx.x_3, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 512;
  if (blockIdx.x_3 < @tir.shift_right(min(min(min(min((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15), (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))), (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))), (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))), ((((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15) + 511)), 9, dtype=int32)) {
    T_softmax_norm[(((((((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) / any_dim_13) + @tir.shift_right(((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13), 31, dtype=int32))*stride_8) + ((((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13) + @tir.bitwise_and(any_dim_13, @tir.shift_right(((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13), 31, dtype=int32), dtype=int32))*stride_9)) + ((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14) + @tir.bitwise_and(any_dim_14, @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32), dtype=int32))*stride_10)) + ((((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[(((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15)])
  } else {
    if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_13*any_dim_12)))) {
      if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*(any_dim_14*(any_dim_12*any_dim_13)))) {
        if (((blockIdx.x_3*512) + threadIdx.x_3) < (any_dim_15*((any_dim_12*any_dim_13)*any_dim_14))) {
          if (((blockIdx.x_3*512) + threadIdx.x_3) < (((any_dim_12*any_dim_13)*any_dim_14)*any_dim_15)) {
            T_softmax_norm[(((((((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) / any_dim_13) + @tir.shift_right(((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13), 31, dtype=int32))*stride_8) + ((((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13) + @tir.bitwise_and(any_dim_13, @tir.shift_right(((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) / any_dim_14) + @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32)) % any_dim_13), 31, dtype=int32), dtype=int32))*stride_9)) + ((((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14) + @tir.bitwise_and(any_dim_14, @tir.shift_right(((((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15) % any_dim_14), 31, dtype=int32), dtype=int32))*stride_10)) + ((((blockIdx.x_3*512) + threadIdx.x_3) % any_dim_15)*stride_11))] = ((float32*)T_softmax_exp_2[((blockIdx.x_3*512) + threadIdx.x_3)] / (float32*)T_softmax_maxelem_3[(((blockIdx.x_3*512) + threadIdx.x_3) / any_dim_15)])
          }
        }
      }
    }
  }
}


[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 2)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == cast(int32, (int64*)arg0.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == cast(int32, (int64*)arg0.strides: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == cast(int32, (int64*)arg1.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == cast(int32, (int64*)arg1.strides: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 2)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == cast(int32, (int64*)arg0.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == cast(int32, (int64*)arg0.strides: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 2)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 0u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 64u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (1 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (num_args: int32 == 2)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 0, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[3]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[2]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[1]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) == 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (cast(int32, (int64*)arg0.shape: handle[0]) != 1)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint @tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint !@tir.isnullptr(@tir.tvm_struct_get(@tir.tvm_struct_get(args: handle, 1, 12, dtype=handle), 0, 3, dtype=handle), dtype=bool)
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg0.code: int32 == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint ((((arg1.code: int32 == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == @tir.tvm_struct_get(arg0: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg0: handle, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg0, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg0, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg0: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (2 == @tir.tvm_struct_get(arg0: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (4 == @tir.tvm_struct_get(arg1: handle, 0, 4, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (((@tir.tvm_struct_get(arg1: handle, 0, 5, dtype=uint8) == 2u8) && (@tir.tvm_struct_get(arg1, 0, 6, dtype=uint8) == 32u8)) && (@tir.tvm_struct_get(arg1, 0, 7, dtype=uint16) == 1u16))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[0]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[1]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[2]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (any_dim: int32 == cast(int32, (int64*)arg1.shape: handle[3]))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (0u64 == @tir.tvm_struct_get(arg1: handle, 0, 8, dtype=uint64))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (2 == @tir.tvm_struct_get(arg1: handle, 0, 10, dtype=int32))
[16:18:29] /workspace/home/codes/tvm/src/arith/analyzer.cc:69: enter constraint (dev_id: int32 == @tir.tvm_struct_get(arg1: handle, 0, 9, dtype=int32))
Raw module: 
def @main(%x: Tensor[(?, ?, ?, ?), float32]) {
  nn.softmax(%x)
}

Running on (cuda, cuda(0))
Finish in 18.73207 ms
